{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13609052", "self": "https://issues.apache.org/jira/rest/api/2/issue/13609052", "key": "HADOOP-19460", "fields": {"summary": "High number of Threads Launched when Calling fs.getFileStatus() via proxyUser after Kerberos authentication.", "description": "We have observed an issue where very large number of threads are being launched when performing concurrent {{fs.getFileStatus(path) operations}} as proxyUser.\r\n\r\nAlthough this issue was observed in our hive services, we were able to isolate and replicate this issue without hive by writing a sample standalone program which first logs in via a principal and keytab and then creates a proxy user and fires concurrent {{fs.getFileStatus(path)}} for a few mins. Eventually when the concurrency increases it tries to create more threads than max available threads(ulimit range) and the process eventually slows down.\r\n{code:java}\r\nUserGroupInformation proxyUserUGI = UserGroupInformation.createProxyUser(\r\n\"hive\", UserGroupInformation.getLoginUser());{code}\r\nIn this particular case, when launching 30 concurrent threads calling , the max number of threads launched by the PID are 6066.\r\n\u00a0\r\n{code:java}\r\nEvery 1.0s: ps -eo nlwp,pid,args --sort -nlwp | head \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Wed Feb 19 06:12:47 2025\r\nNLWP \u00a0 \u00a0 PID COMMAND\r\n6066 \u00a0700718 /usr/lib/jvm/java-17-openjdk/bin/java -cp ./test.jar:/usr/hadoop/*:/usr/hadoop/lib/*:/usr/hadoop-hdfs/* org.apache.hadoop.hive.common.HDFSFileStatusExample hdfs://namenode:8020 principal keytab_location 30 true\r\n\r\n\r\n{code}\r\n\u00a0\r\n\u00a0\r\n\u00a0\r\n\u00a0\r\nBut the same behaviour is not observed when the same calls are made using the current userUGI instead of proxyUser.\r\n{code:java}\r\nUserGroupInformation currentUserUgi = UserGroupInformation.getCurrentUser();{code}\r\n\u00a0\r\n\r\nIn this case when launching 30 concurrent threads calling , the max number of threads launched by the PID are 56 and when launched with 500 concurrent threads the max number of threads launched are 524.\r\n{code:java}\r\nEvery 1.0s: ps -eo nlwp,pid,args --sort -nlwp | head \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Tue Feb 18 06:23:18 2025NLWP \u00a0 \u00a0 PID COMMAND\r\n\u00a0 56 \u00a0748244 /usr/lib/jvm/java-17-openjdk/bin/java -cp ./test.jar:/usr/hadoop/*:/usr/hadoop/lib/*:/usr/hadoop-hdfs/* org.apache.hadoop.hive.common.HDFSFileStatus hdfs://namenode:8020 principal keytab_location 30 false\r\n\r\n\r\n\r\nEvery 1.0s: ps -eo nlwp,pid,args --sort -nlwp | head \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Wed Feb 19 06:19:03 2025NLWP \u00a0 \u00a0 PID COMMAND\r\n\u00a0524 \u00a0750984 /usr/lib/jvm/java-17-openjdk/bin/java -cp ./test.jar:/usr/hadoop/*:/usr/hadoop/lib/*:/usr/hadoop-hdfs/* org.apache.hadoop.hive.common.HDFSFileStatus hdfs://namenode:8020 principal keytab_location 500 false{code}\r\n\u00a0\r\n\r\nI am attaching the sample program where in one case the calls are made by ProxyUser(issue occurs here) and in another case the call is made by currentUser(Works fine).\r\n\r\n\u00a0\r\n\r\nSample program used to reproduce this issue:\r\n{code:java}\r\npackage org.apache.hadoop.hive.common;\r\n\r\nimport org.apache.hadoop.conf.Configuration;\r\nimport org.apache.hadoop.fs.FileStatus;\r\nimport org.apache.hadoop.fs.FileSystem;\r\nimport org.apache.hadoop.fs.Path;\r\nimport org.apache.hadoop.security.UserGroupInformation;\r\nimport org.slf4j.Logger;\r\nimport org.slf4j.LoggerFactory;\r\n\r\nimport java.io.IOException;\r\nimport java.net.URI;\r\nimport java.security.PrivilegedExceptionAction;\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.concurrent.TimeUnit;\r\n\r\npublic class HDFSFileStatusExample {\r\n\r\n    private static final Logger LOG = LoggerFactory.getLogger(HDFSFileStatusExample.class.getName());\r\n\r\n    public static void main(String[] args) throws InterruptedException {\r\n        if (args.length == 0) {\r\n            System.err.println(\"Usage: HDFSFileStatus <hdfs-file-path> [<hdfs-file-path> ...]\");\r\n            System.exit(1);\r\n        }\r\n\r\n        Configuration configuration = new Configuration();\r\n\r\n        // Set up Kerberos authentication\r\n        configuration.set(\"fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\");\r\n        configuration.set(\"hadoop.security.authentication\", \"kerberos\");\r\n        configuration.set(\"hadoop.security.authorization\", \"true\");\r\n\r\n        configuration.set(\"hadoop.http.authentication.type\", \"kerberos\");\r\n        System.out.println(\"hadoop.security.authentication:  \" + configuration.get(\"hadoop.security.authentication\"));\r\n\r\n        UserGroupInformation.setConfiguration(configuration);\r\n        try {\r\n            UserGroupInformation.loginUserFromKeytab(args[1], args[2]);\r\n            System.out.println(\"LOGGED IN\");\r\n        } catch (IOException e) {\r\n            LOG.info(e.getMessage());\r\n        }\r\n\r\n\r\n        configuration.iterator().forEachRemaining(e -> LOG.info(\"Configuration: {}={}\", e.getKey(), e.getValue()));\r\n\r\n\r\n        int threadCount = Integer.parseInt(args[3]);\r\n        ExecutorService executorService = Executors.newFixedThreadPool(threadCount);\r\n\r\n        for (int i = 0; i < threadCount; i++) {\r\n            executorService.submit(new SomeTask(args[0], configuration, Boolean.parseBoolean(args[4])));\r\n        }\r\n\r\n        boolean terminated = executorService.awaitTermination(10, TimeUnit.MINUTES);\r\n        System.out.println(\"Terminated=\" + terminated);\r\n\r\n\r\n    }\r\n\r\n\r\n\r\n    static class SomeTask implements Runnable {\r\n        private final String uri;\r\n        Configuration conf;\r\n        boolean isProxyUser;\r\n\r\n        SomeTask(String hdfs_uri, Configuration conf, boolean isProxyUser) {\r\n            this.uri = hdfs_uri;\r\n            this.conf = conf;\r\n            this.isProxyUser = isProxyUser;\r\n        }\r\n\r\n        @Override\r\n        public void run() {\r\n\r\n            try {\r\n                while (true) {\r\n                    URI uris = new URI(uri);\r\n                    UserGroupInformation currentUserUgi = UserGroupInformation.getCurrentUser();\r\n\r\n                    UserGroupInformation proxyUserUGI = UserGroupInformation.createProxyUser(\r\n                            \"hive\", UserGroupInformation.getLoginUser());\r\n\r\n                    LOG.info(\"Current user: \" + currentUserUgi.getUserName());\r\n                    LOG.info(\"Authentication method: \" + currentUserUgi.getAuthenticationMethod());\r\n\r\n                    // Check if the authentication method is KERBEROS\r\n                    if (currentUserUgi.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS) {\r\n                        LOG.info(\"UGI Successfully authenticated using Kerberos.\");\r\n                    } else {\r\n                        LOG.info(\"UGI Failed to authenticate using Kerberos.\");\r\n                    }\r\n\r\n                    // Check if the authentication method is KERBEROS\r\n                    if (proxyUserUGI.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.PROXY) {\r\n                        LOG.info(\"SESSIONUGI Proxy\");\r\n                    } else {\r\n                        LOG.info(\"SESSIONUGI no Proxy\");\r\n                    }\r\n\r\n\r\n                    LOG.info(\"ugi is \" + currentUserUgi.toString());\r\n\r\n                    LOG.info(\"ProxyUgi is \" + proxyUserUGI.toString());\r\n\r\n                    UserGroupInformation finalUGI;\r\n                    if (isProxyUser) {\r\n                        finalUGI = proxyUserUGI;\r\n                    } else {\r\n                        finalUGI = currentUserUgi;\r\n                    }\r\n\r\n                    finalUGI.doAs((PrivilegedExceptionAction<Void>) () -> {\r\n                        FileSystem hdfs = FileSystem.get(uris, conf);\r\n                        LOG.info(\"hdfs is : {} \", hdfs.toString());\r\n\r\n                        Path path0 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db\");\r\n                        Path path1 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_1\");\r\n                        Path path2 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_2\");\r\n                        Path path3 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_3\");\r\n                        Path path4 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_4\");\r\n                        Path path5 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_5\");\r\n                        Path path6 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_6\");\r\n                        Path path7 = new Path(\"/warehouse/tablespace/external/hive/concurrency.db/table_7\");\r\n                        Path path8 = new Path(\"/data\");\r\n\r\n                        try {\r\n\r\n                            FileStatus fileStatus0 = hdfs.getFileStatus(path0);\r\n                            LOG.info(\"fileStatus0 : {} \", fileStatus0.toString());\r\n                            FileStatus fileStatus1 = hdfs.getFileStatus(path1);\r\n                            LOG.info(\"fileStatus1 : {} \", fileStatus1.toString());\r\n                            FileStatus fileStatus2 = hdfs.getFileStatus(path2);\r\n                            LOG.info(\"fileStatus2 : {} \", fileStatus2.toString());\r\n                            FileStatus fileStatus3 = hdfs.getFileStatus(path3);\r\n                            LOG.info(\"fileStatus3 : {} \", fileStatus3.toString());\r\n                            FileStatus fileStatus4 = hdfs.getFileStatus(path4);\r\n                            LOG.info(\"fileStatus4 : {} \", fileStatus4.toString());\r\n                            FileStatus fileStatus5 = hdfs.getFileStatus(path5);\r\n                            LOG.info(\"fileStatus5 : {} \", fileStatus5.toString());\r\n                            FileStatus fileStatus6 = hdfs.getFileStatus(path6);\r\n                            LOG.info(\"fileStatus6 : {} \", fileStatus6.toString());\r\n                            FileStatus fileStatus7 = hdfs.getFileStatus(path7);\r\n                            LOG.info(\"fileStatus7 : {} \", fileStatus7.toString());\r\n                            FileStatus fileStatus8 = hdfs.getFileStatus(path8);\r\n                            LOG.info(\"fileStatus8 : {} \", fileStatus8.toString());\r\n                        } catch (Exception e) {\r\n                            System.out.println(\"Exception is : \" + e.getMessage());\r\n                        }\r\n                        hdfs.close();\r\n                        return null;\r\n                    });\r\n                    System.out.println(\"-----------------------------------------------------\");\r\n                }\r\n\r\n            } catch(Exception e){\r\n                e.printStackTrace();\r\n            }\r\n        }\r\n    }\r\n}{code}\r\n\u00a0\r\n\r\nThe command line args given for the sample program are:\r\n\r\narg[0] = namenode_host_name:port\r\n\r\narg[1] = principal\r\n\r\narg[2] = keytab_location\r\n\r\narg[3] = Number of threads\r\n\r\nargs[4] = true/false(true is doAs with proxyUserUGI)", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=vikramahuja_", "name": "vikramahuja_", "key": "vikramahuja_", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Vikram Ahuja", "active": true, "timeZone": "Etc/UTC"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13609052/comment/17928650", "id": "17928650", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=vikramahuja_", "name": "vikramahuja_", "key": "vikramahuja_", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Vikram Ahuja", "active": true, "timeZone": "Etc/UTC"}, "body": "cc [~chinnaraol] , [~pkumarsinha] for your reference", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=vikramahuja_", "name": "vikramahuja_", "key": "vikramahuja_", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Vikram Ahuja", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-20T06:02:35.579+0000", "updated": "2025-02-20T06:02:35.579+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13609052/comment/17929335", "id": "17929335", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=vikramahuja_", "name": "vikramahuja_", "key": "vikramahuja_", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Vikram Ahuja", "active": true, "timeZone": "Etc/UTC"}, "body": "[~stevel@apache.org] , can i get some help regarding this?", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=vikramahuja_", "name": "vikramahuja_", "key": "vikramahuja_", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Vikram Ahuja", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-22T10:52:57.739+0000", "updated": "2025-02-22T10:52:57.739+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13609052/comment/17929826", "id": "17929826", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "don't go near HDFS' I'll only break things. Afraid you'll have to do more debugging yourself", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-02-24T15:49:22.877+0000", "updated": "2025-02-24T15:49:22.877+0000"}], "maxResults": 3, "total": 3, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/2", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg", "name": "Critical", "id": "2"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}