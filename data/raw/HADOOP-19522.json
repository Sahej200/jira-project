{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13613637", "self": "https://issues.apache.org/jira/rest/api/2/issue/13613637", "key": "HADOOP-19522", "fields": {"summary": "ABFS: [FnsOverBlob] Rename Recovery Should Succeed When Marker File Exists with Destination Directory", "description": "On the blob endpoint, since rename is not a direct operation but a combination of two operations\u2014copy and delete\u2014in the case of directory rename, we first rename all the blobs that have the source prefix and, at the end, rename the source to the destination.\r\n\r\nIn the normal rename flow, renaming is not allowed if the destination already exists. However, in the case of recovery, there is a possibility that some files have already been renamed from the source to the destination. With the recent change ([HADOOP-19474] ABFS: [FnsOverBlob] Listing Optimizations to avoid multiple iteration over list response. - ASF JIRA), where we create a marker if the path is implicit, rename recovery will fail at the end when it tries to rename the source to the destination after renaming all the files.\r\n\r\nTo fix this, while renaming the source to the destination, if we encounter an error indicating that the path already exists, we will suppress the error and mark the rename recovery as successful.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=bhattmanish98", "name": "bhattmanish98", "key": "JIRAUSER306911", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Manish Bhatt", "active": true, "timeZone": "Asia/Kolkata"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17939626", "id": "17939626", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 opened a new pull request, #7559:\nURL: https://github.com/apache/hadoop/pull/7559\n\n   JIRA: https://issues.apache.org/jira/browse/HADOOP-19522\r\n   On the blob endpoint, since rename is not a direct operation but a combination of two operations\u2014copy and delete\u2014in the case of directory rename, we first rename all the blobs that have the source prefix and, at the end, rename the source to the destination.\r\n   \r\n   In the normal rename flow, renaming is not allowed if the destination already exists. However, in the case of recovery, there is a possibility that some files have already been renamed from the source to the destination. With the recent change ([HADOOP-19474](https://issues.apache.org/jira/browse/HADOOP-19474) ABFS: [FnsOverBlob] Listing Optimizations to avoid multiple iteration over list response. - ASF JIRA), where we create a marker if the path is implicit, rename recovery will fail at the end when it tries to rename the source to the destination after renaming all the files.\r\n   \r\n   To fix this, while renaming the source to the destination, if we encounter an error indicating that the path already exists, we will suppress the error and mark the rename recovery as successful.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-31T10:13:14.037+0000", "updated": "2025-03-31T10:13:14.037+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17939670", "id": "17939670", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2766074619\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 47s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m  1s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 39s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 19s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 29s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/1/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 generated 1 new + 10 unchanged - 0 fixed = 11 total (was 10)  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/1/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06.txt) |  hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 generated 1 new + 10 unchanged - 0 fixed = 11 total (was 10)  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 33s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7559 |\r\n   | JIRA Issue | HADOOP-19522 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 2be4af61ef21 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 71ef4361d61b6a1e8e8bcd29e1d7a913dce4d519 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/1/testReport/ |\r\n   | Max. process+thread count | 591 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-31T12:28:10.606+0000", "updated": "2025-03-31T12:28:10.606+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17939944", "id": "17939944", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2768413476\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 53s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 2 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  42m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 59s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 137m 20s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7559 |\r\n   | JIRA Issue | HADOOP-19522 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 706e5d959e7a 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e5fbd0193cd0e9bdf083a29a2534c9b952308480 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/2/testReport/ |\r\n   | Max. process+thread count | 526 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-01T07:17:17.711+0000", "updated": "2025-04-01T07:17:17.711+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17940110", "id": "17940110", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2769701064\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 12s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 136m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7559 |\r\n   | JIRA Issue | HADOOP-19522 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux f7c9e740bda5 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c5b8d16e72cfcb2b6abd90d5705d7e6bb3b8acd9 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/3/testReport/ |\r\n   | Max. process+thread count | 585 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-01T15:10:22.858+0000", "updated": "2025-04-01T15:10:22.858+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17940248", "id": "17940248", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2771341803\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 803, Failures: 0, Errors: 0, Skipped: 162\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 806, Failures: 0, Errors: 0, Skipped: 116\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 645, Failures: 0, Errors: 0, Skipped: 217\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 803, Failures: 0, Errors: 0, Skipped: 169\r\n   [WARNING] Tests run: 131, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 648, Failures: 0, Errors: 0, Skipped: 144\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 642, Failures: 0, Errors: 0, Skipped: 218\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 645, Failures: 0, Errors: 0, Skipped: 145\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 643, Failures: 0, Errors: 0, Skipped: 163\r\n   [WARNING] Tests run: 131, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 677, Failures: 0, Errors: 0, Skipped: 165\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 642, Failures: 0, Errors: 0, Skipped: 216\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T04:57:40.575+0000", "updated": "2025-04-02T04:57:40.575+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17943179", "id": "17943179", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2037136377\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/BlobRenameHandler.java:\n##########\n@@ -192,6 +196,13 @@ private boolean finalSrcRename() throws AzureBlobFileSystemException {\n     tracingContext.setOperatedBlobCount(operatedBlobCount.get() + 1);\n     try {\n       return renameInternal(src, dst);\n+    } catch(AbfsRestOperationException e) {\n+      if (e.getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+        // If the destination path already exists, then delete the source path.\n+        getAbfsClient().deleteBlobPath(src, null, tracingContext);\n\nReview Comment:\n   Should we validate that destination has the same Etag as the source before assuming that if it already exists, it is safe to delete the source ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-10T11:30:40.404+0000", "updated": "2025-04-10T11:30:40.404+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17943181", "id": "17943181", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2037151847\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n\nReview Comment:\n   This function and the one below it, has a lot of common code, can be refactored into a common function \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-10T11:41:05.709+0000", "updated": "2025-04-10T11:41:05.709+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17944765", "id": "17944765", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2044886486\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/BlobRenameHandler.java:\n##########\n@@ -192,6 +196,13 @@ private boolean finalSrcRename() throws AzureBlobFileSystemException {\n     tracingContext.setOperatedBlobCount(operatedBlobCount.get() + 1);\n     try {\n       return renameInternal(src, dst);\n+    } catch(AbfsRestOperationException e) {\n+      if (e.getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+        // If the destination path already exists, then delete the source path.\n+        getAbfsClient().deleteBlobPath(src, null, tracingContext);\n\nReview Comment:\n   During recovery, if a marker is present in the destination directory, the destination etag is not linked to the source directory's etag (as it may or may not be created with source to dest copy operation). Therefore, comparing the source etag and destination etag may return false. Since we are not losing any data here, so I think it is safe to follow this process here.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-15T15:17:51.521+0000", "updated": "2025-04-15T15:17:51.521+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17944940", "id": "17944940", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2046130007\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n\nReview Comment:\n   Is there any reason for using getpathstatus instead of direct fs.exists(\"path\") here?\r\n   We could shorten it directly to \r\n       Assertions.assertThat(fs.exists(path)).isTrue(); else\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T05:51:46.514+0000", "updated": "2025-04-16T05:51:46.514+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17944949", "id": "17944949", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2046172508\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n\nReview Comment:\n   Code refactored\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T06:27:26.073+0000", "updated": "2025-04-16T06:27:26.073+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17944990", "id": "17944990", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2046357162\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n\nReview Comment:\n   fs.exists internally triggers rename recovery in case path is of source directory. We have separated the check for the existence of the path and then trigger rename recovery separately.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T08:13:35.299+0000", "updated": "2025-04-16T08:13:35.299+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945064", "id": "17945064", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2046854719\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n\nReview Comment:\n   We should move this method to `AbfsTestUtils` that way it can be used by other classes as well.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n\nReview Comment:\n   Also validate the path of json pending file here.\r\n   \n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n+          .describedAs(\"List should return 1 file\")\n+          .isEqualTo(1);\n+    } finally {\n+      if (fs != null) {\n+        fs.close();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with multiple child folders.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists, and multiple files are\n+   * created in the parent directory. It ensures that when listing the files in the parent directory,\n+   * the correct number of files is returned, including the pending rename JSON file.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithMultipleChildFolder() throws Exception {\n\nReview Comment:\n   Not able to get this...\r\n   Aren't we suppose to filter rename pending json files are trigger rename recovery?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n\nReview Comment:\n   Why we don't have validate for intermediate stage in this test?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n\nReview Comment:\n   Is it like always that in these validations source and jsonfile co-exists?\r\n   In case of crash both source and json pending file will be present always. May be we don't need separate parameters for them.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n+          .describedAs(\"List should return 1 file\")\n+          .isEqualTo(1);\n+    } finally {\n+      if (fs != null) {\n+        fs.close();\n\nReview Comment:\n   Do we need to close fs everytime?\r\n   This is spied fs of base class filesystem Base class file system closing will anyway happen?\r\n   Not sure if that is sufficient to close spied object as well or not. Can you please check?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T13:00:02.924+0000", "updated": "2025-04-16T13:00:02.924+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945086", "id": "17945086", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047072088\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n\nReview Comment:\n   Before rename starts, we have source dir but both json file and dest don't exist. So, it will be better keep both json and src status seperate. \n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n\nReview Comment:\n   Updated this.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n+          .describedAs(\"List should return 1 file\")\n+          .isEqualTo(1);\n+    } finally {\n+      if (fs != null) {\n+        fs.close();\n\nReview Comment:\n   It is not required to close the mocked object. I have removed it.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T14:31:27.815+0000", "updated": "2025-04-16T14:31:27.815+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945090", "id": "17945090", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047110190\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n\nReview Comment:\n   Makes sense. Are we validating that for any tests?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T14:49:22.656+0000", "updated": "2025-04-16T14:49:22.656+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945092", "id": "17945092", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047121683\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n+          .describedAs(\"List should return 1 file\")\n+          .isEqualTo(1);\n+    } finally {\n+      if (fs != null) {\n+        fs.close();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with multiple child folders.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists, and multiple files are\n+   * created in the parent directory. It ensures that when listing the files in the parent directory,\n+   * the correct number of files is returned, including the pending rename JSON file.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithMultipleChildFolder() throws Exception {\n\nReview Comment:\n   As per the discussion offline, need change in the comments here and other similar tests.\r\n   Along with assert on the number of files, can we also have assert on what all entries are there in list output and make sure renamePendingJson are not there.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T14:55:03.708+0000", "updated": "2025-04-16T14:55:03.708+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945093", "id": "17945093", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047122530\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n+          .describedAs(\"List should return 1 file\")\n+          .isEqualTo(1);\n+    } finally {\n+      if (fs != null) {\n+        fs.close();\n\nReview Comment:\n   Thanks for checking, this might need update in multiple test where fs close is happening.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T14:55:28.721+0000", "updated": "2025-04-16T14:55:28.721+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945094", "id": "17945094", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047123608\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n\nReview Comment:\n   As per the discussion, rename pending json path should not be there in list output. Assert on its absense\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T14:56:02.440+0000", "updated": "2025-04-16T14:56:02.440+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945102", "id": "17945102", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047146176\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n\nReview Comment:\n   Yes, for one test where dest exist before rename call, there we are using it.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T15:04:49.126+0000", "updated": "2025-04-16T15:04:49.126+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945112", "id": "17945112", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2047188036\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,860 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  private static final int TOTAL_THREADS_IN_POOL = 5;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AbfsBlobClient client, AtomicInteger copyCall)\n+      throws AzureBlobFileSystemException {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create files in the given directory.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for file creation.\n+   * @param src The source path (directory).\n+   * @param numFiles The number of files to create.\n+   * @throws ExecutionException, InterruptedException If an error occurs during file creation.\n+   */\n+  public static void createFiles(AzureBlobFileSystem fs, Path src, int numFiles)\n+      throws ExecutionException, InterruptedException {\n+    ExecutorService executorService = Executors.newFixedThreadPool(TOTAL_THREADS_IN_POOL);\n+    List<Future> futures = new ArrayList<>();\n+    for (int i = 0; i < numFiles; i++) {\n+      final int iter = i;\n+      Future future = executorService.submit(() ->\n+          fs.create(new Path(src, \"file\" + iter + \".txt\")));\n+      futures.add(future);\n+    }\n+    for (Future future : futures) {\n+      future.get();\n+    }\n+    executorService.shutdown();\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      copyCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate delete operation count\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      // Validate that rename redo operation was triggered\n+      deleteCall.set(0);\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(deleteCall.get())\n+          .describedAs(\"Delete operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      // Validate that delete redo operation was triggered\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Assertions to validate renamed destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // This will create marker file in the destination\n+      fs.exists(dst);\n+\n+      copyCall.set(0);\n+      // List Status on src, this will internally do rename recovery\n+      triggerRenameRecovery(fs, src);\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(client, copyCall);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should crash in between.\")\n+          .isFalse();\n+\n+      // Validate copy operation count\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be less than 10.\")\n+          .isLessThan(TOTAL_FILES);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, true, true, true);\n+\n+      copyCall.set(0);\n+      Assertions.assertThat(fs.rename(src, dst))\n+          .describedAs(\"Rename should succeed.\")\n+          .isTrue();\n+\n+      Assertions.assertThat(copyCall.get())\n+          .describedAs(\"Copy operation count should be greater than 0.\")\n+          .isGreaterThan(0);\n+\n+      // Validate final state of destination and source\n+      validateRename(fs, src, dst, false, true, false);\n+    }\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder (with the pending rename JSON file) is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    AzureBlobFileSystem fs = null;\n+    try {\n+      Path path = new Path(\"/hbase/A1/A2\");\n+      Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+      fs = createJsonFile(path, renameJson);\n+\n+      FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+      Assertions.assertThat(fileStatuses.length)\n+          .describedAs(\"List should return 1 file\")\n+          .isEqualTo(1);\n+    } finally {\n+      if (fs != null) {\n+        fs.close();\n\nReview Comment:\n   Yes, fixed at all the places.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-16T15:27:15.130+0000", "updated": "2025-04-16T15:27:15.130+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945261", "id": "17945261", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2812004367\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  41m 15s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 14s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  1s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 136m 45s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7559 |\r\n   | JIRA Issue | HADOOP-19522 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 183040e5fc09 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / af66bd895956a6c5ec26fa44bdaf3eda6bb4ad2f |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/4/testReport/ |\r\n   | Max. process+thread count | 524 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T07:09:27.530+0000", "updated": "2025-04-17T07:09:27.530+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945311", "id": "17945311", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2812302940\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 22s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 13s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 21s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7559 |\r\n   | JIRA Issue | HADOOP-19522 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 3cb968c9ccb8 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 4a1b1152bd4b4b54cb76429578dec9ab778b9e36 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/5/testReport/ |\r\n   | Max. process+thread count | 524 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T09:26:08.872+0000", "updated": "2025-04-17T09:26:08.872+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945344", "id": "17945344", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2048768205\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n\nReview Comment:\n   One general suggestion is to move all he helper methods (private methods in this class) together towards the end of file and keep all @Test methods sequentially one after the other for better readability.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to assert that the pending JSON file does not exist\n+   * and that the list of file statuses does not contain the rename pending JSON file.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param renameJson The path of the rename pending JSON file.\n+   * @param fileStatuses The array of FileStatus objects to check.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPendingJsonFile(AzureBlobFileSystem fs,\n+      Path renameJson, FileStatus[] fileStatuses) throws Exception {\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should not exist.\")\n+        .isFalse();\n+    Assertions.assertThat(\n+            Arrays.stream(fileStatuses)\n+                .anyMatch(status ->\n+                    renameJson.toUri().getPath()\n+                        .equals(status.getPath().toUri().getPath())))\n+        .describedAs(\"Directory with suffix -RenamePending.json should exist.\")\n+        .isFalse();\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    Path path = new Path(\"/hbase/A1/A2\");\n+    Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+    AzureBlobFileSystem fs = createJsonFile(path, renameJson);\n+\n+    FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+    Assertions.assertThat(fileStatuses.length)\n+        .describedAs(\"List should return 0 file\")\n+        .isEqualTo(0);\n+    assertPendingJsonFile(fs, renameJson, fileStatuses);\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with multiple child folders.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists, and multiple files are\n+   * created in the parent directory. It ensures that when listing the files in the parent directory,\n+   * the correct number of files is returned.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithMultipleChildFolder() throws Exception {\n+    Path path = new Path(\"/hbase/A1/A2\");\n+    Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+    AzureBlobFileSystem fs = createJsonFile(path, renameJson);\n+\n+    fs.create(new Path(\"/hbase/A1/file1.txt\"));\n+    fs.create(new Path(\"/hbase/A1/file2.txt\"));\n+\n+    FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+    Assertions.assertThat(fileStatuses.length)\n+        .describedAs(\"List should return 2 files\")\n+        .isEqualTo(2);\n+    Assertions.assertThat(\n\nReview Comment:\n   NIT: This is the assert we can move inside `assertPendingJsonFile` method\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to assert that the pending JSON file does not exist\n+   * and that the list of file statuses does not contain the rename pending JSON file.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param renameJson The path of the rename pending JSON file.\n+   * @param fileStatuses The array of FileStatus objects to check.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPendingJsonFile(AzureBlobFileSystem fs,\n+      Path renameJson, FileStatus[] fileStatuses) throws Exception {\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should not exist.\")\n+        .isFalse();\n+    Assertions.assertThat(\n+            Arrays.stream(fileStatuses)\n+                .anyMatch(status ->\n+                    renameJson.toUri().getPath()\n+                        .equals(status.getPath().toUri().getPath())))\n+        .describedAs(\"Directory with suffix -RenamePending.json should exist.\")\n\nReview Comment:\n   Assertion message should be `Directory with suffix -RenamePending.json should not exist.`\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n\nReview Comment:\n   Do we need to assert on existence of src/dest/json after rename crash?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to assert that the pending JSON file does not exist\n+   * and that the list of file statuses does not contain the rename pending JSON file.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param renameJson The path of the rename pending JSON file.\n+   * @param fileStatuses The array of FileStatus objects to check.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPendingJsonFile(AzureBlobFileSystem fs,\n+      Path renameJson, FileStatus[] fileStatuses) throws Exception {\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should not exist.\")\n+        .isFalse();\n+    Assertions.assertThat(\n+            Arrays.stream(fileStatuses)\n+                .anyMatch(status ->\n+                    renameJson.toUri().getPath()\n+                        .equals(status.getPath().toUri().getPath())))\n+        .describedAs(\"Directory with suffix -RenamePending.json should exist.\")\n\nReview Comment:\n   In this method, can we only assert that the list output does not have a source directory?\r\n   That we it will be in common place\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T11:39:49.699+0000", "updated": "2025-04-17T11:39:49.699+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945373", "id": "17945373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2048896653\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n\nReview Comment:\n   Moved all helper methods to the end of the file in both test files\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T13:04:31.631+0000", "updated": "2025-04-17T13:04:31.631+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945375", "id": "17945375", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2048898764\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n\nReview Comment:\n   We are already doing it inside this method.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T13:05:56.322+0000", "updated": "2025-04-17T13:05:56.322+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945382", "id": "17945382", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2048908242\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to assert that the pending JSON file does not exist\n+   * and that the list of file statuses does not contain the rename pending JSON file.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param renameJson The path of the rename pending JSON file.\n+   * @param fileStatuses The array of FileStatus objects to check.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPendingJsonFile(AzureBlobFileSystem fs,\n+      Path renameJson, FileStatus[] fileStatuses) throws Exception {\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should not exist.\")\n+        .isFalse();\n+    Assertions.assertThat(\n+            Arrays.stream(fileStatuses)\n+                .anyMatch(status ->\n+                    renameJson.toUri().getPath()\n+                        .equals(status.getPath().toUri().getPath())))\n+        .describedAs(\"Directory with suffix -RenamePending.json should exist.\")\n\nReview Comment:\n   Added source path check as well.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T13:09:58.150+0000", "updated": "2025-04-17T13:09:58.150+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945383", "id": "17945383", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#discussion_r2048908970\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRenameRecovery.java:\n##########\n@@ -0,0 +1,763 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.FSOperationType;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n+import org.apache.hadoop.fs.azurebfs.services.RenameAtomicity;\n+import org.apache.hadoop.fs.azurebfs.services.VersionedFileStatus;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingContext;\n+import org.apache.hadoop.fs.azurebfs.utils.TracingHeaderFormat;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+\n+import static java.net.HttpURLConnection.HTTP_OK;\n+import static org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants.ROOT_PATH;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_CONSUMER_MAX_LAG;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_PRODUCER_QUEUE_MAX_SIZE;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_ALREADY_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.BLOB_PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode.PATH_NOT_FOUND;\n+import static org.apache.hadoop.fs.azurebfs.services.RenameAtomicity.SUFFIX;\n+import static org.apache.hadoop.fs.azurebfs.utils.AbfsTestUtils.createFiles;\n+import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n+\n+/**\n+ * Test rename recovery operation.\n+ */\n+public class ITestAzureBlobFileSystemRenameRecovery extends\n+    AbstractAbfsIntegrationTest {\n+\n+  private static final int FAILED_CALL = 15;\n+\n+  private static final int TOTAL_FILES = 25;\n+\n+  public ITestAzureBlobFileSystemRenameRecovery() throws Exception {\n+    super();\n+  }\n+\n+  /**\n+   * Triggers rename recovery by calling getPathStatus on the source path.\n+   * This simulates a scenario where the rename operation was interrupted,\n+   * and the system needs to recover the state of the source path.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to trigger recovery on.\n+   * @throws Exception If an error occurs during the recovery process.\n+   */\n+  private void triggerRenameRecovery(AzureBlobFileSystem fs, Path src) throws Exception {\n+    // Trigger rename recovery\n+    TracingContext tracingContext = new TracingContext(\n+        getConfiguration().getClientCorrelationId(), fs.getFileSystemId(),\n+        FSOperationType.GET_FILESTATUS, TracingHeaderFormat.ALL_ID_FORMAT, null);\n+    AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+        AbfsRestOperationException.class, () -> {\n+          fs.getAbfsStore().getClient().getPathStatus(src.toUri().getPath(), true,\n+              tracingContext, null);\n+        }).getErrorCode();\n+    Assertions.assertThat(errorCode)\n+        .describedAs(\"Path had to be recovered from atomic rename operation.\")\n+        .isEqualTo(PATH_NOT_FOUND);\n+  }\n+\n+  /**\n+   * Simulates a failure during the rename operation by throwing an exception\n+   * when the copyBlob method is called. This is used to test the behavior of\n+   * the rename recovery operation when a blob already exists at the destination.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param src The source path to rename.\n+   * @param dst The destination path for the rename operation.\n+   * @param client The AbfsBlobClient instance.\n+   * @param copyCall The AtomicInteger to track the number of copy calls.\n+   * @throws AzureBlobFileSystemException If an error occurs during the operation.\n+   */\n+  private void renameCrashInBetween(AzureBlobFileSystem fs, Path src, Path dst,\n+      AbfsBlobClient client, AtomicInteger copyCall)\n+      throws Exception {\n+    Mockito.doAnswer(copyRequest -> {\n+      if (copyCall.get() == FAILED_CALL) {\n+        throw new AbfsRestOperationException(\n+            BLOB_ALREADY_EXISTS.getStatusCode(),\n+            BLOB_ALREADY_EXISTS.getErrorCode(),\n+            BLOB_ALREADY_EXISTS.getErrorMessage(),\n+            new Exception());\n+      }\n+      copyCall.incrementAndGet();\n+      return copyRequest.callRealMethod();\n+    }).when(client).copyBlob(Mockito.any(Path.class),\n+        Mockito.any(Path.class), Mockito.nullable(String.class),\n+        Mockito.any(TracingContext.class));\n+    renameOperationWithRecovery(fs, src, dst, copyCall);\n+  }\n+\n+  /**\n+   * Helper method to create the configuration for the AzureBlobFileSystem.\n+   *\n+   * @return The configuration object.\n+   */\n+  private Configuration getConfig() {\n+    Configuration config = new Configuration(this.getRawConfiguration());\n+    config.set(FS_AZURE_PRODUCER_QUEUE_MAX_SIZE, \"5\");\n+    config.set(FS_AZURE_CONSUMER_MAX_LAG, \"3\");\n+    config.set(FS_AZURE_BLOB_DIR_RENAME_MAX_THREAD, \"2\");\n+    return config;\n+  }\n+\n+  /**\n+   * Spies on the AzureBlobFileSystem's store and client to enable mocking and verification\n+   * of client interactions in tests. It replaces the actual store and client with mocked versions.\n+   *\n+   * @param fs the AzureBlobFileSystem instance\n+   * @return the spied AbfsClient for interaction verification\n+   */\n+  private AbfsClient addSpyHooksOnClient(final AzureBlobFileSystem fs) {\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+    return client;\n+  }\n+\n+  /**\n+   * Helper method to validate that the rename was successful and that the destination exists.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param dst The destination path.\n+   * @param src The source path.\n+   * @throws IOException If an I/O error occurs during the validation.\n+   */\n+  private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n+      boolean isSrcExist, boolean isDstExist, boolean isJsonExist) throws Exception {\n+    // Validate pending JSON file status\n+    assertPathStatus(fs,\n+        new Path(src.getParent(), src.getName() + SUFFIX), isJsonExist,\n+        \"Pending JSON file\");\n+\n+    // Validate source directory status\n+    assertPathStatus(fs, src, isSrcExist, \"Source directory\");\n+\n+    // Validate destination directory status\n+    assertPathStatus(fs, dst, isDstExist, \"Destination directory\");\n+  }\n+\n+  /**\n+   * Helper method to assert the status of a path in the AzureBlobFileSystem.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to check the existence on.\n+   * @param path The path to check.\n+   * @param shouldExist Whether the path should exist or not.\n+   * @param description A description for the assertion.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPathStatus(AzureBlobFileSystem fs, Path path,\n+      boolean shouldExist, String description) throws Exception{\n+    TracingContext tracingContext = getTestTracingContext(fs, true);\n+    AbfsBlobClient client = ((AbfsBlobClient) fs.getAbfsClient());\n+    if (shouldExist) {\n+      int actualStatus = client.getPathStatus(\n+              path.toUri().getPath(), tracingContext,\n+              null, true)\n+          .getResult().getStatusCode();\n+      Assertions.assertThat(actualStatus)\n+          .describedAs(\"%s should exists\", description)\n+          .isEqualTo(HTTP_OK);\n+    } else {\n+      AzureServiceErrorCode errorCode = LambdaTestUtils.intercept(\n+          AbfsRestOperationException.class, () -> {\n+            client.getPathStatus(path.toUri().getPath(), true,\n+                tracingContext, null);\n+          }).getErrorCode();\n+      Assertions.assertThat(errorCode)\n+          .describedAs(\"%s should not exists\", description)\n+          .isEqualTo(BLOB_PATH_NOT_FOUND);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to create a json file.\n+   * @param path parent path\n+   * @param renameJson rename json path\n+   * @return file system\n+   * @throws IOException in case of failure\n+   */\n+  private AzureBlobFileSystem createJsonFile(Path path, Path renameJson)\n+      throws IOException {\n+    final AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem());\n+    assumeBlobServiceType();\n+    AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+    Mockito.doReturn(store).when(fs).getAbfsStore();\n+    AbfsClient client = Mockito.spy(store.getClient());\n+    Mockito.doReturn(client).when(store).getClient();\n+\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    fs.create(new Path(path, \"file.txt\"));\n+\n+    VersionedFileStatus fileStatus\n+        = (VersionedFileStatus) fs.getFileStatus(path);\n+\n+    new RenameAtomicity(path, new Path(\"/hbase/test4\"),\n+        renameJson, getTestTracingContext(fs, true),\n+        fileStatus.getEtag(), client)\n+        .preRename();\n+\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should exist.\")\n+        .isTrue();\n+\n+    return fs;\n+  }\n+\n+  /**\n+   * Helper method to perform the rename operation and validate the results.\n+   *\n+   * @param fs The AzureBlobFileSystem instance to use for the rename operation.\n+   * @param src The source path (directory).\n+   * @param dst The destination path (directory).\n+   * @param countCall The AtomicInteger to track the number of operations.\n+   * @throws Exception If an error occurs during the rename operation.\n+   */\n+  private void renameOperationWithRecovery(AzureBlobFileSystem fs, Path src,\n+      Path dst, AtomicInteger countCall) throws Exception {\n+    Assertions.assertThat(fs.rename(src, dst))\n+        .describedAs(\"Rename should crash in between.\")\n+        .isFalse();\n+\n+    // Validate copy operation count\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be less than 10.\")\n+        .isLessThan(TOTAL_FILES);\n+\n+    // Assertions to validate renamed destination and source\n+    validateRename(fs, src, dst, true, true, true);\n+\n+    // Validate that rename redo operation was triggered\n+    countCall.set(0);\n+    triggerRenameRecovery(fs, src);\n+\n+    Assertions.assertThat(countCall.get())\n+        .describedAs(\"Operation count should be greater than 0.\")\n+        .isGreaterThan(0);\n+\n+    // Validate final state of destination and source\n+    validateRename(fs, src, dst, false, true, false);\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameCopyFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the delete operation.\n+   * Simulates an error on the 6th delete operation and verifies the behavior.\n+   */\n+  @Test\n+  public void testRenameDeleteFailureInBetween() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of delete operations\n+      AtomicInteger deleteCall = new AtomicInteger(0);\n+      Mockito.doAnswer(deleteRequest -> {\n+        if (deleteCall.get() == FAILED_CALL) {\n+          throw new AbfsRestOperationException(\n+              BLOB_PATH_NOT_FOUND.getStatusCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorCode(),\n+              BLOB_PATH_NOT_FOUND.getErrorMessage(),\n+              new Exception());\n+        }\n+        deleteCall.incrementAndGet();\n+        return deleteRequest.callRealMethod();\n+      }).when(client).deleteBlobPath(Mockito.any(Path.class),\n+          Mockito.anyString(), Mockito.any(TracingContext.class));\n+\n+      renameOperationWithRecovery(fs, src, dst, deleteCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWhenDestAlreadyExist() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+      // Create the destination directory\n+      fs.mkdirs(dst);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      // Assertions to validate source and dest status before rename\n+      validateRename(fs, src, dst, true, true, false);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Tests renaming a directory with a failure during the copy operation.\n+   * Since, destination path already exists, there will be adjustment in the\n+   * destination path. After crash recovery, recovery should succeed even in the\n+   * case when destination path already exists.\n+   * Simulates an error when copying on the 6th call.\n+   */\n+  @Test\n+  public void testRenameRecoveryWithMarkerPresentInDest() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Test to check behaviour when rename is called on a atomic rename directory\n+   * for which rename pending json file is already present.\n+   * @throws Exception in case of failure\n+   */\n+  @Test\n+  public void testRenameWhenAlreadyRenamePendingJsonFilePresent() throws Exception {\n+    try (AzureBlobFileSystem fs = Mockito.spy(this.getFileSystem(getConfig()))) {\n+      assumeBlobServiceType();\n+      AbfsBlobClient client = (AbfsBlobClient) addSpyHooksOnClient(fs);\n+      fs.getAbfsStore().setClient(client);\n+      Path src = new Path(\"/hbase/A1/A2\");\n+      Path dst = new Path(\"/hbase/A1/A3\");\n+\n+      // Create sample files in the source directory\n+      createFiles(fs, src, TOTAL_FILES);\n+\n+      // Track the number of copy operations\n+      AtomicInteger copyCall = new AtomicInteger(0);\n+      renameCrashInBetween(fs, src, dst, client, copyCall);\n+    }\n+  }\n+\n+  /**\n+   * Helper method to assert that the pending JSON file does not exist\n+   * and that the list of file statuses does not contain the rename pending JSON file.\n+   *\n+   * @param fs The AzureBlobFileSystem instance.\n+   * @param renameJson The path of the rename pending JSON file.\n+   * @param fileStatuses The array of FileStatus objects to check.\n+   * @throws Exception If an error occurs during the assertion.\n+   */\n+  private void assertPendingJsonFile(AzureBlobFileSystem fs,\n+      Path renameJson, FileStatus[] fileStatuses) throws Exception {\n+    Assertions.assertThat(fs.exists(renameJson))\n+        .describedAs(\"Rename Pending Json file should not exist.\")\n+        .isFalse();\n+    Assertions.assertThat(\n+            Arrays.stream(fileStatuses)\n+                .anyMatch(status ->\n+                    renameJson.toUri().getPath()\n+                        .equals(status.getPath().toUri().getPath())))\n+        .describedAs(\"Directory with suffix -RenamePending.json should exist.\")\n+        .isFalse();\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with a single child folder.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists for a single child folder\n+   * under the parent directory. It ensures that when listing the files in the parent directory,\n+   * only the child folder is returned, and no additional files are listed.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithSingleChildFolder() throws Exception {\n+    Path path = new Path(\"/hbase/A1/A2\");\n+    Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+    AzureBlobFileSystem fs = createJsonFile(path, renameJson);\n+\n+    FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+    Assertions.assertThat(fileStatuses.length)\n+        .describedAs(\"List should return 0 file\")\n+        .isEqualTo(0);\n+    assertPendingJsonFile(fs, renameJson, fileStatuses);\n+  }\n+\n+  /**\n+   * Test case to verify crash recovery with multiple child folders.\n+   *\n+   * This test simulates a scenario where a pending rename JSON file exists, and multiple files are\n+   * created in the parent directory. It ensures that when listing the files in the parent directory,\n+   * the correct number of files is returned.\n+   *\n+   * @throws Exception if any error occurs during the test execution\n+   */\n+  @Test\n+  public void testListCrashRecoveryWithMultipleChildFolder() throws Exception {\n+    Path path = new Path(\"/hbase/A1/A2\");\n+    Path renameJson = new Path(path.getParent(), path.getName() + SUFFIX);\n+    AzureBlobFileSystem fs = createJsonFile(path, renameJson);\n+\n+    fs.create(new Path(\"/hbase/A1/file1.txt\"));\n+    fs.create(new Path(\"/hbase/A1/file2.txt\"));\n+\n+    FileStatus[] fileStatuses = fs.listStatus(new Path(\"/hbase/A1\"));\n+\n+    Assertions.assertThat(fileStatuses.length)\n+        .describedAs(\"List should return 2 files\")\n+        .isEqualTo(2);\n+    Assertions.assertThat(\n\nReview Comment:\n   Moved to assertPendingJsonFile.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T13:10:28.165+0000", "updated": "2025-04-17T13:10:28.165+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945462", "id": "17945462", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2813582853\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   1m  5s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 37s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  43m 44s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  44m  7s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m  0s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  1s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 140m  3s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.49 ServerAPI=1.49 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7559 |\r\n   | JIRA Issue | HADOOP-19522 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 91ba230fb55e 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / aa971588aa17b3f89ff3a167e61ec6fa6097eb64 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/7/testReport/ |\r\n   | Max. process+thread count | 585 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7559/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-17T17:10:55.789+0000", "updated": "2025-04-17T17:10:55.789+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945580", "id": "17945580", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559#issuecomment-2814508173\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 808, Failures: 0, Errors: 0, Skipped: 160\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 6\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 811, Failures: 0, Errors: 0, Skipped: 113\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 6\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 650, Failures: 0, Errors: 0, Skipped: 218\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 7\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 808, Failures: 0, Errors: 0, Skipped: 171\r\n   [WARNING] Tests run: 133, Failures: 0, Errors: 0, Skipped: 7\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 653, Failures: 0, Errors: 0, Skipped: 141\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 647, Failures: 0, Errors: 0, Skipped: 220\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 7\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 650, Failures: 0, Errors: 0, Skipped: 143\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 648, Failures: 0, Errors: 0, Skipped: 161\r\n   [WARNING] Tests run: 133, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 682, Failures: 0, Errors: 0, Skipped: 167\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 6\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 647, Failures: 0, Errors: 0, Skipped: 218\r\n   [WARNING] Tests run: 156, Failures: 0, Errors: 0, Skipped: 7\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-18T04:25:22.867+0000", "updated": "2025-04-18T04:25:22.867+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945641", "id": "17945641", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7559:\nURL: https://github.com/apache/hadoop/pull/7559\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-18T09:51:54.686+0000", "updated": "2025-04-18T09:51:54.686+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945642", "id": "17945642", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 opened a new pull request, #7633:\nURL: https://github.com/apache/hadoop/pull/7633\n\n   JIRA: https://issues.apache.org/jira/browse/HADOOP-19522\r\n   -----------------------------------------------------------------------\r\n   On the blob endpoint, since rename is not a direct operation but a combination of two operations\u2014copy and delete\u2014in the case of directory rename, we first rename all the blobs that have the source prefix and, at the end, rename the source to the destination.\r\n   \r\n   In the normal rename flow, renaming is not allowed if the destination already exists. However, in the case of recovery, there is a possibility that some files have already been renamed from the source to the destination. With the recent change ([HADOOP-19474](https://issues.apache.org/jira/browse/HADOOP-19474) ABFS: [FnsOverBlob] Listing Optimizations to avoid multiple iteration over list response. - ASF JIRA), where we create a marker if the path is implicit, rename recovery will fail at the end when it tries to rename the source to the destination after renaming all the files.\r\n   \r\n   To fix this, while renaming the source to the destination, if we encounter an error indicating that the path already exists, we will suppress the error and mark the rename recovery as successful.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-18T10:00:23.511+0000", "updated": "2025-04-18T10:00:23.511+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945669", "id": "17945669", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7633:\nURL: https://github.com/apache/hadoop/pull/7633#issuecomment-2815352768\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  18m 35s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 4 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 23s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 30s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 35s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 22s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 37s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 146m 40s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.49 ServerAPI=1.49 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7633/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7633 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 981d9eac63ca 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / 9eb1037cfc00320dc79b819e336d61b7cb6ecdcc |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7633/1/testReport/ |\r\n   | Max. process+thread count | 584 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7633/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-18T12:28:18.991+0000", "updated": "2025-04-18T12:28:18.991+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945712", "id": "17945712", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7633:\nURL: https://github.com/apache/hadoop/pull/7633#issuecomment-2815698118\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 820, Failures: 0, Errors: 0, Skipped: 172\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 31\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 820, Failures: 0, Errors: 0, Skipped: 122\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 31\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 804, Failures: 0, Errors: 0, Skipped: 375\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 32\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 820, Failures: 0, Errors: 0, Skipped: 183\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 55\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 804, Failures: 0, Errors: 0, Skipped: 295\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 804, Failures: 0, Errors: 0, Skipped: 380\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 32\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 804, Failures: 0, Errors: 0, Skipped: 300\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 804, Failures: 0, Errors: 0, Skipped: 320\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 51\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 820, Failures: 0, Errors: 0, Skipped: 305\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 31\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 175, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 804, Failures: 0, Errors: 0, Skipped: 378\r\n   [WARNING] Tests run: 181, Failures: 0, Errors: 0, Skipped: 32\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-18T16:00:40.297+0000", "updated": "2025-04-18T16:00:40.297+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13613637/comment/17945713", "id": "17945713", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7633:\nURL: https://github.com/apache/hadoop/pull/7633\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-18T16:01:39.192+0000", "updated": "2025-04-18T16:01:39.192+0000"}], "maxResults": 33, "total": 33, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/1", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg", "name": "Blocker", "id": "1"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}