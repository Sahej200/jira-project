{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13618000", "self": "https://issues.apache.org/jira/rest/api/2/issue/13618000", "key": "HADOOP-19567", "fields": {"summary": "S3A: error stack traces printed on analytics stream factory close", "description": "When you close an s3a filesystem there is a lot of ERROR level stack traces about a CancellationException -despite that being exactly what is wanted.\r\n\r\nCore of it comes from netty.\r\n{code}\r\n        Suppressed: software.amazon.awssdk.core.exception.SdkClientException: Request attempt 1 failure: Unable to execute HTTP request: The connection was closed during the request. The request will usually succeed on a retry, but if it does not: consider disabling any proxies you have configured, enabling debug logging, or performing a TCP dump to identify the root cause. If this is a streaming operation, validate that data is being read or written in a timely manner. Channel Information: ChannelDiagnostics(channel=[id: 0x801baead, L:0.0.0.0/0.0.0.0:59534 ! R:bucket.vpce-0117f6033eaf7aee5-2hxd9fg4.s3.us-west-2.vpce.amazonaws.com/10.80.134.179:443], channelAge=PT0.676S, requestCount=1, responseCount=0, lastIdleDuration=PT0.006284125S)\r\nCaused by: java.lang.IllegalStateException: executor not accepting a task\r\n{code}\r\n", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13618000/comment/17951228", "id": "17951228", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "Full log. me trying to do minimal bandwidth test and calling control-c mid download.\r\n\r\nI don't mind the noise as much as the way the cancellation exception was escalated to become the failure cause.\r\n{code}\r\n2025-05-13 17:09:16,705 [main] INFO  util.ExitUtil (ExitUtil.java:terminate(241)) - Exiting with status -1: java.util.concurrent.CancellationException\r\n{code}\r\n\r\nProposed: service stop code in {{AnalyticsStreamFactory}} to catch and swallow those. \r\n\r\n{code}\r\n> bin/hadoop jar $CLOUDSTORE bandwidth -csv out.csv 1M s3a://stevel-usw2/bw\r\n\r\nBandwidth test against s3a://stevel-usw2/bw with data size 1m\r\n=============================================================\r\n\r\nBlock size 1 MB\r\nSaving statistics as CSV data to out.csv\r\nUsing filesystem s3a://stevel-usw2\r\nUpload size in Megabytes 1 MB\r\nWriting data as 1 blocks each of size 1,048,576 bytes\r\nStarting: Opening s3a://stevel-usw2/bw for upload\r\nDuration of Opening s3a://stevel-usw2/bw for upload: 0:00:00.018\r\nWrite block 0 in 0.015 seconds\r\n\r\nStarting: upload stream close()\r\nDuration of upload stream close(): 0:00:03.793\r\n\r\nProgress callbacks 4; in close 4\r\n\r\nDownload s3a://stevel-usw2/bw\r\n=============================\r\n\r\nStarting: open s3a://stevel-usw2/bw\r\n^C2025-05-13 17:09:16,700 [shutdown-hook-0] INFO  s3a.S3AFileSystem (S3AFileSystem.java:processDeleteOnExit(4331)) - Ignoring failure to deleteOnExit for path s3a://stevel-usw2/bw\r\n2025-05-13 17:09:16,702 [s3a-transfer-stevel-usw2-unbounded-pool2-t1] ERROR s3.telemetry (LogHelper.java:logAtLevel(38)) - [2025-05-13T17:09:15.996Z] [failure] [6lu5cof10v8ch] metadata.store.head.join(thread_id=30, uri=s3://stevel-usw2/bw): 705,819,458 ns [java.util.concurrent.CancellationException: 'null']\r\njava.util.concurrent.CancellationException\r\n        at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2276)\r\n        at software.amazon.s3.analyticsaccelerator.io.physical.data.MetadataStore.safeCancel(MetadataStore.java:147)\r\n        at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608)\r\n        at java.util.Collections$SynchronizedCollection.forEach(Collections.java:2064)\r\n        at software.amazon.s3.analyticsaccelerator.io.physical.data.MetadataStore.close(MetadataStore.java:157)\r\n        at software.amazon.s3.analyticsaccelerator.S3SeekableInputStreamFactory.close(S3SeekableInputStreamFactory.java:162)\r\n        at org.apache.hadoop.util.functional.LazyAutoCloseableReference.close(LazyAutoCloseableReference.java:82)\r\n        at org.apache.hadoop.fs.s3a.impl.streams.AnalyticsStreamFactory.serviceStop(AnalyticsStreamFactory.java:101)\r\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\r\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:53)\r\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:102)\r\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:160)\r\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:134)\r\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\r\n        at org.apache.hadoop.service.AbstractService.close(AbstractService.java:248)\r\n        at org.apache.hadoop.fs.s3a.S3AUtils.closeAutocloseables(S3AUtils.java:1567)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$stopAllServices$24(S3AFileSystem.java:4375)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:547)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:528)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:449)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.stopAllServices(S3AFileSystem.java:4374)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.close(S3AFileSystem.java:4354)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:3820)\r\n        at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:3837)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n2025-05-13 17:09:16,702 [shutdown-hook-0] ERROR s3.telemetry (LogHelper.java:logAtLevel(38)) - [2025-05-13T17:09:15.995Z] [failure] [272un7pgiak2a] metadata.store.head.async(thread_id=30, uri=s3://stevel-usw2/bw): 706,204,250 ns [java.util.concurrent.CancellationException: 'null']\r\njava.util.concurrent.CancellationException\r\n        at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2276)\r\n        at software.amazon.s3.analyticsaccelerator.io.physical.data.MetadataStore.safeCancel(MetadataStore.java:147)\r\n        at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608)\r\n        at java.util.Collections$SynchronizedCollection.forEach(Collections.java:2064)\r\n        at software.amazon.s3.analyticsaccelerator.io.physical.data.MetadataStore.close(MetadataStore.java:157)\r\n        at software.amazon.s3.analyticsaccelerator.S3SeekableInputStreamFactory.close(S3SeekableInputStreamFactory.java:162)\r\n        at org.apache.hadoop.util.functional.LazyAutoCloseableReference.close(LazyAutoCloseableReference.java:82)\r\n        at org.apache.hadoop.fs.s3a.impl.streams.AnalyticsStreamFactory.serviceStop(AnalyticsStreamFactory.java:101)\r\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\r\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:53)\r\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:102)\r\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:160)\r\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:134)\r\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\r\n        at org.apache.hadoop.service.AbstractService.close(AbstractService.java:248)\r\n        at org.apache.hadoop.fs.s3a.S3AUtils.closeAutocloseables(S3AUtils.java:1567)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$stopAllServices$24(S3AFileSystem.java:4375)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:547)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:528)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:449)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.stopAllServices(S3AFileSystem.java:4374)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.close(S3AFileSystem.java:4354)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:3820)\r\n        at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:3837)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\njava.util.concurrent.CancellationException\r\n        at java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2276)\r\n        at software.amazon.s3.analyticsaccelerator.io.physical.data.MetadataStore.safeCancel(MetadataStore.java:147)\r\n        at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608)\r\n        at java.util.Collections$SynchronizedCollection.forEach(Collections.java:2064)\r\n        at software.amazon.s3.analyticsaccelerator.io.physical.data.MetadataStore.close(MetadataStore.java:157)\r\n        at software.amazon.s3.analyticsaccelerator.S3SeekableInputStreamFactory.close(S3SeekableInputStreamFactory.java:162)\r\n        at org.apache.hadoop.util.functional.LazyAutoCloseableReference.close(LazyAutoCloseableReference.java:82)\r\n        at org.apache.hadoop.fs.s3a.impl.streams.AnalyticsStreamFactory.serviceStop(AnalyticsStreamFactory.java:101)\r\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\r\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:53)\r\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:102)\r\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:160)\r\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:134)\r\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\r\n        at org.apache.hadoop.service.AbstractService.close(AbstractService.java:248)\r\n        at org.apache.hadoop.fs.s3a.S3AUtils.closeAutocloseables(S3AUtils.java:1567)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$stopAllServices$24(S3AFileSystem.java:4375)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:547)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:528)\r\n        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:449)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.stopAllServices(S3AFileSystem.java:4374)\r\n        at org.apache.hadoop.fs.s3a.S3AFileSystem.close(S3AFileSystem.java:4354)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:3820)\r\n        at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:3837)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\n2025-05-13 17:09:16,705 [main] INFO  util.ExitUtil (ExitUtil.java:terminate(241)) - Exiting with status -1: java.util.concurrent.CancellationException\r\n2025-05-13 17:09:17,429 [sdk-async-response-2-1] ERROR s3.telemetry (LogHelper.java:logAtLevel(38)) - [2025-05-13T17:09:15.993Z] [failure] [-38acq15b21262] s3.client.head(thread_id=30, uri=s3://stevel-usw2/bw): 1,435,559,459 ns [java.util.concurrent.CompletionException: 'software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: executor not accepting a task']\r\njava.util.concurrent.CompletionException: software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: executor not accepting a task\r\n        at software.amazon.awssdk.utils.CompletableFutureUtils.errorAsCompletionException(CompletableFutureUtils.java:64)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncExecutionFailureExceptionReportingStage.lambda$execute$0(AsyncExecutionFailureExceptionReportingStage.java:51)\r\n        at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:836)\r\n        at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:811)\r\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)\r\n        at software.amazon.awssdk.utils.CompletableFutureUtils.lambda$forwardExceptionTo$0(CompletableFutureUtils.java:78)\r\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\r\n        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\r\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage2$RetryingExecutor.maybeAttemptExecute(AsyncRetryableStage2.java:135)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage2$RetryingExecutor.maybeRetryExecute(AsyncRetryableStage2.java:152)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage2$RetryingExecutor.lambda$attemptExecute$1(AsyncRetryableStage2.java:113)\r\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\r\n        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\r\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)\r\n        at software.amazon.awssdk.utils.CompletableFutureUtils.lambda$forwardExceptionTo$0(CompletableFutureUtils.java:78)\r\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\r\n        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\r\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.MakeAsyncHttpRequestStage.lambda$execute$0(MakeAsyncHttpRequestStage.java:108)\r\n        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\r\n        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\r\n        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.MakeAsyncHttpRequestStage.completeResponseFuture(MakeAsyncHttpRequestStage.java:255)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.MakeAsyncHttpRequestStage.lambda$executeHttpRequest$3(MakeAsyncHttpRequestStage.java:167)\r\n        at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:836)\r\n        at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:811)\r\n        at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:750)\r\nCaused by: software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: executor not accepting a task\r\n        at software.amazon.awssdk.core.exception.SdkClientException$BuilderImpl.build(SdkClientException.java:111)\r\n        at software.amazon.awssdk.core.exception.SdkClientException.create(SdkClientException.java:47)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.utils.RetryableStageHelper2.setLastException(RetryableStageHelper2.java:226)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.utils.RetryableStageHelper2.setLastException(RetryableStageHelper2.java:221)\r\n        at software.amazon.awssdk.core.internal.http.pipeline.stages.AsyncRetryableStage2$RetryingExecutor.maybeRetryExecute(AsyncRetryableStage2.java:151)\r\n        ... 23 more\r\n        Suppressed: software.amazon.awssdk.core.exception.SdkClientException: Request attempt 1 failure: Unable to execute HTTP request: The connection was closed during the request. The request will usually succeed on a retry, but if it does not: consider disabling any proxies you have configured, enabling debug logging, or performing a TCP dump to identify the root cause. If this is a streaming operation, validate that data is being read or written in a timely manner. Channel Information: ChannelDiagnostics(channel=[id: 0x801baead, L:0.0.0.0/0.0.0.0:59534 ! R:bucket.vpce-0117f6033eaf7aee5-2hxd9fg4.s3.us-west-2.vpce.amazonaws.com/10.80.134.179:443], channelAge=PT0.676S, requestCount=1, responseCount=0, lastIdleDuration=PT0.006284125S)\r\nCaused by: java.lang.IllegalStateException: executor not accepting a task\r\n        at software.amazon.awssdk.thirdparty.io.netty.resolver.AddressResolverGroup.getResolver(AddressResolverGroup.java:61)\r\n        at software.amazon.awssdk.thirdparty.io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:208)\r\n        at software.amazon.awssdk.thirdparty.io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:47)\r\n        at software.amazon.awssdk.thirdparty.io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:189)\r\n        at software.amazon.awssdk.thirdparty.io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:175)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:492)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:636)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:625)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:105)\r\n        at software.amazon.awssdk.thirdparty.io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\r\n        at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:988)\r\n        at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:515)\r\n        at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:428)\r\n        at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:485)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\r\n        at software.amazon.awssdk.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\r\n        at software.amazon.awssdk.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n        ... 1 more\r\n{code}\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-05-13T16:21:05.892+0000", "updated": "2025-05-13T16:21:05.892+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13618000/comment/17953112", "id": "17953112", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #7701:\nURL: https://github.com/apache/hadoop/pull/7701\n\n   \r\n   HADOOP-19567.\r\n   \r\n   catch all exception raised in stream close; log at debug\r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Surfaced during a cloudstore bandwidth test; manual testing can check.\r\n   \r\n   Hard to write an ITest as it probably depends on the stream state at the time...will have to explore.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-21T10:46:01.718+0000", "updated": "2025-05-21T10:46:01.718+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13618000/comment/17953136", "id": "17953136", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7701:\nURL: https://github.com/apache/hadoop/pull/7701#issuecomment-2897716585\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 17s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | -1 :x: |  test4tests  |   0m  0s |  |  The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  trunk passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m  2s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 40s |  |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 26s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  81m 22s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.49 ServerAPI=1.49 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7701/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7701 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 730169d3cabd 5.15.0-136-generic #147-Ubuntu SMP Sat Mar 15 15:53:30 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / d847a1e7fd0f6950b4d06d8481c936455c97ea4e |\r\n   | Default Java | Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.27+6-post-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_452-8u452-ga~us1-0ubuntu1~20.04-b09 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7701/1/testReport/ |\r\n   | Max. process+thread count | 553 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7701/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-21T12:08:28.765+0000", "updated": "2025-05-21T12:08:28.765+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13618000/comment/17953687", "id": "17953687", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7701:\nURL: https://github.com/apache/hadoop/pull/7701#issuecomment-2904257437\n\n   @ahmarsuhail stack is in the JIRA, just submission of some asyc work failing.\r\n   \r\n   this is a much better failure than in the output stream case, which blocks...just that's an existing bug I only just noticed when manually stopping uploads (todo: add to the qualification)\r\n   \r\n   \r\n   Note that this is in the SDK...it's not checking that the executor is open before presenting an explanation which is completely wrong. Will leave that for you to report.\r\n   \r\n   ```\r\n   Suppressed: software.amazon.awssdk.core.exception.SdkClientException: Request attempt 1 failure: Unable to execute HTTP request: The connection was closed during the request. The request will usually succeed on a retry, but if it does not: consider disabling any proxies you have configured, enabling debug logging, or performing a TCP dump to identify the root cause. If this is a streaming operation, validate that data is being read or written in a timely manner. Channel Information: ChannelDiagnostics(channel=[id: 0x801baead, L:0.0.0.0/0.0.0.0:59534 ! R:bucket.vpce-0117f6033eaf7aee5-2hxd9fg4.s3.us-west-2.vpce.amazonaws.com/10.80.134.179:443], channelAge=PT0.676S, requestCount=1, responseCount=0, lastIdleDuration=PT0.006284125S)\r\n   Caused by: java.lang.IllegalStateException: executor not accepting a task\r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-23T12:26:08.689+0000", "updated": "2025-05-23T12:26:08.689+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13618000/comment/17953688", "id": "17953688", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran merged PR #7701:\nURL: https://github.com/apache/hadoop/pull/7701\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-23T12:26:46.441+0000", "updated": "2025-05-23T12:26:46.441+0000"}], "maxResults": 5, "total": 5, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}