{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13632704", "self": "https://issues.apache.org/jira/rest/api/2/issue/13632704", "key": "SPARK-54065", "fields": {"summary": "Fix `test_in_memory_data_source` in Python 3.14", "description": "{code}\r\n======================================================================\r\nERROR [0.007s]: test_in_memory_data_source (pyspark.sql.tests.test_python_datasource.PythonDataSourceTests.test_in_memory_data_source)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/__w/spark/spark/python/pyspark/serializers.py\", line 460, in dumps\r\n    return cloudpickle.dumps(obj, pickle_protocol)\r\n           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/cloudpickle/cloudpickle.py\", line 1537, in dumps\r\n    cp.dump(obj)\r\n    ~~~~~~~^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/cloudpickle/cloudpickle.py\", line 1303, in dump\r\n    return super().dump(obj)\r\n           ~~~~~~~~~~~~^^^^^\r\nTypeError: cannot pickle '_abc._abc_data' object\r\nwhen serializing dict item '_abc_impl'\r\nwhen serializing tuple item 0\r\nwhen serializing cell reconstructor arguments\r\nwhen serializing cell object\r\nwhen serializing tuple item 0\r\nwhen serializing dict item '__closure__'\r\nwhen serializing tuple item 1\r\nwhen serializing function state\r\nwhen serializing function object\r\nwhen serializing dict item '__annotate_func__'\r\nwhen serializing tuple item 0\r\nwhen serializing abc.ABCMeta state\r\nwhen serializing abc.ABCMeta object\r\nwhen serializing tuple item 0\r\nwhen serializing cell reconstructor arguments\r\nwhen serializing cell object\r\nwhen serializing tuple item 0\r\nwhen serializing dict item '__closure__'\r\nwhen serializing tuple item 1\r\nwhen serializing function state\r\nwhen serializing function object\r\nwhen serializing dict item 'reader'\r\nwhen serializing tuple item 0\r\nwhen serializing abc.ABCMeta state\r\nwhen serializing abc.ABCMeta object\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/__w/spark/spark/python/pyspark/sql/tests/test_python_datasource.py\", line 283, in test_in_memory_data_source\r\n    self.spark.dataSource.register(InMemoryDataSource)\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/sql/datasource.py\", line 1197, in register\r\n    wrapped = _wrap_function(sc, dataSource)\r\n  File \"/__w/spark/spark/python/pyspark/sql/udf.py\", line 59, in _wrap_function\r\n    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)\r\n                                                     ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/core/rdd.py\", line 5121, in _prepare_for_python_RDD\r\n    pickled_command = ser.dumps(command)\r\n  File \"/__w/spark/spark/python/pyspark/serializers.py\", line 470, in dumps\r\n    raise pickle.PicklingError(msg)\r\n_pickle.PicklingError: Could not serialize object: TypeError: cannot pickle '_abc._abc_data' object\r\n{code}\r\n\r\n{code}\r\n======================================================================\r\nERROR [0.014s]: test_in_memory_data_source (pyspark.sql.tests.connect.test_parity_python_datasource.PythonDataSourceParityTests.test_in_memory_data_source)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/__w/spark/spark/python/pyspark/serializers.py\", line 460, in dumps\r\n    return cloudpickle.dumps(obj, pickle_protocol)\r\n           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/cloudpickle/cloudpickle.py\", line 1537, in dumps\r\n    cp.dump(obj)\r\n    ~~~~~~~^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/cloudpickle/cloudpickle.py\", line 1303, in dump\r\n    return super().dump(obj)\r\n           ~~~~~~~~~~~~^^^^^\r\nTypeError: cannot pickle '_abc._abc_data' object\r\nwhen serializing dict item '_abc_impl'\r\nwhen serializing tuple item 0\r\nwhen serializing cell reconstructor arguments\r\nwhen serializing cell object\r\nwhen serializing tuple item 0\r\nwhen serializing dict item '__closure__'\r\nwhen serializing tuple item 1\r\nwhen serializing function state\r\nwhen serializing function object\r\nwhen serializing dict item '__annotate_func__'\r\nwhen serializing tuple item 0\r\nwhen serializing abc.ABCMeta state\r\nwhen serializing abc.ABCMeta object\r\nwhen serializing tuple item 0\r\nwhen serializing cell reconstructor arguments\r\nwhen serializing cell object\r\nwhen serializing tuple item 0\r\nwhen serializing dict item '__closure__'\r\nwhen serializing tuple item 1\r\nwhen serializing function state\r\nwhen serializing function object\r\nwhen serializing dict item 'reader'\r\nwhen serializing tuple item 0\r\nwhen serializing abc.ABCMeta state\r\nwhen serializing abc.ABCMeta object\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/__w/spark/spark/python/pyspark/sql/tests/test_python_datasource.py\", line 283, in test_in_memory_data_source\r\n    self.spark.dataSource.register(InMemoryDataSource)\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/sql/connect/datasource.py\", line 45, in register\r\n    self.sparkSession._client.register_data_source(dataSource)\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/sql/connect/client/core.py\", line 863, in register_data_source\r\n    ).to_data_source_proto(self)\r\n      ~~~~~~~~~~~~~~~~~~~~^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/sql/connect/plan.py\", line 2833, in to_data_source_proto\r\n    plan.python_data_source.CopyFrom(self._data_source.to_plan(session))\r\n                                     ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/sql/connect/plan.py\", line 2807, in to_plan\r\n    ds.command = CloudPickleSerializer().dumps(self._data_source)\r\n                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\r\n  File \"/__w/spark/spark/python/pyspark/serializers.py\", line 470, in dumps\r\n    raise pickle.PicklingError(msg)\r\n_pickle.PicklingError: Could not serialize object: TypeError: cannot pickle '_abc._abc_data' object\r\n\r\n----------------------------------------------------------------------\r\n{code}", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=dongjoon", "name": "dongjoon", "key": "dongjoon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=dongjoon&avatarId=42503", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dongjoon&avatarId=42503", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dongjoon&avatarId=42503", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dongjoon&avatarId=42503"}, "displayName": "Dongjoon Hyun", "active": true, "timeZone": "America/Los_Angeles"}, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}