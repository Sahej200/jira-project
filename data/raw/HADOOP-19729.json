{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13631778", "self": "https://issues.apache.org/jira/rest/api/2/issue/13631778", "key": "HADOOP-19729", "fields": {"summary": "ABFS: [Perf] Network Profiling of Tailing Requests and Killing Bad Connections Proactively", "description": "It has been observed that certain requests taking more time than expected to complete hinders the performance of whole workload. Such requests are known as tailing requests. They can be taking more time due to a number of reasons and the prominent among them is a bad network connection. In Abfs driver we cache network connections and keeping such bad connections in cache and reusing them can be bad for perf.\r\n\r\nIn this effort we try to identify such connections and close them so that new good connetions can be established and perf can be improved. There are two parts of this effort.\r\n # Identifying Tailing Requests: This involves profiling all the network calls and getting percentiles value optimally. By default we consider p99 as the tail latency and all the future requests taking more than tail latency will be considere as Tailing requests.\r\n\r\n # Proactively Killing Socket Connections: With Apache client, we can now kill the socket connection and fail the tailing request. Such failures will not be thrown back to user and retried immediately without any sleep but from another socket connection.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033018", "id": "18033018", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3448411577\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  11m  8s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  21m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 26s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 43s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 21s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 10s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 43 new + 3 unchanged - 0 fixed = 46 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 18s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 34 new + 1472 unchanged - 0 fixed = 1506 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 33 new + 1413 unchanged - 0 fixed = 1446 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 4 new + 177 unchanged - 1 fixed = 181 total (was 178)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 12s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m  8s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  70m  0s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 533] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 81] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux d98c9c1604f2 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7dcac93eec4dc5a48d643ae81372c581b6c3bebf |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/testReport/ |\r\n   | Max. process+thread count | 614 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-26T10:46:14.005+0000", "updated": "2025-10-26T10:46:14.005+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033112", "id": "18033112", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3449602331\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 43 new + 3 unchanged - 0 fixed = 46 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 35 new + 1472 unchanged - 0 fixed = 1507 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 34 new + 1413 unchanged - 0 fixed = 1447 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 45s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 4 new + 177 unchanged - 1 fixed = 181 total (was 178)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m  8s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 18s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  60m 12s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 533] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 81] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 9b5c6baa74d5 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / de244d215362fca4d8ba16b3d01a9f39a3ff0e81 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/testReport/ |\r\n   | Max. process+thread count | 637 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/3/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T05:39:12.286+0000", "updated": "2025-10-27T05:39:12.286+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033137", "id": "18033137", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2464810768\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n\nReview Comment:\n   first check should be for isTailLatencyTrackerEnabled\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T08:37:41.756+0000", "updated": "2025-10-27T08:37:41.756+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033140", "id": "18033140", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2464820798\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n+        && getPreferredHttpOperationType().equals(HttpOperationType.APACHE_HTTP_CLIENT);\n+  }\n+\n+  public int getTailLatencyPercentile() {\n+    return tailLatencyPercentile;\n+  }\n+\n+  public int getTailLatencyMinDeviation() {\n+    return tailLatencyMinDeviation;\n+  }\n+\n+  public int getTailLatencyMinSampleSize() {\n+    return tailLatencyMinSampleSize;\n+  }\n+\n+  public int getTailLatencyAnalysisWindowInMillis() {\n+    return tailLatencyAnalysisWindowInMillis;\n+  }\n+\n+  public int getTailLatencyPercentileComputationIntervalInMillis() {\n\nReview Comment:\n   Name should be shortened\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T08:41:50.368+0000", "updated": "2025-10-27T08:41:50.368+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033176", "id": "18033176", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465174540\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n\nReview Comment:\n   Do we not want this feature to be enabled by default ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T10:36:34.608+0000", "updated": "2025-10-27T10:36:34.608+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033183", "id": "18033183", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465238391\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -143,6 +173,51 @@ public HttpResponse execute(HttpRequestBase httpRequest,\n     return httpClient.execute(httpRequest, abfsHttpClientContext);\n   }\n \n+  /**\n+   * Executes the HTTP request with a deadline. If the request does not complete\n+   * within the deadline, it is aborted and an IOException is thrown.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   * @param deadlineMillis Deadline in milliseconds.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error or deadline exceeded.\n+   */\n+  public HttpResponse executeWithDeadline(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long deadlineMillis) throws IOException {\n+    RequestConfig.Builder requestConfigBuilder = RequestConfig\n+        .custom()\n+        .setConnectTimeout(connectTimeout)\n+        .setSocketTimeout(readTimeout);\n+    httpRequest.setConfig(requestConfigBuilder.build());\n+    ExecutorService executor = Executors.newSingleThreadExecutor();\n+    Future<HttpResponse> future = executor.submit(() ->\n+        httpClient.execute(httpRequest, abfsHttpClientContext)\n+    );\n+\n+    try {\n+      return future.get(deadlineMillis, TimeUnit.MILLISECONDS);\n+    } catch (TimeoutException e) {\n+      /* Deadline exceeded, abort the request.\n+       * This will also kill the underlying socket exception in the HttpClient.\n+       * Connection will be marker stale and won't be returned back to KAC for reuse.\n\nReview Comment:\n   nit: typo marked\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:00:11.638+0000", "updated": "2025-10-27T11:00:11.638+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033186", "id": "18033186", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465280967\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/RetryPolicyConstants.java:\n##########\n@@ -32,4 +32,8 @@ private RetryPolicyConstants() {\n    * Constant for Static Retry Policy Abbreviation. {@value}\n    */\n   public static final String STATIC_RETRY_POLICY_ABBREVIATION = \"S\";\n+  /**\n+   * Constant for Static Retry Policy Abbreviation. {@value}\n+   */\n+  public static final String TAIL_LATENCY_TIMEOUT_RETRY_POLICY_ABBREVIATION = \"T\";\n\nReview Comment:\n   Can we make it TL ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:16:02.020+0000", "updated": "2025-10-27T11:16:02.020+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033192", "id": "18033192", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465316539\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n\nReview Comment:\n   Should be numberOfSegments in exception\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:30:48.845+0000", "updated": "2025-10-27T11:30:48.845+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033194", "id": "18033194", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465371723\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n\nReview Comment:\n   We can return here itself\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T11:53:15.752+0000", "updated": "2025-10-27T11:53:15.752+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033196", "id": "18033196", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465396005\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n\nReview Comment:\n   Chances of division by zero error\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:02:48.630+0000", "updated": "2025-10-27T12:02:48.630+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033204", "id": "18033204", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465418474\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n\nReview Comment:\n   Is less than 0 possible for total count ? It is increment always right \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:10:12.482+0000", "updated": "2025-10-27T12:10:12.482+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033205", "id": "18033205", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465418474\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n\nReview Comment:\n   Is less than 0 possible for total count? It is incremented always right \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:10:29.724+0000", "updated": "2025-10-27T12:10:29.724+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033211", "id": "18033211", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465446936\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n+        currentSegmentStartMillis = alignToSegmentDuration(System.currentTimeMillis());\n+        LOG.debug(\"[{}] No data recorded in current time segment at {}. Skipping Rotation. Current Index is {}.\",\n+            operationType, currentSegmentStartMillis, currentIndex.get());\n+        return;\n+      }\n+\n+      LOG.debug(\"[{}] Rotating current segment with total count {} into slot {}\",\n+          operationType, currentSegmentAccumulation.getTotalCount(), currentIndex.get());\n+\n+      // Place the finished currentAccumulation into the ring buffer slot ahead.\n+      int currentIdx = (currentIndex.getAndIncrement()) % numSegments;\n+      // Next slot is now going to be eradicated. Remove its count from total.\n+      currentTotalCount.set(currentTotalCount.get() - (completedSegments[currentIdx] == null ? 0 : completedSegments[currentIdx].getTotalCount()));\n+      // Store an immutable snapshot (make sure we don't mutate the instance after storing)\n+      completedSegments[currentIdx] = currentSegmentAccumulation;\n\nReview Comment:\n   how are we making sure that this is immutable after this point ? completedSegments[currentIdx] = currentSegmentAccumulation.copy(); ideally we should create a deep copy of the histogram data so that even if currentSegmentAccumulation is reused or reset for the next segment, the data in completedSegments remains unchanged.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:20:21.973+0000", "updated": "2025-10-27T12:20:21.973+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033212", "id": "18033212", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465452348\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n\nReview Comment:\n   what is the use of the variable now ? We can directly use System.currentTimeMillis(); in expectedStart as we are doing later in line 195\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:22:32.912+0000", "updated": "2025-10-27T12:22:32.912+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033216", "id": "18033216", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465506034\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -114,6 +116,7 @@ public class AbfsRestOperation {\n    */\n   private String failureReason;\n   private AbfsRetryPolicy retryPolicy;\n+  private boolean shouldTailLatencyTimeout = true;\n\nReview Comment:\n   Can be renamed to enableTailLatencyTimeout\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:41:20.427+0000", "updated": "2025-10-27T12:41:20.427+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033217", "id": "18033217", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465510352\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n\nReview Comment:\n   Will get updated for -1 status code as well, should be checked between 200 to 300\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:43:01.013+0000", "updated": "2025-10-27T12:43:01.013+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033223", "id": "18033223", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465561509\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n\nReview Comment:\n   add comment for which value represents what\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T12:55:40.546+0000", "updated": "2025-10-27T12:55:40.546+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033226", "id": "18033226", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2465576049\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        0,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Verify that the histogram is created successfully with default values and\n+    // do not report any percentiles\n+    assertThat(histogram).isNotNull();\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(0);\n+    assertThat(histogram.getCurrentIndex()).isEqualTo(0);\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Verify that recording values works as expected\n+    addAndRotate(histogram, 10, 5); // Add 5 values of 10\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(5);\n+\n+    // Verify that percentiles are not computed with insufficient samples\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values to exceed the minimum sample size\n+    addAndRotate(histogram, 20, 5); // Add 5 values of 20\n+\n+    // Verify that percentiles are now computed but tail Latency is still not reported\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values and rotate histogram to fill whole analysis window\n+    addAndRotate(histogram, 30, 5); // Add 5 values of 30\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(15);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 60, 5); // Add 5 values of 60\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(20);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation is skipped if nothing new recorded and hence window not filled\n+    addAndRotate(histogram, 100, 0); // No new values added\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation does not happen if analysis window is not filled\n+    histogram.rotateIfNeeded();\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 80\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(25);\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles and tail latency are computed\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isGreaterThan(0.0);\n+\n+    // Verify that sliding window works. Old values should be evicted\n+    addAndRotate(histogram, 90, 3); // Add 3 values of 90\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(23);\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementNotMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        100,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        50,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n\nReview Comment:\n   nit: should be computed ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-27T13:00:48.587+0000", "updated": "2025-10-27T13:00:48.587+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033529", "id": "18033529", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2469106859\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT = false;\n+  public static final int DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE = 99;\n\nReview Comment:\n   shouldn't it be float/double instead of int? Tomorrow we can change default percentile to 99.9 or 99.99.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n\nReview Comment:\n   @param missing in the java doc\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -132,6 +138,30 @@ public void close() throws IOException {\n    * @throws IOException network error.\n    */\n   public HttpResponse execute(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long tailLatencyTimeout) throws IOException {\n+    if (tailLatencyTimeout <= 0) {\n+      return executeWithoutDeadline(httpRequest, abfsHttpClientContext,\n+          connectTimeout, readTimeout);\n+    }\n+    return executeWithDeadline(httpRequest, abfsHttpClientContext,\n+        connectTimeout, readTimeout, tailLatencyTimeout);\n+  }\n+\n+  /**\n+   * Executes the HTTP request.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error.\n+   */\n+  public HttpResponse executeWithoutDeadline(HttpRequestBase httpRequest,\n\nReview Comment:\n   executeWithoutDeadline and executeWithDeadline can be private methods.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n+    super(ERR_TAIL_LATENCY_REQUEST_TIMEOUT, innerException);\n+  }\n+\n+  public TailLatencyRequestTimeoutException() {\n\nReview Comment:\n   Java doc missing for this\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n\nReview Comment:\n   We can rename this variable to something which is more relevant.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n\nReview Comment:\n   We should close this thread pool and one below once the use is done or at least during filesystem close.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -611,10 +630,30 @@ AbfsJdkHttpOperation createAbfsHttpOperation() throws IOException {\n \n   @VisibleForTesting\n   AbfsAHCHttpOperation createAbfsAHCHttpOperation() throws IOException {\n+    long tailLatency = getTailLatencyTimeoutIfEnabled();\n     return new AbfsAHCHttpOperation(url, method, requestHeaders,\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpConnectionTimeout()),\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpReadTimeout()),\n-        client.getAbfsApacheHttpClient(), client);\n+        tailLatency, client.getAbfsApacheHttpClient(), client);\n+  }\n+\n+  /**\n+   * Get Tail Latency Timeout value if profiling is enabled, timeout is enabled\n+   * and retries due to tail latency request timeout is allowed.\n+   * @return tail latency timeout value else return zero.\n+   */\n+  long getTailLatencyTimeoutIfEnabled() {\n+    if (isTailLatencyTimeoutEnabled() && shouldTailLatencyTimeout) {\n+      return (long) tailLatencyTracker.getTailLatency(this.operationType);\n+    }\n+    return ZERO;\n+  }\n+\n+  boolean isTailLatencyTimeoutEnabled() {\n\nReview Comment:\n   Java doc missing\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T11:35:24.187+0000", "updated": "2025-10-28T11:35:24.187+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033618", "id": "18033618", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470451730\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n\nReview Comment:\n   Make sense.\r\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:34:58.647+0000", "updated": "2025-10-28T17:34:58.647+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033619", "id": "18033619", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470457723\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1824,4 +1860,41 @@ public int getBlobRenameDirConsumptionParallelism() {\n   public int getBlobDeleteDirConsumptionParallelism() {\n     return blobDeleteDirConsumptionParallelism;\n   }\n+\n+  public boolean isTailLatencyTrackerEnabled() {\n+    return isTailLatencyTrackerEnabled;\n+  }\n+\n+  public boolean isTailLatencyRequestTimeoutEnabled() {\n+    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n+        && getPreferredHttpOperationType().equals(HttpOperationType.APACHE_HTTP_CLIENT);\n+  }\n+\n+  public int getTailLatencyPercentile() {\n+    return tailLatencyPercentile;\n+  }\n+\n+  public int getTailLatencyMinDeviation() {\n+    return tailLatencyMinDeviation;\n+  }\n+\n+  public int getTailLatencyMinSampleSize() {\n+    return tailLatencyMinSampleSize;\n+  }\n+\n+  public int getTailLatencyAnalysisWindowInMillis() {\n+    return tailLatencyAnalysisWindowInMillis;\n+  }\n+\n+  public int getTailLatencyPercentileComputationIntervalInMillis() {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:36:57.219+0000", "updated": "2025-10-28T17:36:57.219+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033620", "id": "18033620", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470459989\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n\nReview Comment:\n   There is no value add currently to just enable profling as we are not consuming it anywhere.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:37:43.800+0000", "updated": "2025-10-28T17:37:43.800+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033621", "id": "18033621", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470461231\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -143,6 +173,51 @@ public HttpResponse execute(HttpRequestBase httpRequest,\n     return httpClient.execute(httpRequest, abfsHttpClientContext);\n   }\n \n+  /**\n+   * Executes the HTTP request with a deadline. If the request does not complete\n+   * within the deadline, it is aborted and an IOException is thrown.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   * @param deadlineMillis Deadline in milliseconds.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error or deadline exceeded.\n+   */\n+  public HttpResponse executeWithDeadline(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long deadlineMillis) throws IOException {\n+    RequestConfig.Builder requestConfigBuilder = RequestConfig\n+        .custom()\n+        .setConnectTimeout(connectTimeout)\n+        .setSocketTimeout(readTimeout);\n+    httpRequest.setConfig(requestConfigBuilder.build());\n+    ExecutorService executor = Executors.newSingleThreadExecutor();\n+    Future<HttpResponse> future = executor.submit(() ->\n+        httpClient.execute(httpRequest, abfsHttpClientContext)\n+    );\n+\n+    try {\n+      return future.get(deadlineMillis, TimeUnit.MILLISECONDS);\n+    } catch (TimeoutException e) {\n+      /* Deadline exceeded, abort the request.\n+       * This will also kill the underlying socket exception in the HttpClient.\n+       * Connection will be marker stale and won't be returned back to KAC for reuse.\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:38:13.828+0000", "updated": "2025-10-28T17:38:13.828+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033622", "id": "18033622", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470463895\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/RetryPolicyConstants.java:\n##########\n@@ -32,4 +32,8 @@ private RetryPolicyConstants() {\n    * Constant for Static Retry Policy Abbreviation. {@value}\n    */\n   public static final String STATIC_RETRY_POLICY_ABBREVIATION = \"S\";\n+  /**\n+   * Constant for Static Retry Policy Abbreviation. {@value}\n+   */\n+  public static final String TAIL_LATENCY_TIMEOUT_RETRY_POLICY_ABBREVIATION = \"T\";\n\nReview Comment:\n   Other Retry policy abbreviations are already single character. Keeping it likewise\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:39:08.862+0000", "updated": "2025-10-28T17:39:08.862+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033623", "id": "18033623", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470465366\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:39:28.635+0000", "updated": "2025-10-28T17:39:28.635+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033624", "id": "18033624", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470469035\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:40:22.880+0000", "updated": "2025-10-28T17:40:22.880+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033625", "id": "18033625", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470478310\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n\nReview Comment:\n   Nice catch.\r\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:42:19.000+0000", "updated": "2025-10-28T17:42:19.000+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033626", "id": "18033626", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470481704\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n\nReview Comment:\n   Yeah this is primarily for equal to 0\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:42:54.939+0000", "updated": "2025-10-28T17:42:54.939+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033627", "id": "18033627", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470498123\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n+    long expectedStart = alignToSegmentDuration(now);\n+    if (expectedStart == currentSegmentStartMillis) {\n+      LOG.debug(\"[{}] Current Time Segment Still Active at {}. Skipping Rotation\", operationType, expectedStart);\n+      return; // still current\n+    }\n+\n+    rotateLock.lock();\n+    try {\n+      // Re-check inside lock\n+      now = System.currentTimeMillis();\n+      expectedStart = alignToSegmentDuration(now);\n+      if (expectedStart == currentSegmentStartMillis) return;\n+\n+      // Finalize the current bucket:\n+      // Pull any remaining deltas from active recorder and add to currentAccumulation\n+      tmpForDelta.reset();\n+      activeSegmentRecorder.getIntervalHistogramInto(tmpForDelta);\n+      currentSegmentAccumulation.add(tmpForDelta);\n+\n+      if (currentSegmentAccumulation.getTotalCount() <= 0) {\n+        currentSegmentStartMillis = alignToSegmentDuration(System.currentTimeMillis());\n+        LOG.debug(\"[{}] No data recorded in current time segment at {}. Skipping Rotation. Current Index is {}.\",\n+            operationType, currentSegmentStartMillis, currentIndex.get());\n+        return;\n+      }\n+\n+      LOG.debug(\"[{}] Rotating current segment with total count {} into slot {}\",\n+          operationType, currentSegmentAccumulation.getTotalCount(), currentIndex.get());\n+\n+      // Place the finished currentAccumulation into the ring buffer slot ahead.\n+      int currentIdx = (currentIndex.getAndIncrement()) % numSegments;\n+      // Next slot is now going to be eradicated. Remove its count from total.\n+      currentTotalCount.set(currentTotalCount.get() - (completedSegments[currentIdx] == null ? 0 : completedSegments[currentIdx].getTotalCount()));\n+      // Store an immutable snapshot (make sure we don't mutate the instance after storing)\n+      completedSegments[currentIdx] = currentSegmentAccumulation;\n\nReview Comment:\n   This is happening by reference. The reference earlier held by `currentSegmentAccumulation` is now saved into `completedSegments[currentIdx]`. And a new reference is created  and saved into `currentSegmentAccumulation`\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:45:35.253+0000", "updated": "2025-10-28T17:45:35.253+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033628", "id": "18033628", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470505964\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+import org.HdrHistogram.Histogram;\n+import org.HdrHistogram.Recorder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.apache.hadoop.classification.VisibleForTesting;\n+\n+public class SlidingWindowHdrHistogram {\n+  private static final Logger LOG = LoggerFactory.getLogger(SlidingWindowHdrHistogram.class);\n+\n+  // Configuration\n+  private final long windowSizeMillis;          // Total analysis window\n+  private final long timeSegmentDurationMillis;       // Subdivision on analysis window\n+  private final int numSegments;\n+  private final long highestTrackableValue;\n+  private final int significantFigures;\n+\n+  // Ring buffer of immutable snapshots for completed time segments\n+  private final Histogram[] completedSegments;\n+  private final AtomicInteger currentIndex = new AtomicInteger(0);\n+\n+  // Active Time Segment\n+  private volatile Recorder activeSegmentRecorder;\n+  private Histogram currentSegmentAccumulation;\n+  private volatile long currentSegmentStartMillis;\n+  private final AtomicLong currentTotalCount = new AtomicLong(0L);\n+\n+  // Synchronization\n+  // Writers never take locks. Readers (queries) and rotation use this lock\n+  // to mutate currentAccumulation and ring-buffer pointers safely.\n+  private final ReentrantLock rotateLock = new ReentrantLock();\n+\n+  // Reusable temp histograms to minimize allocations\n+  private Histogram tmpForDelta;\n+  private Histogram tmpForMerge;\n+\n+  private final AbfsRestOperationType operationType;\n+\n+  private boolean isAnalysisWindowFilled = false;\n+  private int minSampleSize;\n+  private int tailLatencyPercentile;\n+  private int tailLatencyMinDeviation;\n+\n+  private double p50 = 0.0;\n+  private double p90 = 0.0;\n+  private double p99 = 0.0;\n+  private double tailLatency = 0.0;\n+  private int deviation = 0;\n+\n+  public SlidingWindowHdrHistogram(long windowSizeMillis,\n+      int numberOfSegments,\n+      int minSampleSize,\n+      int tailLatencyPercentile,\n+      int tailLatencyMinDeviation,\n+      long highestTrackableValue,\n+      int significantFigures,\n+      final AbfsRestOperationType operationType) {\n+    if (windowSizeMillis <= 0) throw new IllegalArgumentException(\"windowSizeMillis > 0\");\n+    if (numberOfSegments <= 0) throw new IllegalArgumentException(\"bucketDurationMillis > 0\");\n+    if (highestTrackableValue <= 0) throw new IllegalArgumentException(\"highestTrackableValue > 0\");\n+    if (significantFigures < 1 || significantFigures > 5) throw new IllegalArgumentException(\"significantFigures in [1,5]\");\n+\n+    this.windowSizeMillis = windowSizeMillis;\n+    this.numSegments = numberOfSegments;\n+    this.timeSegmentDurationMillis = windowSizeMillis/numberOfSegments;\n+    this.highestTrackableValue = highestTrackableValue;\n+    this.significantFigures = significantFigures;\n+    this.operationType = operationType;\n+    this.minSampleSize = minSampleSize;\n+    this.tailLatencyPercentile = tailLatencyPercentile;\n+    this.tailLatencyMinDeviation = tailLatencyMinDeviation; // 5ms\n+\n+    this.completedSegments = new Histogram[numSegments];\n+    long now = System.currentTimeMillis();\n+    this.currentSegmentStartMillis = alignToSegmentDuration(now);\n+    currentIndex.set(0);\n+    this.activeSegmentRecorder = new Recorder(highestTrackableValue, significantFigures);\n+    this.currentSegmentAccumulation = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForDelta = new Histogram(highestTrackableValue, significantFigures);\n+    this.tmpForMerge = new Histogram(highestTrackableValue, significantFigures);\n+\n+    LOG.debug(\"[{}] Initialized SlidingWindowHdrHistogram with WindowSize {}, TimeSegmentDur: {}, NumOfSegments: {}\", operationType, windowSizeMillis, timeSegmentDurationMillis, numSegments);\n+  }\n+\n+  /** Record a single latency value (in your chosen time unit). Thread-safe and lock-free. */\n+  public void recordValue(long value) {\n+    if (value < 0 || value > highestTrackableValue) {\n+      LOG.warn(\"[{}] Value {} outside of range [0, {}]. Ignoring\",\n+          operationType, value, highestTrackableValue);\n+      return;\n+    }\n+    activeSegmentRecorder.recordValue(value);\n+    currentTotalCount.incrementAndGet();\n+    LOG.debug(\"[{}] Recorded latency value: {}. Current total count: {}\",\n+        operationType, value, currentTotalCount.get());\n+  }\n+\n+  /** Get any percentile over the current sliding window. */\n+  public void computeLatency() {\n+    if (getCurrentTotalCount() < minSampleSize) {\n+      LOG.debug(\"[{}] Not enough data to report percentiles. Current total count: {}\",\n+          operationType, getCurrentTotalCount());\n+    } else {\n+      rotateLock.lock();\n+      try {\n+        tmpForMerge.reset();\n+        for (int i = 0; i < numSegments; i++) {\n+          Histogram h = completedSegments[i];\n+          if (h != null && h.getTotalCount() > 0) {\n+            tmpForMerge.add(h);\n+          }\n+        }\n+\n+        if (tmpForMerge.getTotalCount() == 0) return;\n+\n+        tailLatency = tmpForMerge.getValueAtPercentile(tailLatencyPercentile);\n+        p50 = tmpForMerge.getValueAtPercentile(50);\n+        p90 = tmpForMerge.getValueAtPercentile(90);\n+        p99 = tmpForMerge.getValueAtPercentile(99);\n+        deviation = (int) ((tailLatency - p50)/p50 * 100);\n+      } finally {\n+        rotateLock.unlock();\n+      }\n+    }\n+    LOG.debug(\"[{}] Computed Latencies. p50: {}, p90: {}, p99: {}, tailLatency: {}, deviation with p50: {} Current total count: {}\",\n+        operationType, p50, p90, p99, tailLatency, deviation, getCurrentTotalCount());\n+  }\n+\n+  private long alignToSegmentDuration(long timeMs) {\n+    return timeMs - (timeMs % timeSegmentDurationMillis);\n+  }\n+\n+  /** Ensure active bucket is aligned to current time; rotate if we've crossed a boundary. */\n+  public void rotateIfNeeded() {\n+    LOG.debug(\"[{}] Triggering Histogram Rotation\", operationType);\n+    long now = System.currentTimeMillis();\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:47:01.456+0000", "updated": "2025-10-28T17:47:01.456+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033630", "id": "18033630", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470514912\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -114,6 +116,7 @@ public class AbfsRestOperation {\n    */\n   private String failureReason;\n   private AbfsRetryPolicy retryPolicy;\n+  private boolean shouldTailLatencyTimeout = true;\n\nReview Comment:\n   That might be misleading.\r\n   This variable is not a flag for this feature. Even when feature is enabled, we might have this as false.\r\n   \r\n   This is to indicate that all the retried due to TailLatencyTimeout are exhausted and even though the feature is still enabled, for the next retry we should not Timeout due to tail latency\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:48:45.361+0000", "updated": "2025-10-28T17:48:45.361+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033631", "id": "18033631", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470519920\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -114,6 +116,7 @@ public class AbfsRestOperation {\n    */\n   private String failureReason;\n   private AbfsRetryPolicy retryPolicy;\n+  private boolean shouldTailLatencyTimeout = true;\n\nReview Comment:\n   Added javadoc\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:49:35.107+0000", "updated": "2025-10-28T17:49:35.107+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033632", "id": "18033632", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470527273\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:51:16.136+0000", "updated": "2025-10-28T17:51:16.136+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033634", "id": "18033634", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470543064\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestSlidingWindowHdrHistogram.java:\n##########\n@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class TestSlidingWindowHdrHistogram {\n+\n+  @Test\n+  public void testSlidingWindowHdrHistogram() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        0,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Verify that the histogram is created successfully with default values and\n+    // do not report any percentiles\n+    assertThat(histogram).isNotNull();\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(0);\n+    assertThat(histogram.getCurrentIndex()).isEqualTo(0);\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Verify that recording values works as expected\n+    addAndRotate(histogram, 10, 5); // Add 5 values of 10\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(5);\n+\n+    // Verify that percentiles are not computed with insufficient samples\n+    assertThat(histogram.getP50()).isEqualTo(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values to exceed the minimum sample size\n+    addAndRotate(histogram, 20, 5); // Add 5 values of 20\n+\n+    // Verify that percentiles are now computed but tail Latency is still not reported\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+\n+    // Record more values and rotate histogram to fill whole analysis window\n+    addAndRotate(histogram, 30, 5); // Add 5 values of 30\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(15);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 60, 5); // Add 5 values of 60\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(20);\n+\n+    // Verify that analysis window is not full until full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation is skipped if nothing new recorded and hence window not filled\n+    addAndRotate(histogram, 100, 0); // No new values added\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    // Verify that rotation does not happen if analysis window is not filled\n+    histogram.rotateIfNeeded();\n+    assertThat(histogram.isAnalysisWindowFilled()).isFalse();\n+\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 80\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(25);\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles and tail latency are computed\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isGreaterThan(0.0);\n+\n+    // Verify that sliding window works. Old values should be evicted\n+    addAndRotate(histogram, 90, 3); // Add 3 values of 90\n+    assertThat(histogram.getCurrentTotalCount()).isEqualTo(23);\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementNotMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        100,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n+    assertThat(histogram.getP50()).isGreaterThan(0.0);\n+    assertThat(histogram.getTailLatency()).isEqualTo(0.0);\n+  }\n+\n+  @Test\n+  public void testMinDeviationRequirementMet() throws Exception {\n+    SlidingWindowHdrHistogram histogram = new SlidingWindowHdrHistogram(\n+        100,\n+        5,\n+        7,\n+        99,\n+        50,\n+        100,\n+        3,\n+        AbfsRestOperationType.GetPathStatus);\n+\n+    // Add values with low deviation\n+    addAndRotate(histogram, 50, 5); // Add 5 values of 50\n+    addAndRotate(histogram, 51, 5); // Add 5 values of 52\n+    addAndRotate(histogram, 52, 5); // Add 5 values of 51\n+    addAndRotate(histogram, 80, 5); // Add 5 values of 53\n+    addAndRotate(histogram, 90, 5); // Add 5 values of 50\n+\n+    // Verify that analysis window is full after full rotation.\n+    assertThat(histogram.isAnalysisWindowFilled()).isTrue();\n+\n+    // Verify that percentiles are not computed due to low deviation\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T17:56:44.091+0000", "updated": "2025-10-28T17:56:44.091+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033635", "id": "18033635", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470552760\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n\nReview Comment:\n   the division could be by 0 if someone sets window granularity as 0\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:00:19.882+0000", "updated": "2025-10-28T18:00:19.882+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033636", "id": "18033636", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470562303\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -519,6 +519,42 @@ public class AbfsConfiguration{\n       DefaultValue = DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY)\n   private boolean enableCreateIdempotency;\n \n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER)\n+  private boolean isTailLatencyTrackerEnabled;\n+\n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT)\n+  private boolean isTailLatencyRequestTimeoutEnabled;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_PERCENTILE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE)\n+  private int tailLatencyPercentile;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_DEVIATION,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_DEVIATION)\n+  private int tailLatencyMinDeviation;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE)\n+  private int tailLatencyMinSampleSize;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS)\n+  private int tailLatencyAnalysisWindowInMillis;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY)\n\nReview Comment:\n   should we have a min, max value for window size above and window granularity?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:04:11.348+0000", "updated": "2025-10-28T18:04:11.348+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033638", "id": "18033638", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470579619\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT = false;\n+  public static final int DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE = 99;\n\nReview Comment:\n   Nice suggestion. Will take it up.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:10:51.707+0000", "updated": "2025-10-28T18:10:51.707+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033639", "id": "18033639", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470580745\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n\nReview Comment:\n   Added\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/TailLatencyRequestTimeoutException.java:\n##########\n@@ -0,0 +1,39 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.exceptions;\n+\n+import java.util.concurrent.TimeoutException;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_TAIL_LATENCY_REQUEST_TIMEOUT;\n+\n+/**\n+ * Thrown when a request takes more time than the current reported tail latency.\n+ */\n+public class TailLatencyRequestTimeoutException extends AzureBlobFileSystemException {\n+\n+  /**\n+   * Constructs a TailLatencyRequestTimeoutException with TimeoutException as the cause.\n+   */\n+  public TailLatencyRequestTimeoutException(TimeoutException innerException) {\n+    super(ERR_TAIL_LATENCY_REQUEST_TIMEOUT, innerException);\n+  }\n+\n+  public TailLatencyRequestTimeoutException() {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:11:15.107+0000", "updated": "2025-10-28T18:11:15.107+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033640", "id": "18033640", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470581573\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n\nReview Comment:\n   we could log the initialization with the granularity etc configs here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:11:36.763+0000", "updated": "2025-10-28T18:11:36.763+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033641", "id": "18033641", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470582171\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsApacheHttpClient.java:\n##########\n@@ -132,6 +138,30 @@ public void close() throws IOException {\n    * @throws IOException network error.\n    */\n   public HttpResponse execute(HttpRequestBase httpRequest,\n+      final AbfsManagedHttpClientContext abfsHttpClientContext,\n+      final int connectTimeout,\n+      final int readTimeout,\n+      final long tailLatencyTimeout) throws IOException {\n+    if (tailLatencyTimeout <= 0) {\n+      return executeWithoutDeadline(httpRequest, abfsHttpClientContext,\n+          connectTimeout, readTimeout);\n+    }\n+    return executeWithDeadline(httpRequest, abfsHttpClientContext,\n+        connectTimeout, readTimeout, tailLatencyTimeout);\n+  }\n+\n+  /**\n+   * Executes the HTTP request.\n+   *\n+   * @param httpRequest HTTP request to execute.\n+   * @param abfsHttpClientContext HttpClient context.\n+   * @param connectTimeout Connection timeout.\n+   * @param readTimeout Read timeout.\n+   *\n+   * @return HTTP response.\n+   * @throws IOException network error.\n+   */\n+  public HttpResponse executeWithoutDeadline(HttpRequestBase httpRequest,\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:11:56.584+0000", "updated": "2025-10-28T18:11:56.584+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033642", "id": "18033642", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470583329\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -611,10 +630,30 @@ AbfsJdkHttpOperation createAbfsHttpOperation() throws IOException {\n \n   @VisibleForTesting\n   AbfsAHCHttpOperation createAbfsAHCHttpOperation() throws IOException {\n+    long tailLatency = getTailLatencyTimeoutIfEnabled();\n     return new AbfsAHCHttpOperation(url, method, requestHeaders,\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpConnectionTimeout()),\n         Duration.ofMillis(client.getAbfsConfiguration().getHttpReadTimeout()),\n-        client.getAbfsApacheHttpClient(), client);\n+        tailLatency, client.getAbfsApacheHttpClient(), client);\n+  }\n+\n+  /**\n+   * Get Tail Latency Timeout value if profiling is enabled, timeout is enabled\n+   * and retries due to tail latency request timeout is allowed.\n+   * @return tail latency timeout value else return zero.\n+   */\n+  long getTailLatencyTimeoutIfEnabled() {\n+    if (isTailLatencyTimeoutEnabled() && shouldTailLatencyTimeout) {\n+      return (long) tailLatencyTracker.getTailLatency(this.operationType);\n+    }\n+    return ZERO;\n+  }\n+\n+  boolean isTailLatencyTimeoutEnabled() {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:12:21.624+0000", "updated": "2025-10-28T18:12:21.624+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033643", "id": "18033643", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470586126\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:13:35.825+0000", "updated": "2025-10-28T18:13:35.825+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033644", "id": "18033644", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470589733\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n\nReview Comment:\n   Latency tracker are per account basis. They are shared across all filesystem in a single JVM. These are daemon threads and will be killed when JVM gets killed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:14:49.165+0000", "updated": "2025-10-28T18:14:49.165+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033645", "id": "18033645", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470589786\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n+        tailLatencyTracker.updateLatency(operationType,\n\nReview Comment:\n   can 2 threads call updateLatency() for the same operation type simultaneously and create histograms?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:14:50.078+0000", "updated": "2025-10-28T18:14:50.078+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033646", "id": "18033646", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470595674\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:17:16.007+0000", "updated": "2025-10-28T18:17:16.007+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033647", "id": "18033647", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470598024\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -519,6 +519,42 @@ public class AbfsConfiguration{\n       DefaultValue = DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY)\n   private boolean enableCreateIdempotency;\n \n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER)\n+  private boolean isTailLatencyTrackerEnabled;\n+\n+  @BooleanConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT,\n+      DefaultValue = DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT)\n+  private boolean isTailLatencyRequestTimeoutEnabled;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_PERCENTILE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE)\n+  private int tailLatencyPercentile;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_DEVIATION,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_DEVIATION)\n+  private int tailLatencyMinDeviation;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_MIN_SAMPLE_SIZE)\n+  private int tailLatencyMinSampleSize;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_MILLIS)\n+  private int tailLatencyAnalysisWindowInMillis;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY,\n+      DefaultValue = DEFAULT_FS_AZURE_TAIL_LATENCY_ANALYSIS_WINDOW_GRANULARITY)\n\nReview Comment:\n   Added min value for granularity.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:18:16.050+0000", "updated": "2025-10-28T18:18:16.050+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033648", "id": "18033648", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470599110\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n\nReview Comment:\n   Already in SlidingWindowHdrHistogram class\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:18:39.919+0000", "updated": "2025-10-28T18:18:39.919+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033649", "id": "18033649", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470608205\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n+        }\n+      } finally {\n+        LOCK.unlock();\n+      }\n+    }\n+    return singleton;\n+  }\n+\n+  /**\n+   * Updates the latency for a specific operation type.\n+   * @param latency Latency value to be recorded.\n+   * @param operationType Only applicable for read and write operations.\n+   */\n+  public void updateLatency(final AbfsRestOperationType operationType,\n+      final long latency) {\n+    SlidingWindowHdrHistogram histogram = operationLatencyMap.get(operationType);\n+    if (histogram == null) {\n+      LOG.debug(\"Creating new histogram for operation: {}\", operationType);\n+      histogram = new SlidingWindowHdrHistogram(\n+          configuration.getTailLatencyAnalysisWindowInMillis(),\n+          configuration.getTailLatencyAnalysisWindowGranularity(),\n+          configuration.getTailLatencyMinSampleSize(),\n+          configuration.getTailLatencyPercentile(),\n+          configuration.getTailLatencyMinDeviation(),\n+          HISTOGRAM_MAX_VALUE, HISTOGRAM_SIGNIFICANT_FIGURES, operationType);\n+      operationLatencyMap.put(operationType, histogram);\n+    } else {\n+      LOG.debug(\"Using existing histogram for operation: {}\",  operationType);\n+    }\n+    histogram.recordValue(latency);\n+    LOG.debug(\"Updated latency for operation: {} with latency: {}\",\n+        operationType, latency);\n+  }\n+\n+  /**\n+   * Gets the tail latency for a specific operation type.\n+   * @param operationType Only applicable for read and write operations.\n\nReview Comment:\n   why only for read, write operations? \r\n   we are not making the operationType check inside the method\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:20:56.228+0000", "updated": "2025-10-28T18:20:56.228+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033650", "id": "18033650", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470616013\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -531,6 +544,12 @@ private boolean executeHttpOperation(final int retryCount,\n       if (shouldUpdateCSTMetrics(statusCode) && !wasKnownExceptionThrown) {\n         intercept.updateMetrics(operationType, httpOperation);\n       }\n+\n+      // Update Tail Latency Tracker only for successful requests.\n+      if (tailLatencyTracker != null && statusCode <  HttpURLConnection.HTTP_MULT_CHOICE) {\n+        tailLatencyTracker.updateLatency(operationType,\n\nReview Comment:\n   Nice catch.\r\n   Added Lock while creation.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:22:37.547+0000", "updated": "2025-10-28T18:22:37.547+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033651", "id": "18033651", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2470619056\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.AbfsConfiguration;\n+\n+/**\n+ * Account Specific Latency Tracker.\n+ * This class tracks the latency of various operations like read, write etc for a single account.\n+ * It maintains a sliding window histogram for each operation type to analyze latency patterns over time.\n+ */\n+public class AbfsTailLatencyTracker {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      AbfsTailLatencyTracker.class);\n+  private static AbfsTailLatencyTracker singleton;\n+  private static final ReentrantLock LOCK = new ReentrantLock();\n+  private static final int HISTOGRAM_MAX_VALUE = 60_000;\n+  private static final int HISTOGRAM_SIGNIFICANT_FIGURES = 3;\n+  private final Map<AbfsRestOperationType, SlidingWindowHdrHistogram>\n+      operationLatencyMap = new HashMap<>();\n+  private final AbfsConfiguration configuration;\n+\n+  /**\n+   * Constructor to initialize the latency tracker with configuration.\n+   * @param abfsConfiguration Configuration settings for latency tracking.\n+   */\n+  public AbfsTailLatencyTracker(AbfsConfiguration abfsConfiguration) {\n+    this.configuration = abfsConfiguration;\n+    ScheduledExecutorService histogramRotatorThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Histogram-Rotator-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+    long rotationInterval = configuration.getTailLatencyAnalysisWindowInMillis()\n+        / configuration.getTailLatencyAnalysisWindowGranularity();\n+    histogramRotatorThread.scheduleAtFixedRate(this::rotateHistograms,\n+        rotationInterval, rotationInterval, TimeUnit.MILLISECONDS);\n+\n+\n+    ScheduledExecutorService tailLatencyComputationThread = Executors.newSingleThreadScheduledExecutor(\n+        r -> {\n+          Thread t = new Thread(r, \"Tail-Latency-Computation-Thread\");\n+          t.setDaemon(true);\n+          return t;\n+        });\n+\n+    long computationalInterval = configuration.getTailLatencyPercentileComputationIntervalInMillis();\n+    tailLatencyComputationThread.scheduleAtFixedRate(this::computePercentiles,\n+        computationalInterval, computationalInterval, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Rotates all histograms to ensure they reflect the most recent latency data.\n+   * This method is called periodically based on the configured rotation interval.\n+   */\n+  private void rotateHistograms() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.rotateIfNeeded();\n+    }\n+  }\n+\n+  /**\n+   * Computes the tail latency percentiles for all operation types.\n+   * This method is called periodically based on the configured computation interval.\n+   */\n+  private void computePercentiles() {\n+    for (SlidingWindowHdrHistogram histogram : operationLatencyMap.values()) {\n+      histogram.computeLatency();\n+    }\n+  }\n+\n+  /**\n+   * Creates a singleton object of the {@link SlidingWindowHdrHistogram}.\n+   * which is shared across all filesystem instances.\n+   * @param abfsConfiguration configuration set.\n+   * @return singleton object of intercept.\n+   */\n+  static AbfsTailLatencyTracker initializeSingleton(AbfsConfiguration abfsConfiguration) {\n+    if (singleton == null) {\n+      LOCK.lock();\n+      try {\n+        if (singleton == null) {\n+          singleton = new AbfsTailLatencyTracker(abfsConfiguration);\n+        }\n+      } finally {\n+        LOCK.unlock();\n+      }\n+    }\n+    return singleton;\n+  }\n+\n+  /**\n+   * Updates the latency for a specific operation type.\n+   * @param latency Latency value to be recorded.\n+   * @param operationType Only applicable for read and write operations.\n+   */\n+  public void updateLatency(final AbfsRestOperationType operationType,\n+      final long latency) {\n+    SlidingWindowHdrHistogram histogram = operationLatencyMap.get(operationType);\n+    if (histogram == null) {\n+      LOG.debug(\"Creating new histogram for operation: {}\", operationType);\n+      histogram = new SlidingWindowHdrHistogram(\n+          configuration.getTailLatencyAnalysisWindowInMillis(),\n+          configuration.getTailLatencyAnalysisWindowGranularity(),\n+          configuration.getTailLatencyMinSampleSize(),\n+          configuration.getTailLatencyPercentile(),\n+          configuration.getTailLatencyMinDeviation(),\n+          HISTOGRAM_MAX_VALUE, HISTOGRAM_SIGNIFICANT_FIGURES, operationType);\n+      operationLatencyMap.put(operationType, histogram);\n+    } else {\n+      LOG.debug(\"Using existing histogram for operation: {}\",  operationType);\n+    }\n+    histogram.recordValue(latency);\n+    LOG.debug(\"Updated latency for operation: {} with latency: {}\",\n+        operationType, latency);\n+  }\n+\n+  /**\n+   * Gets the tail latency for a specific operation type.\n+   * @param operationType Only applicable for read and write operations.\n\nReview Comment:\n   Updated\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T18:23:22.496+0000", "updated": "2025-10-28T18:23:22.496+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18033666", "id": "18033666", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3458139061\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 44s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 45s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 178 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 14s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 44 new + 3 unchanged - 0 fixed = 47 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 34 new + 1472 unchanged - 0 fixed = 1506 total (was 1472)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 33 new + 1413 unchanged - 0 fixed = 1446 total (was 1413)  |\r\n   | -1 :x: |  spotbugs  |   0m 44s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 5 new + 177 unchanged - 1 fixed = 182 total (was 178)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 10s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  60m 40s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Possible null pointer dereference of histogram in org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker.updateLatency(AbfsRestOperationType, long)  Dereferenced at AbfsTailLatencyTracker.java:histogram in org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker.updateLatency(AbfsRestOperationType, long)  Dereferenced at AbfsTailLatencyTracker.java:[line 149] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 81] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux c4d12ec6b6d0 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3ca8f94cbd461d8904d9c655d446c2927dac0cd5 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/testReport/ |\r\n   | Max. process+thread count | 611 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/4/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-28T19:25:47.744+0000", "updated": "2025-10-28T19:25:47.744+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034128", "id": "18034128", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2477231657\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -359,7 +369,7 @@ void completeExecute(TracingContext tracingContext)\n   @VisibleForTesting\n   void updateBackoffMetrics(int retryCount, int statusCode) {\n     if (abfsBackoffMetrics != null) {\n-      if (statusCode < HttpURLConnection.HTTP_OK\n\nReview Comment:\n   This change can we reverted.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -453,7 +463,7 @@ private boolean executeHttpOperation(final int retryCount,\n       }\n         incrementCounter(AbfsStatistic.GET_RESPONSES, 1);\n       //Only increment bytesReceived counter when the status code is 2XX.\n-      if (httpOperation.getStatusCode() >= HttpURLConnection.HTTP_OK\n\nReview Comment:\n   same as above\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AbstractAbfsIntegrationTest;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_NETWORKING_LIBRARY;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ITestAbfsTailLatencyTracker extends AbstractAbfsIntegrationTest {\n+\n+  protected ITestAbfsTailLatencyTracker() throws Exception {\n+  }\n+\n+  @Test\n+  public void testTailLatencyTimeoutEnabled() throws Exception {\n\nReview Comment:\n   Java doc missing. Please add it to all newly added test cases\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-30T09:59:16.677+0000", "updated": "2025-10-30T09:59:16.677+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034320", "id": "18034320", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2480181549\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -266,5 +266,15 @@ public final class FileSystemConfigurations {\n \n   public static final boolean DEFAULT_FS_AZURE_ENABLE_CREATE_BLOB_IDEMPOTENCY = true;\n \n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT = false;\n+  public static final int DEFAULT_FS_AZURE_TAIL_LATENCY_PERCENTILE = 99;\n\nReview Comment:\n   I am not finding an easy way to make this change. Will add a work item for this improvement and take it up in follow up items.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T05:11:13.819+0000", "updated": "2025-10-31T05:11:13.819+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034339", "id": "18034339", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3471759836\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  21m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 44s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 177 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  13m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 12s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 25 new + 3 unchanged - 0 fixed = 28 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 18s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 32 new + 1518 unchanged - 0 fixed = 1550 total (was 1518)  |\r\n   | -1 :x: |  javadoc  |   0m 16s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 31 new + 1412 unchanged - 0 fixed = 1443 total (was 1412)  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 4 new + 176 unchanged - 1 fixed = 180 total (was 177)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  3s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  59m 35s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   |  |  new org.apache.hadoop.fs.azurebfs.services.AbfsTailLatencyTracker(AbfsConfiguration) may expose internal representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:representation by storing an externally mutable object into AbfsTailLatencyTracker.configuration  At AbfsTailLatencyTracker.java:[line 55] |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:new org.apache.hadoop.fs.azurebfs.services.SlidingWindowHdrHistogram(long, int, int, int, int, long, int, AbfsRestOperationType)  At SlidingWindowHdrHistogram.java:[line 95] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 4e580718cb8c 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / a57f2afea1b3be581f31a6595e498ec2b2a42e3a |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/testReport/ |\r\n   | Max. process+thread count | 633 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/5/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T08:12:08.548+0000", "updated": "2025-10-31T08:12:08.548+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034353", "id": "18034353", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2480654128\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -453,7 +463,7 @@ private boolean executeHttpOperation(final int retryCount,\n       }\n         incrementCounter(AbfsStatistic.GET_RESPONSES, 1);\n       //Only increment bytesReceived counter when the status code is 2XX.\n-      if (httpOperation.getStatusCode() >= HttpURLConnection.HTTP_OK\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java:\n##########\n@@ -359,7 +369,7 @@ void completeExecute(TracingContext tracingContext)\n   @VisibleForTesting\n   void updateBackoffMetrics(int retryCount, int statusCode) {\n     if (abfsBackoffMetrics != null) {\n-      if (statusCode < HttpURLConnection.HTTP_OK\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/ITestAbfsTailLatencyTracker.java:\n##########\n@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AbstractAbfsIntegrationTest;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_REQUEST_TIMEOUT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ENABLE_TAIL_LATENCY_TRACKER;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_NETWORKING_LIBRARY;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+public class ITestAbfsTailLatencyTracker extends AbstractAbfsIntegrationTest {\n+\n+  protected ITestAbfsTailLatencyTracker() throws Exception {\n+  }\n+\n+  @Test\n+  public void testTailLatencyTimeoutEnabled() throws Exception {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T09:15:18.495+0000", "updated": "2025-10-31T09:15:18.495+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034373", "id": "18034373", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2480943824\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java:\n##########\n@@ -1949,7 +1950,7 @@ public boolean isTailLatencyTrackerEnabled() {\n   }\n \n   public boolean isTailLatencyRequestTimeoutEnabled() {\n-    return isTailLatencyRequestTimeoutEnabled && isTailLatencyTrackerEnabled\n+    return isTailLatencyTrackerEnabled && isTailLatencyRequestTimeoutEnabled\n\nReview Comment:\n   javadocs for warnings can be added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T10:32:31.656+0000", "updated": "2025-10-31T10:32:31.656+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034406", "id": "18034406", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#discussion_r2481457271\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsTailLatencyTracker.java:\n##########\n@@ -131,11 +139,11 @@ public void updateLatency(final AbfsRestOperationType operationType,\n         if (operationLatencyMap.get(operationType) == null) {\n           LOG.debug(\"Creating new histogram for operation: {}\", operationType);\n           histogram = new SlidingWindowHdrHistogram(\n-              configuration.getTailLatencyAnalysisWindowInMillis(),\n-              configuration.getTailLatencyAnalysisWindowGranularity(),\n-              configuration.getTailLatencyMinSampleSize(),\n-              configuration.getTailLatencyPercentile(),\n-              configuration.getTailLatencyMinDeviation(),\n+              talLatencyAnalysisWindowInMillis,\n\nReview Comment:\n   nit: spelling of tail\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T13:38:21.580+0000", "updated": "2025-10-31T13:38:21.580+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034411", "id": "18034411", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3473362007\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 18s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 45s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 177 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 21 new + 1517 unchanged - 1 fixed = 1538 total (was 1518)  |\r\n   | -1 :x: |  javadoc  |   0m 17s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 19 new + 1412 unchanged - 0 fixed = 1431 total (was 1412)  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 2 new + 176 unchanged - 1 fixed = 178 total (was 177)  |\r\n   | +1 :green_heart: |  shadedclient  |  15m 45s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 10s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  63m  1s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 7c5c2cb63961 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 56129accd046c6ae237402d7f64894da6ba44046 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/testReport/ |\r\n   | Max. process+thread count | 639 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/6/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T14:33:39.488+0000", "updated": "2025-10-31T14:33:39.488+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13631778/comment/18034419", "id": "18034419", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8043:\nURL: https://github.com/apache/hadoop/pull/8043#issuecomment-3473551869\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 3 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  33m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 48s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 43s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   1m 25s | [/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/branch-spotbugs-hadoop-tools_hadoop-azure-warnings.html) |  hadoop-tools/hadoop-azure in trunk has 177 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  28m 33s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 37s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 31s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-21.0.7+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 generated 21 new + 1517 unchanged - 1 fixed = 1538 total (was 1518)  |\r\n   | -1 :x: |  javadoc  |   0m 28s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-17.0.15+6-Ubuntu-0ubuntu120.04 with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 generated 19 new + 1412 unchanged - 0 fixed = 1431 total (was 1412)  |\r\n   | -1 :x: |  spotbugs  |   1m 23s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 2 new + 176 unchanged - 1 fixed = 178 total (was 177)  |\r\n   | +1 :green_heart: |  shadedclient  |  26m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  4s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 105m 11s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Unknown bug pattern CT_CONSTRUCTOR_THROW in new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:new org.apache.hadoop.fs.azurebfs.services.AbfsAHCHttpOperation(URL, String, List, Duration, Duration, long, AbfsApacheHttpClient, AbfsClient)  At AbfsAHCHttpOperation.java:[line 123] |\r\n   |  |  Unknown bug pattern AT_STALE_THREAD_WRITE_OF_PRIMITIVE in org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation.executeHttpOperation(int, TracingContext)  At AbfsRestOperation.java:[line 539] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8043 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle |\r\n   | uname | Linux 86ea63abc892 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 56129accd046c6ae237402d7f64894da6ba44046 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/testReport/ |\r\n   | Max. process+thread count | 634 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8043/7/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-31T15:17:41.571+0000", "updated": "2025-10-31T15:17:41.571+0000"}], "maxResults": 59, "total": 59, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}