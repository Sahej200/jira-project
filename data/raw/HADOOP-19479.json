{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13610579", "self": "https://issues.apache.org/jira/rest/api/2/issue/13610579", "key": "HADOOP-19479", "fields": {"summary": "S3A: Deadlock in multipart upload", "description": "Reproduced while testing system resilience and turning S3 network off (introduced a network partition to the list of IP addresses S3 uses) - but given it's seemingly timers related stack traces, I'd guess it could happen any time?\r\n\r\n\r\n{code:java}\r\nFound one Java-level deadlock:\r\n=============================\r\n\"sdk-ScheduledExecutor-2-3\":\r\n\u00a0 waiting to lock monitor 0x00007f5c880a8630 (object 0x0000000315523c78, a java.lang.Object),\r\n\u00a0 which is held by \"sdk-ScheduledExecutor-2-4\"\r\n\"sdk-ScheduledExecutor-2-4\":\r\n\u00a0 waiting to lock monitor 0x00007f5c7c016700 (object 0x0000000327800000, a org.apache.hadoop.fs.s3a.S3ABlockOutputStream),\r\n\u00a0 which is held by \"io-compute-blocker-15\"\r\n\"io-compute-blocker-15\":\r\n\u00a0 waiting to lock monitor 0x00007f5c642ae900 (object 0x00000003af0001d8, a java.lang.Object),\r\n\u00a0 which is held by \"sdk-ScheduledExecutor-2-3\"\r\nJava stack information for the threads listed above:\r\n===================================================\r\n\"sdk-ScheduledExecutor-2-3\":\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.interrupt(java.base@21/Thread.java:1717)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - waiting to lock <0x0000000315523c78> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.timers.SyncTimeoutTask.run(SyncTimeoutTask.java:60)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x00000003af0001d8> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(java.base@21/Executors.java:572)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(java.base@21/FutureTask.java:317)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(java.base@21/ScheduledThreadPoolExecutor.java:304)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@21/ThreadPoolExecutor.java:1144)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@21/ThreadPoolExecutor.java:642)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.runWith(java.base@21/Thread.java:1596)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(java.base@21/Thread.java:1583)\r\n\"sdk-ScheduledExecutor-2-4\":\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.getActiveBlock(S3ABlockOutputStream.java:304)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - waiting to lock <0x0000000327800000> (a org.apache.hadoop.fs.s3a.S3ABlockOutputStream)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.close(S3ABlockOutputStream.java:485)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.util.HadoopPositionOutputStream.close(HadoopPositionOutputStream.java:66)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.nio.channels.Channels$WritableByteChannelImpl.implCloseChannel(java.base@21/Channels.java:404)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.nio.channels.spi.AbstractInterruptibleChannel$1.interrupt(java.base@21/AbstractInterruptibleChannel.java:163)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x00000003af0002a0> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.interrupt(java.base@21/Thread.java:1722)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x0000000315523c78> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.timers.SyncTimeoutTask.run(SyncTimeoutTask.java:60)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x00000003af0002e0> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(java.base@21/Executors.java:572)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(java.base@21/FutureTask.java:317)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(java.base@21/ScheduledThreadPoolExecutor.java:304)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@21/ThreadPoolExecutor.java:1144)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@21/ThreadPoolExecutor.java:642)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.runWith(java.base@21/Thread.java:1596)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(java.base@21/Thread.java:1583)\r\n\"io-compute-blocker-15\":\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.timers.SyncTimeoutTask.cancel(SyncTimeoutTask.java:74)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - waiting to lock <0x00000003af0001d8> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.timers.ApiCallTimeoutTracker.cancel(ApiCallTimeoutTracker.java:53)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:77)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:42)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:78)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:40)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptMetricCollectionStage.execute(ApiCallAttemptMetricCollectionStage.java:55)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptMetricCollectionStage.execute(ApiCallAttemptMetricCollectionStage.java:39)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:81)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:36)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:56)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:36)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.executeWithTimer(ApiCallTimeoutTrackingStage.java:80)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:60)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:42)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:50)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:32)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:224)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:103)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:173)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$1(BaseSyncClientHandler.java:80)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler$$Lambda/0x00007f5d2cb20ca8.get(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:182)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:74)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:45)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:53)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.services.s3.DefaultS3Client.createMultipartUpload(DefaultS3Client.java:1463)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.services.s3.DelegatingS3Client.lambda$createMultipartUpload$4(DelegatingS3Client.java:1232)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.services.s3.DelegatingS3Client$$Lambda/0x00007f5d2d316118.apply(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.services.s3.internal.crossregion.S3CrossRegionSyncClient.invokeOperation(S3CrossRegionSyncClient.java:67)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at software.amazon.awssdk.services.s3.DelegatingS3Client.createMultipartUpload(DelegatingS3Client.java:1232)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$initiateMultipartUpload$30(S3AFileSystem.java:4705)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3AFileSystem$$Lambda/0x00007f5d2d315ef8.get(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDurationOfSupplier(IOStatisticsBinding.java:651)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3AFileSystem.initiateMultipartUpload(S3AFileSystem.java:4703)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.WriteOperationHelper.lambda$initiateMultiPartUpload$0(WriteOperationHelper.java:283)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.WriteOperationHelper$$Lambda/0x00007f5d2d30e230.apply(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:122)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.Invoker.lambda$retry$4(Invoker.java:376)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.Invoker$$Lambda/0x00007f5d2d2dd6a0.apply(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:468)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:372)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:347)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.WriteOperationHelper.retry(WriteOperationHelper.java:207)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.WriteOperationHelper.initiateMultiPartUpload(WriteOperationHelper.java:278)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.lambda$new$0(S3ABlockOutputStream.java:904)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload$$Lambda/0x00007f5d2d30e000.apply(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:547)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:528)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding$$Lambda/0x00007f5d2ca3c918.apply(Unknown Source)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:449)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream$MultiPartUpload.<init>(S3ABlockOutputStream.java:902)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.initMultipartUpload(S3ABlockOutputStream.java:462)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.uploadCurrentBlock(S3ABlockOutputStream.java:439)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x0000000327800000> (a org.apache.hadoop.fs.s3a.S3ABlockOutputStream)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.s3a.S3ABlockOutputStream.write(S3ABlockOutputStream.java:413)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x0000000327800000> (a org.apache.hadoop.fs.s3a.S3ABlockOutputStream)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.io.DataOutputStream.write(java.base@21/DataOutputStream.java:115)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x0000000327800208> (a org.apache.hadoop.fs.FSDataOutputStream)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.util.HadoopPositionOutputStream.write(HadoopPositionOutputStream.java:50)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.nio.channels.Channels$WritableByteChannelImpl.write(java.base@21/Channels.java:392)\r\n\u00a0 \u00a0 \u00a0 \u00a0 - locked <0x00000003afab3da8> (a java.lang.Object)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.bytes.ConcatenatingByteBufferCollector.writeAllTo(ConcatenatingByteBufferCollector.java:77)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.ParquetFileWriter.writeColumnChunk(ParquetFileWriter.java:1338)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.ParquetFileWriter.writeColumnChunk(ParquetFileWriter.java:1259)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.ColumnChunkPageWriteStore$ColumnChunkPageWriter.writeToFileWriter(ColumnChunkPageWriteStore.java:408)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.ColumnChunkPageWriteStore.flushToFileWriter(ColumnChunkPageWriteStore.java:675)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.InternalParquetRecordWriter.flushRowGroupToStore(InternalParquetRecordWriter.java:210)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.InternalParquetRecordWriter.checkBlockSizeReached(InternalParquetRecordWriter.java:178)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.InternalParquetRecordWriter.write(InternalParquetRecordWriter.java:154)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.parquet.hadoop.ParquetWriter.write(ParquetWriter.java:428)\r\nFound 1 deadlock.\r\n {code}", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13610579/comment/17932661", "id": "17932661", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "Good Find!\r\n\r\nlooks like one thread has blocked in the initMultipartUpload request due to the far end not responding, and the timeout thread is trying to close() the stream in a different thread. and that is causing the deadlock.\r\n\r\nmaybe we could pull the initMultipartUpload() call out of the sync block, so the network IO isn't being done there. Tricky though...I wouldn't want to make this a last minute change for 3.4.2. That output stream is complicated beast. ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-03-05T14:50:42.771+0000", "updated": "2025-03-05T14:50:42.771+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610579/comment/17932725", "id": "17932725", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "maybe move off simple sync to try to acquire a lock with timeouts? it'd make close() more robust, even if the action on timeout is failure. which, given there are clearly network problems, is the right thing to do.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-03-05T19:42:26.322+0000", "updated": "2025-03-05T19:42:26.322+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610579/comment/17951137", "id": "17951137", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "body": "hi, is there a workaround we could use? e.g. can we adjust the timeout to not close and cause the deadlock?\r\n\r\nwhile the risk of S3 (or network routes to it) being not available is fairly low, the impact of this is rather high as it freezes the whole system and does not recover after the network recovers", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-13T08:50:49.746+0000", "updated": "2025-05-13T08:50:49.746+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610579/comment/17951190", "id": "17951190", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "Afraid I don't even know how a reference to the s3a output stream is even getting down as far as the aws sdk. And any changes in the SDK are way out of scope.\r\n\r\ntry turning down the s3a retry interval and count (its in the docs) so that the multipart upload attempt will fail before the SDK starts timing out. ", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-05-13T13:12:28.050+0000", "updated": "2025-05-13T13:12:28.050+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610579/comment/17951211", "id": "17951211", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "body": "if you're talking about per request retries vs per connection retry - would new requests, however small the retry settings, not incur the same error once connection timeout kicks in?\r\n\r\ncontext - in our application we expect new rows to be added to the parquet output at all times and very frequently - essentially it's a never ending flow of data to rotating parquet files\r\n\r\nit is ok to fail to export to s3 if network fails, but we mustn't stop the host service as it's primary purpose is other than just exporting this data", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-13T15:12:07.464+0000", "updated": "2025-05-13T15:14:17.891+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610579/comment/17951382", "id": "17951382", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "body": "Hi, I'm rather new to the codebase here, but it seems to me the issue is due to all of the synchronised calls in the S3ABlockOutputStream - \r\n\r\nit seems to try:\r\n 1. to create multipart uploader to upload a block\r\n 2. which gets stuck and tries to cancel itself\r\n 3. cancelling tries to close the uploader\r\n 4. closing the uploader tries to upload the last block, but it is stuck in step 2\r\n\r\nas an idea, would it be better to skip uploading the last block if the upload is in progress already?\r\n\r\nsomething like this: https://github.com/svalaskevicius/hadoop/commit/dc8898fec040a499ae0d6d860e33e9e952c54c92", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=rakatan", "name": "rakatan", "key": "rakatan", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Sarunas Valaskevicius", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-05-14T10:24:26.889+0000", "updated": "2025-05-14T11:55:34.718+0000"}], "maxResults": 6, "total": 6, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}