{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13632245", "self": "https://issues.apache.org/jira/rest/api/2/issue/13632245", "key": "HADOOP-19733", "fields": {"summary": "S3A: Credentials provider classes not found despite setting `fs.s3a.classloader.isolation` to `false`", "description": "HADOOP-18993 added the option `fs.s3a.classloader.isolation` to support, for example, a Spark job using an AWS credentials provider class that is bundled into the Spark job JAR. In testing this, the AWS credentials provider classes are still not found.\r\n\r\nI think the cause is:\r\n * `fs.s3a.classloader.isolation` is implemented by setting (or not setting) a classloader on the `Configuration`\r\n * However, code paths to load AWS credential provider call `S3AUtils.getInstanceFromReflection`, which uses the classloader that loaded the S3AUtils class. That's likely to be the built-in application classloader, which won't be able to load classes in a Spark job JAR.\r\n\r\nAnd the fix seems small:\r\n * Change `S3AUtils.getInstanceFromReflection` to load classes using the `Configuration`'s classloader. Luckily we already have the Configuration in this method.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032249", "id": "18032249", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "body": "I haven't contributed to Hadoop or other Apache projects before, but this approachable for a first contribution. I'll open a PR.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-22T20:36:34.829+0000", "updated": "2025-10-22T20:49:13.366+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032340", "id": "18032340", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brandonvin opened a new pull request, #8048:\nURL: https://github.com/apache/hadoop/pull/8048\n\n   \u2026lassloader\r\n   \r\n   \r\n   \r\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   \r\n   Follow-up to [HADOOP-18993](https://issues.apache.org/jira/browse/HADOOP-18993) and [HADOOP-19733](https://issues.apache.org/jira/browse/HADOOP-19733) before it.\r\n   \r\n   With `fs.s3a.classloader.isolation` set to `false` in a Spark application, it was still impossible to load a credentials provider class from the Spark application jar.\r\n   \r\n   `fs.s3a.classloader.isolation` works by saving a reference to the intended classloader in the `Configuration`.\r\n   \r\n   However, loading credentials providers goes through\r\n   `S3AUtils#getInstanceFromReflection`, which always used the classloader that loaded `S3AUtils`.\r\n   \r\n   With this patch, credentials providers will be loaded using the `Configuration`'s classloader.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Unit tests in `org.apache.hadoop.fs.s3a.ITestS3AFileSystemIsolatedClassloader`.\r\n   \r\n   Manual testing in a Spark application.\r\n   \r\n   ### For code changes:\r\n   \r\n   - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [x] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [x] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [x] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T04:13:15.711+0000", "updated": "2025-10-23T04:13:15.711+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032344", "id": "18032344", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brandonvin commented on code in PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#discussion_r2453905622\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS\n     }\n   }\n \n-  private Map<String, String> mapOf() {\n-    return new HashMap<>();\n-  }\n-\n-  private Map<String, String> mapOf(String key, String value) {\n-    HashMap<String, String> m = new HashMap<>();\n-    m.put(key, value);\n-    return m;\n-  }\n\nReview Comment:\n   Since I added test cases that set 2 key-value pairs, I switched to `Map.of` instead of extending these. Not sure if there was a reason to avoid `Map.of` here.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T04:43:50.648+0000", "updated": "2025-10-23T04:43:50.648+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032345", "id": "18032345", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#issuecomment-3435132657\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  24m 19s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-aws.txt) |  hadoop-tools/hadoop-aws: The patch generated 31 new + 4 unchanged - 0 fixed = 35 total (was 4)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) |  hadoop-tools/hadoop-aws generated 2 new + 188 unchanged - 0 fixed = 190 total (was 188)  |\r\n   | +1 :green_heart: |  shadedclient  |  15m  9s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   1m 57s | [/patch-unit-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/patch-unit-hadoop-tools_hadoop-aws.txt) |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 19s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  63m 28s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-aws |\r\n   |  |  Nullcheck of conf at line 655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:[line 645] |\r\n   |  |  Non-virtual method call in org.apache.hadoop.fs.s3a.auth.SignerFactory.createSigner(String, String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:[line 125] |\r\n   | Failed junit tests | hadoop.fs.s3a.auth.TestSignerManager |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8048 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 573c49df2825 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 032c335082f24aef12ee3e002ae1cfd9c5f40507 |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/testReport/ |\r\n   | Max. process+thread count | 610 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/1/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T05:17:39.742+0000", "updated": "2025-10-23T05:17:39.742+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032358", "id": "18032358", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#issuecomment-3435205771\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 1 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  25m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 17s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 23s |  |  trunk passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  trunk passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 47s | [/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/branch-spotbugs-hadoop-tools_hadoop-aws-warnings.html) |  hadoop-tools/hadoop-aws in trunk has 188 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  14m 50s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 20s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 10s | [/results-checkstyle-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-aws.txt) |  hadoop-tools/hadoop-aws: The patch generated 12 new + 4 unchanged - 0 fixed = 16 total (was 4)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 23s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 16s |  |  the patch passed with JDK Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04  |\r\n   | -1 :x: |  spotbugs  |   0m 46s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) |  hadoop-tools/hadoop-aws generated 2 new + 188 unchanged - 0 fixed = 190 total (was 188)  |\r\n   | +1 :green_heart: |  shadedclient  |  14m  2s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  |   2m  0s | [/patch-unit-hadoop-tools_hadoop-aws.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/patch-unit-hadoop-tools_hadoop-aws.txt) |  hadoop-aws in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 20s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  63m 47s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-aws |\r\n   |  |  Nullcheck of conf at line 655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:655 of value previously dereferenced in org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At S3AUtils.java:[line 645] |\r\n   |  |  Non-virtual method call in org.apache.hadoop.fs.s3a.auth.SignerFactory.createSigner(String, String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:String) passes null for non-null parameter of org.apache.hadoop.fs.s3a.S3AUtils.getInstanceFromReflection(String, Configuration, URI, Class, String, String)  At SignerFactory.java:[line 125] |\r\n   | Failed junit tests | hadoop.fs.s3a.auth.TestSignerManager |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/8048 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 55f7cbac0d20 5.15.0-156-generic #166-Ubuntu SMP Sat Aug 9 00:02:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 249aef5213fa039d252e7f7ae03c060b6c87d94f |\r\n   | Default Java | Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-21-openjdk-amd64:Ubuntu-21.0.7+6-Ubuntu-0ubuntu120.04 /usr/lib/jvm/java-17-openjdk-amd64:Ubuntu-17.0.15+6-Ubuntu-0ubuntu120.04 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/testReport/ |\r\n   | Max. process+thread count | 616 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-8048/2/console |\r\n   | versions | git=2.25.1 maven=3.9.11 spotbugs=4.9.7 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T05:46:12.703+0000", "updated": "2025-10-23T05:46:12.703+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032474", "id": "18032474", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#discussion_r2455036391\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -37,10 +46,33 @@\n  */\n public class ITestS3AFileSystemIsolatedClassloader extends AbstractS3ATestBase {\n \n+  private static String customClassName = \"custom.class.name\";\n+\n+  private static class CustomCredentialsProvider implements AwsCredentialsProvider {\n+\n+      public CustomCredentialsProvider() {\n+      }\n+\n+      @Override\n+      public AwsCredentials resolveCredentials() {\n+          return null;\n+      }\n+\n+  }\n+\n   private static class CustomClassLoader extends ClassLoader {\n   }\n \n-  private final ClassLoader customClassLoader = new CustomClassLoader();\n+  private final ClassLoader customClassLoader = spy(new CustomClassLoader());\n+  {\n+    try {\n\nReview Comment:\n   this is a nice way to simulate classloader pain.\r\n   \n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -28,6 +29,14 @@\n \n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.s3a.impl.InstantiationIOException;\n+\n+import software.amazon.awssdk.auth.credentials.AwsCredentials;\n\nReview Comment:\n   nit: put the amazon imports in the same group as the junit ones\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -100,11 +122,26 @@ public void defaultIsolatedClassloader() throws IOException {\n               .isEqualTo(fs.getClass().getClassLoader())\n               .describedAs(\"the classloader that loaded the fs\");\n     });\n+\n+    Throwable thrown = Assertions.catchThrowable(() -> {\n\nReview Comment:\n   Use our `LambdaTestUtils.intercept()`; it's like the spark one and does the casting checks\r\n   \r\n   ```\r\n   InstantiationIOException ex = intercept(InstantiationIOException.class, () -> { assert...})\r\n   ```\r\n   we have a `assertExceptionContains` to look at the inner stuff, but the assert of L136 is fine.\r\n   \r\n   \n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -115,11 +152,31 @@ public void isolatedClassloader() throws IOException {\n               .isEqualTo(fs.getClass().getClassLoader())\n               .describedAs(\"the classloader that loaded the fs\");\n     });\n+\n+    Throwable thrown = Assertions.catchThrowable(() -> {\n\nReview Comment:\n   again `intercept()` and cut the assert at L163\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS\n     }\n   }\n \n-  private Map<String, String> mapOf() {\n-    return new HashMap<>();\n-  }\n-\n-  private Map<String, String> mapOf(String key, String value) {\n-    HashMap<String, String> m = new HashMap<>();\n-    m.put(key, value);\n-    return m;\n-  }\n\nReview Comment:\n   It's because we only switched to java17 yesterday! And in trunk only.\r\n   \r\n   If you want to see this change in Hadoop 3.4.3 it'll still need to be java8 code, so this needs to be restored. Otherwise: trunk/3.5.0 only\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T13:03:14.097+0000", "updated": "2025-10-23T13:03:14.097+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032528", "id": "18032528", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Ok, will also update the custom signer loading to use the configuration, for consistency.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=brandonvin", "name": "brandonvin", "key": "brandonvin", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Brandon", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-23T16:33:11.604+0000", "updated": "2025-10-23T16:33:11.604+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13632245/comment/18032581", "id": "18032581", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "brandonvin commented on code in PR #8048:\nURL: https://github.com/apache/hadoop/pull/8048#discussion_r2456994430\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemIsolatedClassloader.java:\n##########\n@@ -77,19 +109,9 @@ private void assertInNewFilesystem(Map<String, String> confToSet, Consumer<FileS\n     }\n   }\n \n-  private Map<String, String> mapOf() {\n-    return new HashMap<>();\n-  }\n-\n-  private Map<String, String> mapOf(String key, String value) {\n-    HashMap<String, String> m = new HashMap<>();\n-    m.put(key, value);\n-    return m;\n-  }\n\nReview Comment:\n   Thanks, makes sense!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-23T19:44:03.691+0000", "updated": "2025-10-23T19:44:03.691+0000"}], "maxResults": 8, "total": 8, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/4", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg", "name": "Minor", "id": "4"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}