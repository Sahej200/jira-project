{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13607595", "self": "https://issues.apache.org/jira/rest/api/2/issue/13607595", "key": "HADOOP-19450", "fields": {"summary": "[ABFS] Rename/Create path idempotency client-level resolution", "description": "CreatePath and RenamePath APIs are idempotent as subsequent retries on same resource don\u2019t change the server state. However, when client experiences connection break on the CreatePath and the RenamePath APIs, client cannot make sense if the request is accepted by the server or not.\u00a0\r\n\r\nOn connection failure, the client retries the request. The server might return 404 (sourceNotFound) in case of RenamePath API and 409 (pathAlreadyExists) in case of CreatePath (overwrite=false) API. Now the client doesn\u2019t have a path forward. Reason being, in case of CreatePath, client doesn\u2019t know if the path was created on the original request or the path was already there for some other request, in case of RenamePath, client doesn\u2019t know if the source was removed because of the original-try or it was not there on the first place.\u00a0\r\n\r\n\u00a0", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=bhattmanish98", "name": "bhattmanish98", "key": "JIRAUSER306911", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Manish Bhatt", "active": true, "timeZone": "Asia/Kolkata"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17924629", "id": "17924629", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 opened a new pull request, #7364:\nURL: https://github.com/apache/hadoop/pull/7364\n\n   Description\r\n   -----------------------------------------------------------------------------------------------------------------------------------------------\r\n   CreatePath and RenamePath APIs are idempotent as subsequent retries on same resource don\u2019t change the server state[[1]](bookmark://rfcIdempotency). However, when client experiences connection break on the CreatePath and the RenamePath APIs, client cannot make sense if the request is accepted by the server or not. \r\n   \r\n   On connection failure, the client retries the request. The server might return 404 (sourceNotFound) in case of RenamePath API and 409 (pathAlreadyExists) in case of CreatePath (overwrite=false) API. Now the client doesn\u2019t have a path forward. Reason being, in case of CreatePath, client doesn\u2019t know if the path was created on the original request or the path was already there for some other request, in case of RenamePath, client doesn\u2019t know if the source was removed because of the original-try or it was not there on the first place.\r\n   \r\n   Proposed Solution\r\n   ---------------------------------------------------------------------------------------------------------------------------------------------\r\n   Driver will send addition header \"x-ms-client-transaction-id\" which will store by the server. In case first call fails because of time out and retry happens and server throw source not found (in case of rename) and path already exist (in case of create call). Driver will do list call on the path and check whether the \"x-ms-client-transaction-id\" returned by server same as what driver has at its end. In such case driver will return success to the caller.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-06T17:00:06.295+0000", "updated": "2025-02-06T17:00:06.295+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17924667", "id": "17924667", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2640770705\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  42m 13s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 52s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/1/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 3 unchanged - 0 fixed = 4 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 34s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 131m 32s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 7d4c7cf69c8d 5.15.0-125-generic #135-Ubuntu SMP Fri Sep 27 13:53:58 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e2eba214503db812a4f2f7e19f6e1417ba227929 |\r\n   | Default Java | Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/1/testReport/ |\r\n   | Max. process+thread count | 541 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-06T19:13:04.042+0000", "updated": "2025-02-06T19:13:04.042+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17924681", "id": "17924681", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2640874156\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 36s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 49s |  |  trunk passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  trunk passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  trunk passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 58s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/2/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 3 unchanged - 0 fixed = 4 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 131m 55s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 272fc60f98e1 5.15.0-125-generic #135-Ubuntu SMP Fri Sep 27 13:53:58 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 086f2440907ac4afdac54a324d89f5448d48e5d7 |\r\n   | Default Java | Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.25+9-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_432-8u432-ga~us1-0ubuntu2~20.04-ga |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/2/testReport/ |\r\n   | Max. process+thread count | 635 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-06T20:01:18.288+0000", "updated": "2025-02-06T20:01:18.288+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17926761", "id": "17926761", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2656449749\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  18m 58s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m  4s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m  5s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/3/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 4 new + 3 unchanged - 0 fixed = 7 total (was 3)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   2m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 37s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 40s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 151m 41s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux f8992abbb234 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / bef0bdd0b1810f5527ef10e45912450d380ac822 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/3/testReport/ |\r\n   | Max. process+thread count | 541 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-13T12:27:05.159+0000", "updated": "2025-02-13T12:27:05.159+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927493", "id": "17927493", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2661397298\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 767, Failures: 0, Errors: 0, Skipped: 135\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 1\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 770, Failures: 0, Errors: 0, Skipped: 90\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 1\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 13\r\n   [WARNING] Tests run: 609, Failures: 0, Errors: 0, Skipped: 196\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 767, Failures: 0, Errors: 0, Skipped: 143\r\n   [WARNING] Tests run: 124, Failures: 0, Errors: 0, Skipped: 2\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 612, Failures: 0, Errors: 0, Skipped: 139\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 13\r\n   [WARNING] Tests run: 606, Failures: 0, Errors: 0, Skipped: 197\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 609, Failures: 0, Errors: 0, Skipped: 140\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 12\r\n   [WARNING] Tests run: 607, Failures: 0, Errors: 0, Skipped: 157\r\n   [WARNING] Tests run: 124, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 641, Failures: 0, Errors: 0, Skipped: 141\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 1\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 13\r\n   [WARNING] Tests run: 606, Failures: 0, Errors: 0, Skipped: 195\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-16T11:57:25.138+0000", "updated": "2025-02-16T11:57:25.138+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927514", "id": "17927514", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2661446638\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  38m 27s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 38s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 38s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 21s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  37m 42s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/4/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 5 unchanged - 0 fixed = 7 total (was 5)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 58s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 40s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 128m  4s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 1d46d30411df 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 13d87cf6c49947be01e8d7a1ac1f15ae5324bd07 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/4/testReport/ |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-16T14:01:45.639+0000", "updated": "2025-02-16T14:01:45.639+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927515", "id": "17927515", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2661452926\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 47s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 6 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  38m  3s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 30s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 31s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  37m 52s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/5/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 5 unchanged - 0 fixed = 7 total (was 5)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m  5s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 44s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 127m 55s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 9d830329e4c6 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c05dd77483795b7442c42e7e6bf31d4fd067f7bb |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/5/testReport/ |\r\n   | Max. process+thread count | 594 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-16T14:16:46.071+0000", "updated": "2025-02-16T14:16:46.071+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927534", "id": "17927534", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2661513389\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 48s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 6 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m  4s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m  0s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 22s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 46s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 17s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 09e19410ac01 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 73743981341184e0a690bfa050f9ca27c7693169 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/6/testReport/ |\r\n   | Max. process+thread count | 579 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-16T16:32:40.736+0000", "updated": "2025-02-16T16:32:40.736+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927714", "id": "17927714", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1957984519\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1876,7 +1875,7 @@ private long extractContentLength(AbfsHttpOperation op) {\n     long contentLength;\n     String contentLengthHeader = op.getResponseHeader(\n         HttpHeaderConfigurations.CONTENT_LENGTH);\n-    if (!contentLengthHeader.equals(EMPTY_STRING)) {\n+    if (!Strings.isNullOrEmpty(contentLengthHeader)) {\n\nReview Comment:\n   can use StringUtils.isEmpty like all other places\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T10:26:03.309+0000", "updated": "2025-02-17T10:26:03.309+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927718", "id": "17927718", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1957990905\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -402,11 +406,32 @@ public AbfsRestOperation createPath(final String path,\n       if (!op.hasResult()) {\n         throw ex;\n       }\n-      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n-        String existingResource =\n-            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n-        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-          return op; //don't throw ex on mkdirs for existing directory\n+      if (!isFile) {\n+        if (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+          String existingResource =\n+              op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+          if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+            return op; //don't throw ex on mkdirs for existing directory\n+          }\n+        }\n+      } else {\n+        // recovery using client transaction id only if it is a retried request.\n+        if (op.isARetriedRequest() && clientTransactionId != null\n+            && (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT\n+            || op.getResult().getStatusCode() == HttpURLConnection.HTTP_PRECON_FAILED)) {\n+          try {\n+            final AbfsHttpOperation getPathStatusOp =\n+                getPathStatus(path, false,\n+                    tracingContext, null).getResult();\n+            if (clientTransactionId.equals(\n+                getPathStatusOp.getResponseHeader(\n+                    X_MS_CLIENT_TRANSACTION_ID))) {\n+              return op;\n+            }\n+          } catch (AzureBlobFileSystemException ignored) {\n+            // In case of get path status failure,\n\nReview Comment:\n   we are ignoring and not throwing the exception right ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T10:30:28.909+0000", "updated": "2025-02-17T10:30:28.909+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927725", "id": "17927725", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958018325\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -402,11 +406,32 @@ public AbfsRestOperation createPath(final String path,\n       if (!op.hasResult()) {\n         throw ex;\n       }\n-      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n-        String existingResource =\n-            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n-        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-          return op; //don't throw ex on mkdirs for existing directory\n+      if (!isFile) {\n+        if (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+          String existingResource =\n+              op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+          if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+            return op; //don't throw ex on mkdirs for existing directory\n+          }\n+        }\n+      } else {\n+        // recovery using client transaction id only if it is a retried request.\n+        if (op.isARetriedRequest() && clientTransactionId != null\n+            && (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT\n+            || op.getResult().getStatusCode() == HttpURLConnection.HTTP_PRECON_FAILED)) {\n+          try {\n+            final AbfsHttpOperation getPathStatusOp =\n+                getPathStatus(path, false,\n+                    tracingContext, null).getResult();\n+            if (clientTransactionId.equals(\n+                getPathStatusOp.getResponseHeader(\n+                    X_MS_CLIENT_TRANSACTION_ID))) {\n+              return op;\n+            }\n+          } catch (AzureBlobFileSystemException ignored) {\n+            // In case of get path status failure,\n\nReview Comment:\n   Yes, in case we get exception on getPathStatus, we are raising original exception.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T10:47:32.752+0000", "updated": "2025-02-17T10:47:32.752+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927734", "id": "17927734", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958088806\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +734,35 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          fs.getAbfsStore().getClientHandler().getIngressClient()\n\nReview Comment:\n   can use getIngressServiceType method here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T11:41:02.889+0000", "updated": "2025-02-17T11:41:02.889+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927735", "id": "17927735", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958089246\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +734,35 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          fs.getAbfsStore().getClientHandler().getIngressClient()\n+              instanceof AbfsDfsClient);\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeTrue(\n+          StringUtils.isEmpty(\n+              fs.getAbfsStore().getAbfsConfiguration().getAppendBlobDirs()));\n\nReview Comment:\n   isAppendBlobEnabled method can be used\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T11:41:22.905+0000", "updated": "2025-02-17T11:41:22.905+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927736", "id": "17927736", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958111293\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +185,139 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+      AbfsClientHandler clientHandler = Mockito.spy(store.getClientHandler());\n+      AbfsDfsClient abfsClient = (AbfsDfsClient) Mockito.spy(\n+          clientHandler.getClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      fs.getAbfsStore().setClientHandler(clientHandler);\n+      Mockito.doReturn(abfsClient).when(clientHandler).getIngressClient();\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(\"PUT\").when(op).getMethod();\n+                Mockito.doReturn(\"\").when(op).getStorageErrorMessage();\n\nReview Comment:\n   use empty string constant\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T11:57:43.618+0000", "updated": "2025-02-17T11:57:43.618+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927737", "id": "17927737", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958112915\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +185,139 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+      AbfsClientHandler clientHandler = Mockito.spy(store.getClientHandler());\n+      AbfsDfsClient abfsClient = (AbfsDfsClient) Mockito.spy(\n+          clientHandler.getClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      fs.getAbfsStore().setClientHandler(clientHandler);\n+      Mockito.doReturn(abfsClient).when(clientHandler).getIngressClient();\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(\"PUT\").when(op).getMethod();\n+                Mockito.doReturn(\"\").when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), \"\",\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that when a new file is created, the Azure Blob FileSystem client\n+   * correctly includes the client transaction ID in the response header for the created file.\n+   * The test uses a configuration where client transaction ID is enabled and verifies\n+   * its presence after the file creation operation.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void getClientTransactionIdAfterCreate() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsDfsClient = (AbfsDfsClient) fs.getAbfsClient();\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      fs.create(nonOverwriteFile, false);\n+\n+      final AbfsHttpOperation getPathStatusOp =\n+          abfsDfsClient.getPathStatus(nonOverwriteFile.toUri().getPath(), false,\n+              getTestTracingContext(fs, true), null).getResult();\n+      Assertions.assertThat(\n+          getPathStatusOp.getResponseHeader(X_MS_CLIENT_TRANSACTION_ID))\n+          .describedAs(\"Client transaction ID should be set during create\")\n+          .isNotNull();\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * after two consecutive create operations on the same file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that even after performing two create operations (with overwrite)\n+   * on the same file, the Azure Blob FileSystem client includes the client transaction ID\n+   * in the response header for the created file. The test checks for the presence of\n+   * the client transaction ID in the response after the second create call.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void testClientTransactionIdAfterTwoCreateCalls() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsDfsClient = (AbfsDfsClient) fs.getAbfsClient();\n+      Path testPath = path(\"testfile\");\n+      AzureBlobFileSystemStore.Permissions permissions\n+          = new AzureBlobFileSystemStore.Permissions(false,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+      fs.create(testPath, false);\n+      fs.create(testPath, true);\n+      final AbfsHttpOperation getPathStatusOp =\n+          abfsDfsClient.getPathStatus(testPath.toUri().getPath(), false,\n+              getTestTracingContext(fs, true), null).getResult();\n+      Assertions.assertThat(\n+              getPathStatusOp.getResponseHeader(X_MS_CLIENT_TRANSACTION_ID))\n+          .describedAs(\"Client transaction ID should be set during create\")\n+          .isNotNull();\n+    }\n\nReview Comment:\n   We should add a test to assert the set transaction id and the received one is same\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T11:58:58.344+0000", "updated": "2025-02-17T11:58:58.344+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927739", "id": "17927739", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958113872\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1641,4 +1648,112 @@ public void testRenameSrcDirDeleteEmitDeletionCountInClientRequestId()\n             Mockito.any(TracingContext.class));\n     fs.rename(new Path(dirPathStr), new Path(\"/dst/\"));\n   }\n+\n+  /**\n+   * Test to verify the idempotency of the `rename` operation in Azure Blob File System when retrying\n+   * after a failure. The test simulates a \"path not found\" error (HTTP 404) on the first attempt,\n+   * checks that the operation correctly retries using the appropriate transaction ID,\n+   * and ensures that the source file is renamed to the destination path once successful.\n+   *\n+   * @throws Exception if an error occurs during the file system operations or mocking\n+   */\n+  @Test\n+  public void renamePathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, false);\n+      AbfsClient abfsClient = Mockito.spy(fs.getAbfsClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      Path sourceDir = path(\"/testSrc\");\n+      assertMkdirs(fs, sourceDir);\n+      String filename = \"file1\";\n+      Path sourceFilePath = new Path(sourceDir, filename);\n+      touch(sourceFilePath);\n\nReview Comment:\n   touch should be inside try catch ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T11:59:45.898+0000", "updated": "2025-02-17T11:59:45.898+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927741", "id": "17927741", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958135113\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -402,11 +406,32 @@ public AbfsRestOperation createPath(final String path,\n       if (!op.hasResult()) {\n         throw ex;\n       }\n-      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n-        String existingResource =\n-            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n-        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-          return op; //don't throw ex on mkdirs for existing directory\n+      if (!isFile) {\n+        if (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+          String existingResource =\n+              op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+          if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+            return op; //don't throw ex on mkdirs for existing directory\n+          }\n+        }\n+      } else {\n+        // recovery using client transaction id only if it is a retried request.\n+        if (op.isARetriedRequest() && clientTransactionId != null\n+            && (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT\n+            || op.getResult().getStatusCode() == HttpURLConnection.HTTP_PRECON_FAILED)) {\n+          try {\n+            final AbfsHttpOperation getPathStatusOp =\n+                getPathStatus(path, false,\n+                    tracingContext, null).getResult();\n+            if (clientTransactionId.equals(\n+                getPathStatusOp.getResponseHeader(\n+                    X_MS_CLIENT_TRANSACTION_ID))) {\n+              return op;\n+            }\n+          } catch (AzureBlobFileSystemException ignored) {\n+            // In case of get path status failure,\n\nReview Comment:\n   But here getPathStatus is inside try catch and inside catch we are ignoring the caught exception\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T12:16:50.015+0000", "updated": "2025-02-17T12:16:50.015+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927749", "id": "17927749", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958165392\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1641,4 +1648,112 @@ public void testRenameSrcDirDeleteEmitDeletionCountInClientRequestId()\n             Mockito.any(TracingContext.class));\n     fs.rename(new Path(dirPathStr), new Path(\"/dst/\"));\n   }\n+\n+  /**\n+   * Test to verify the idempotency of the `rename` operation in Azure Blob File System when retrying\n+   * after a failure. The test simulates a \"path not found\" error (HTTP 404) on the first attempt,\n+   * checks that the operation correctly retries using the appropriate transaction ID,\n+   * and ensures that the source file is renamed to the destination path once successful.\n+   *\n+   * @throws Exception if an error occurs during the file system operations or mocking\n+   */\n+  @Test\n+  public void renamePathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, false);\n+      AbfsClient abfsClient = Mockito.spy(fs.getAbfsClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      Path sourceDir = path(\"/testSrc\");\n+      assertMkdirs(fs, sourceDir);\n+      String filename = \"file1\";\n+      Path sourceFilePath = new Path(sourceDir, filename);\n+      touch(sourceFilePath);\n\nReview Comment:\n   It is inside try block only.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1641,4 +1648,112 @@ public void testRenameSrcDirDeleteEmitDeletionCountInClientRequestId()\n             Mockito.any(TracingContext.class));\n     fs.rename(new Path(dirPathStr), new Path(\"/dst/\"));\n   }\n+\n+  /**\n+   * Test to verify the idempotency of the `rename` operation in Azure Blob File System when retrying\n+   * after a failure. The test simulates a \"path not found\" error (HTTP 404) on the first attempt,\n+   * checks that the operation correctly retries using the appropriate transaction ID,\n+   * and ensures that the source file is renamed to the destination path once successful.\n+   *\n+   * @throws Exception if an error occurs during the file system operations or mocking\n+   */\n+  @Test\n+  public void renamePathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, false);\n+      AbfsClient abfsClient = Mockito.spy(fs.getAbfsClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      Path sourceDir = path(\"/testSrc\");\n+      assertMkdirs(fs, sourceDir);\n+      String filename = \"file1\";\n+      Path sourceFilePath = new Path(sourceDir, filename);\n+      touch(sourceFilePath);\n\nReview Comment:\n   It is already inside try block.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T12:39:46.619+0000", "updated": "2025-02-17T12:39:46.619+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927750", "id": "17927750", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958166104\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +185,139 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+      AbfsClientHandler clientHandler = Mockito.spy(store.getClientHandler());\n+      AbfsDfsClient abfsClient = (AbfsDfsClient) Mockito.spy(\n+          clientHandler.getClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      fs.getAbfsStore().setClientHandler(clientHandler);\n+      Mockito.doReturn(abfsClient).when(clientHandler).getIngressClient();\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(\"PUT\").when(op).getMethod();\n+                Mockito.doReturn(\"\").when(op).getStorageErrorMessage();\n\nReview Comment:\n   Used Constants\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +734,35 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          fs.getAbfsStore().getClientHandler().getIngressClient()\n+              instanceof AbfsDfsClient);\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeTrue(\n+          StringUtils.isEmpty(\n+              fs.getAbfsStore().getAbfsConfiguration().getAppendBlobDirs()));\n\nReview Comment:\n   Made the changes\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T12:40:20.276+0000", "updated": "2025-02-17T12:40:20.276+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927751", "id": "17927751", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1958166453\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +734,35 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          fs.getAbfsStore().getClientHandler().getIngressClient()\n\nReview Comment:\n   Taken!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-17T12:40:31.251+0000", "updated": "2025-02-17T12:40:31.251+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927906", "id": "17927906", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959038196\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -402,11 +406,32 @@ public AbfsRestOperation createPath(final String path,\n       if (!op.hasResult()) {\n         throw ex;\n       }\n-      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n-        String existingResource =\n-            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n-        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-          return op; //don't throw ex on mkdirs for existing directory\n+      if (!isFile) {\n+        if (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+          String existingResource =\n+              op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+          if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+            return op; //don't throw ex on mkdirs for existing directory\n+          }\n+        }\n+      } else {\n+        // recovery using client transaction id only if it is a retried request.\n+        if (op.isARetriedRequest() && clientTransactionId != null\n+            && (op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT\n+            || op.getResult().getStatusCode() == HttpURLConnection.HTTP_PRECON_FAILED)) {\n+          try {\n+            final AbfsHttpOperation getPathStatusOp =\n+                getPathStatus(path, false,\n+                    tracingContext, null).getResult();\n+            if (clientTransactionId.equals(\n+                getPathStatusOp.getResponseHeader(\n+                    X_MS_CLIENT_TRANSACTION_ID))) {\n+              return op;\n+            }\n+          } catch (AzureBlobFileSystemException ignored) {\n+            // In case of get path status failure,\n\nReview Comment:\n   There are 2 try-catch blocks here. I think the first catch method will throw the original exception at the very end when required.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T04:23:26.836+0000", "updated": "2025-02-18T04:23:26.836+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927915", "id": "17927915", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959107055\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +185,139 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AzureBlobFileSystemStore store = Mockito.spy(fs.getAbfsStore());\n+      AbfsClientHandler clientHandler = Mockito.spy(store.getClientHandler());\n+      AbfsDfsClient abfsClient = (AbfsDfsClient) Mockito.spy(\n+          clientHandler.getClient());\n+      fs.getAbfsStore().setClient(abfsClient);\n+      fs.getAbfsStore().setClientHandler(clientHandler);\n+      Mockito.doReturn(abfsClient).when(clientHandler).getIngressClient();\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(\"PUT\").when(op).getMethod();\n+                Mockito.doReturn(\"\").when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), \"\",\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that when a new file is created, the Azure Blob FileSystem client\n+   * correctly includes the client transaction ID in the response header for the created file.\n+   * The test uses a configuration where client transaction ID is enabled and verifies\n+   * its presence after the file creation operation.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void getClientTransactionIdAfterCreate() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsDfsClient = (AbfsDfsClient) fs.getAbfsClient();\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      fs.create(nonOverwriteFile, false);\n+\n+      final AbfsHttpOperation getPathStatusOp =\n+          abfsDfsClient.getPathStatus(nonOverwriteFile.toUri().getPath(), false,\n+              getTestTracingContext(fs, true), null).getResult();\n+      Assertions.assertThat(\n+          getPathStatusOp.getResponseHeader(X_MS_CLIENT_TRANSACTION_ID))\n+          .describedAs(\"Client transaction ID should be set during create\")\n+          .isNotNull();\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * after two consecutive create operations on the same file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that even after performing two create operations (with overwrite)\n+   * on the same file, the Azure Blob FileSystem client includes the client transaction ID\n+   * in the response header for the created file. The test checks for the presence of\n+   * the client transaction ID in the response after the second create call.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void testClientTransactionIdAfterTwoCreateCalls() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsDfsClient = (AbfsDfsClient) fs.getAbfsClient();\n+      Path testPath = path(\"testfile\");\n+      AzureBlobFileSystemStore.Permissions permissions\n+          = new AzureBlobFileSystemStore.Permissions(false,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+      fs.create(testPath, false);\n+      fs.create(testPath, true);\n+      final AbfsHttpOperation getPathStatusOp =\n+          abfsDfsClient.getPathStatus(testPath.toUri().getPath(), false,\n+              getTestTracingContext(fs, true), null).getResult();\n+      Assertions.assertThat(\n+              getPathStatusOp.getResponseHeader(X_MS_CLIENT_TRANSACTION_ID))\n+          .describedAs(\"Client transaction ID should be set during create\")\n+          .isNotNull();\n+    }\n\nReview Comment:\n   Added assert for clienttransactionid check.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T05:47:12.878+0000", "updated": "2025-02-18T05:47:12.878+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927931", "id": "17927931", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959160201\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n\nReview Comment:\n   This test simulates HTTP 409 retry and that the same transaction ID is carried for the retry as well. Should we also test that the create retry returns a 200 now to truly test the idempotency behaviour?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T06:49:46.236+0000", "updated": "2025-02-18T06:49:46.236+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927932", "id": "17927932", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959162075\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -754,6 +755,14 @@ public AbfsClientRenameResult renamePath(\n         throw e;\n       }\n \n+      // ref: HADOOP-19393. Write permission checks can occur before validating\n+      // rename operation's validity. If there is an existing destination path, it may be rejected\n+      // with an authorization error. Catching and throwing FileAlreadyExistsException instead.\n+      if (op.getResult().getStorageErrorCode()\n\nReview Comment:\n   why is this change showing as a part of this PR ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T06:51:46.356+0000", "updated": "2025-02-18T06:51:46.356+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927933", "id": "17927933", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959167581\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsClient = mockIngressClientHandler(fs);\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(HTTP_METHOD_PUT).when(op).getMethod();\n+                Mockito.doReturn(EMPTY_STRING).when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), EMPTY_STRING,\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n\nReview Comment:\n   Nit: Do we need these <p> tags? Else we can remove them in these tests- getClientTransactionIdAfterCreate, testClientTransactionIdAfterTwoCreateCalls, getClientTransactionIdAfterRename\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T06:57:17.089+0000", "updated": "2025-02-18T06:57:17.089+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927934", "id": "17927934", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959167581\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsClient = mockIngressClientHandler(fs);\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(HTTP_METHOD_PUT).when(op).getMethod();\n+                Mockito.doReturn(EMPTY_STRING).when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), EMPTY_STRING,\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n\nReview Comment:\n   Nit: Do we need these \"<p>\" tags? Else we can remove them in these tests- getClientTransactionIdAfterCreate, testClientTransactionIdAfterTwoCreateCalls, getClientTransactionIdAfterRename\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsClient = mockIngressClientHandler(fs);\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(HTTP_METHOD_PUT).when(op).getMethod();\n+                Mockito.doReturn(EMPTY_STRING).when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), EMPTY_STRING,\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n\nReview Comment:\n   Nit: Do we need these \"p\" tags? Else we can remove them in these tests- getClientTransactionIdAfterCreate, testClientTransactionIdAfterTwoCreateCalls, getClientTransactionIdAfterRename\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T06:58:51.782+0000", "updated": "2025-02-18T06:58:51.782+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927940", "id": "17927940", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959184697\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -754,6 +755,14 @@ public AbfsClientRenameResult renamePath(\n         throw e;\n       }\n \n+      // ref: HADOOP-19393. Write permission checks can occur before validating\n+      // rename operation's validity. If there is an existing destination path, it may be rejected\n+      // with an authorization error. Catching and throwing FileAlreadyExistsException instead.\n+      if (op.getResult().getStorageErrorCode()\n\nReview Comment:\n   Could you check now if it still visible? Now sure why it is coming here?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T07:14:46.940+0000", "updated": "2025-02-18T07:14:46.940+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927941", "id": "17927941", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959185322\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsClient = mockIngressClientHandler(fs);\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(HTTP_METHOD_PUT).when(op).getMethod();\n+                Mockito.doReturn(EMPTY_STRING).when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), EMPTY_STRING,\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n\nReview Comment:\n   It if fine to keep it as it is.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T07:15:24.467+0000", "updated": "2025-02-18T07:15:24.467+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927946", "id": "17927946", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959195177\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n\nReview Comment:\n   Create retry will throw 409, that is the test case. Retry will not return 200 as resource already exists.\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T07:24:52.574+0000", "updated": "2025-02-18T07:24:52.574+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927952", "id": "17927952", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959211387\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -198,7 +198,7 @@ public final class FileSystemConfigurations {\n \n   public static final int DEFAULT_FS_AZURE_BLOB_DELETE_THREAD = DEFAULT_FS_AZURE_LISTING_ACTION_THREADS;\n \n-  public static final boolean DEFAULT_FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = true;\n\nReview Comment:\n   revert to false\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T07:39:39.634+0000", "updated": "2025-02-18T07:39:39.634+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17927958", "id": "17927958", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2664868989\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 51s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 6 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 36s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  38m 58s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 21s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/8/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 5 unchanged - 0 fixed = 6 total (was 5)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 47s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 132m 51s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux b43936fb224e 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 87d432e8b53665870e0d2eecb951bf65c4d2b333 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/8/testReport/ |\r\n   | Max. process+thread count | 578 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T08:00:03.357+0000", "updated": "2025-02-18T08:00:03.357+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17928029", "id": "17928029", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2665275465\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 6 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 42s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  40m  3s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  6s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 46s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 43s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 24s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.47 ServerAPI=1.47 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux d56df973cb10 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c91031776b11a54bc65bf4a1ec05977efb270cb8 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/9/testReport/ |\r\n   | Max. process+thread count | 577 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/9/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T10:49:51.859+0000", "updated": "2025-02-18T10:49:51.859+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17928060", "id": "17928060", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959647089\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -757,12 +760,30 @@ protected void assumeRecoveryThroughClientTransactionID(\n     if (isCreate) {\n       // Assume that create client is DFS client.\n       Assume.assumeTrue(\n-          fs.getAbfsStore().getClientHandler().getIngressClient()\n-              instanceof AbfsDfsClient);\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n\nReview Comment:\n   Can simply call getIngressServiceType method in this class\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T12:23:45.285+0000", "updated": "2025-02-18T12:23:45.285+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17928062", "id": "17928062", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959651094\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -754,6 +755,14 @@ public AbfsClientRenameResult renamePath(\n         throw e;\n       }\n \n+      // ref: HADOOP-19393. Write permission checks can occur before validating\n+      // rename operation's validity. If there is an existing destination path, it may be rejected\n+      // with an authorization error. Catching and throwing FileAlreadyExistsException instead.\n+      if (op.getResult().getStorageErrorCode()\n\nReview Comment:\n   not visible now\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T12:26:19.726+0000", "updated": "2025-02-18T12:26:19.726+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17928067", "id": "17928067", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1959678019\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/constants/FileSystemConfigurations.java:\n##########\n@@ -198,7 +198,7 @@ public final class FileSystemConfigurations {\n \n   public static final int DEFAULT_FS_AZURE_BLOB_DELETE_THREAD = DEFAULT_FS_AZURE_LISTING_ACTION_THREADS;\n \n-  public static final boolean DEFAULT_FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = false;\n+  public static final boolean DEFAULT_FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID = true;\n\nReview Comment:\n   Done\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-18T12:44:53.803+0000", "updated": "2025-02-18T12:44:53.803+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929578", "id": "17929578", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967062469\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -216,6 +216,11 @@ private AbfsClient(final URL baseUrl,\n       encryptionType = EncryptionType.GLOBAL_KEY;\n     }\n \n+    // Version update needed to support x-ms-client-transaction-id header\n\nReview Comment:\n   I think we might need to be careful here.\r\n   1. Do we want to upgrade version for all APIs here or just the Rename/create?\r\n   2. What happens when driver upgrades the version overall? It might lead to downgrade. May be we should check if version is less than required then only update else use the default version.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeFalse(isAppendBlobEnabled());\n+    }\n+  }\n+\n+  /**\n+   * Mocks the behavior of adding a client transaction ID to the request headers\n+   * for the given AzureBlobFileSystem. This method generates a random transaction ID\n+   * and adds it to the headers of the {@link AbfsDfsClient}.\n+   *\n+   * @param abfsDfsClient The {@link AbfsDfsClient} mocked AbfsDfsClient.\n+   * @param clientTransactionId An array to hold the generated transaction ID.\n+   */\n+  protected void mockAddClientTransactionIdToHeader(AbfsDfsClient abfsDfsClient,\n\nReview Comment:\n   Can this be moved to `AbfsClientTestUtil` class or similar utility class. Doesn't seem like a base class thing.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n\nReview Comment:\n   Instead of enabling it just for this test, we should enabel it for all the create/mkdir/rename tests IMO.\r\n   This is a service side change and normal tests should also be working with this.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/MockIntercept.java:\n##########\n@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.mockito.invocation.InvocationOnMock;\n+\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+\n+/**\n+ * Interface used to intercept and customize the behavior of mocked\n+ * `AbfsRestOperation` objects. The implementing class should define\n+ * how to handle the mock operation when it is invoked.\n+ *\n+ * @param <T> the type of the mocked object, typically an `AbfsRestOperation`\n+ */\n+public interface MockIntercept<T> {\n\nReview Comment:\n   Why is this needed?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n\nReview Comment:\n   We don't need fs here if we use base class utility method.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n\nReview Comment:\n   We have a method for this as well. `assumeHnsEnabled`\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeFalse(isAppendBlobEnabled());\n+    }\n+  }\n+\n+  /**\n+   * Mocks the behavior of adding a client transaction ID to the request headers\n+   * for the given AzureBlobFileSystem. This method generates a random transaction ID\n+   * and adds it to the headers of the {@link AbfsDfsClient}.\n+   *\n+   * @param abfsDfsClient The {@link AbfsDfsClient} mocked AbfsDfsClient.\n+   * @param clientTransactionId An array to hold the generated transaction ID.\n+   */\n+  protected void mockAddClientTransactionIdToHeader(AbfsDfsClient abfsDfsClient,\n+      String[] clientTransactionId) {\n+    Mockito.doAnswer(addClientTransactionId -> {\n+      clientTransactionId[0] = UUID.randomUUID().toString();\n+      List<AbfsHttpHeader> headers = addClientTransactionId.getArgument(0);\n+      headers.add(\n+          new AbfsHttpHeader(X_MS_CLIENT_TRANSACTION_ID,\n+              clientTransactionId[0]));\n+      return clientTransactionId[0];\n+    }).when(abfsDfsClient).addClientTransactionIdToHeader(Mockito.anyList());\n+  }\n }\n\nReview Comment:\n   Should we set this config as true for all the tests so that any regression can be catched when running our CI and PR validations??\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsClient = mockIngressClientHandler(fs);\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(HTTP_METHOD_PUT).when(op).getMethod();\n+                Mockito.doReturn(EMPTY_STRING).when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), EMPTY_STRING,\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that when a new file is created, the Azure Blob FileSystem client\n+   * correctly includes the client transaction ID in the response header for the created file.\n+   * The test uses a configuration where client transaction ID is enabled and verifies\n+   * its presence after the file creation operation.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void getClientTransactionIdAfterCreate() throws Exception {\n\nReview Comment:\n   Nit: SHould we move all the create test cases to `ITestAzureBlobFileSystemCreate` class?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:03:35.998+0000", "updated": "2025-02-24T06:03:35.998+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929580", "id": "17929580", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967079356\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeFalse(isAppendBlobEnabled());\n+    }\n+  }\n+\n+  /**\n+   * Mocks the behavior of adding a client transaction ID to the request headers\n+   * for the given AzureBlobFileSystem. This method generates a random transaction ID\n+   * and adds it to the headers of the {@link AbfsDfsClient}.\n+   *\n+   * @param abfsDfsClient The {@link AbfsDfsClient} mocked AbfsDfsClient.\n+   * @param clientTransactionId An array to hold the generated transaction ID.\n+   */\n+  protected void mockAddClientTransactionIdToHeader(AbfsDfsClient abfsDfsClient,\n+      String[] clientTransactionId) {\n+    Mockito.doAnswer(addClientTransactionId -> {\n+      clientTransactionId[0] = UUID.randomUUID().toString();\n+      List<AbfsHttpHeader> headers = addClientTransactionId.getArgument(0);\n+      headers.add(\n+          new AbfsHttpHeader(X_MS_CLIENT_TRANSACTION_ID,\n+              clientTransactionId[0]));\n+      return clientTransactionId[0];\n+    }).when(abfsDfsClient).addClientTransactionIdToHeader(Mockito.anyList());\n+  }\n }\n\nReview Comment:\n   Setting client transaction id header to true will not help, as there can be cases where server changes is not deployed and if we set the flag as true, it will not return client transaction id in the get path status response. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:10:46.420+0000", "updated": "2025-02-24T06:10:46.420+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929583", "id": "17929583", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967081561\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n\nReview Comment:\n   For this test case, we are not relying on server's client transaction id. Therefore, we are manually hardcoding here this to true. But for all other test cases, we are checking the actual response we are getting from server. So, if server changes are not deployed in the tenant where we are testing this change, the test would fail.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:14:30.524+0000", "updated": "2025-02-24T06:14:30.524+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929585", "id": "17929585", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967086202\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/MockIntercept.java:\n##########\n@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.mockito.invocation.InvocationOnMock;\n+\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+\n+/**\n+ * Interface used to intercept and customize the behavior of mocked\n+ * `AbfsRestOperation` objects. The implementing class should define\n+ * how to handle the mock operation when it is invoked.\n+ *\n+ * @param <T> the type of the mocked object, typically an `AbfsRestOperation`\n+ */\n+public interface MockIntercept<T> {\n\nReview Comment:\n   We use this in two places: the mock retry response for create and rename. In mockAbfsOperationCreation, we parse the mocked response, and in the test case, we implement answers based on different use cases.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:21:55.680+0000", "updated": "2025-02-24T06:21:55.680+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929589", "id": "17929589", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967099150\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeFalse(isAppendBlobEnabled());\n+    }\n+  }\n+\n+  /**\n+   * Mocks the behavior of adding a client transaction ID to the request headers\n+   * for the given AzureBlobFileSystem. This method generates a random transaction ID\n+   * and adds it to the headers of the {@link AbfsDfsClient}.\n+   *\n+   * @param abfsDfsClient The {@link AbfsDfsClient} mocked AbfsDfsClient.\n+   * @param clientTransactionId An array to hold the generated transaction ID.\n+   */\n+  protected void mockAddClientTransactionIdToHeader(AbfsDfsClient abfsDfsClient,\n\nReview Comment:\n   Moved to AbfsClientTestUtil class.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:41:56.224+0000", "updated": "2025-02-24T06:41:56.224+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929590", "id": "17929590", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967099261\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n\nReview Comment:\n   Taken!\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n\nReview Comment:\n   Taken!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:42:09.087+0000", "updated": "2025-02-24T06:42:09.087+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929591", "id": "17929591", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967102166\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemMkDir.java:\n##########\n@@ -167,4 +187,163 @@ public void testMkdirWithExistingFilename() throws Exception {\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath\")));\n     intercept(FileAlreadyExistsException.class, () -> fs.mkdirs(new Path(\"/testFilePath/newDir\")));\n   }\n+\n+  /**\n+   * Tests the idempotency of creating a path with retries by simulating\n+   * a conflict response (HTTP 409) from the Azure Blob File System client.\n+   * The method ensures that the path creation operation retries correctly\n+   * with the proper transaction ID headers, verifying idempotency during\n+   * failure recovery.\n+   *\n+   * @throws Exception if any error occurs during the operation.\n+   */\n+  @Test\n+  public void createPathRetryIdempotency() throws Exception {\n+    Configuration configuration = new Configuration(getRawConfiguration());\n+    configuration.set(FS_AZURE_ENABLE_CLIENT_TRANSACTION_ID, \"true\");\n+    try (AzureBlobFileSystem fs = getFileSystem(configuration)) {\n+      assumeRecoveryThroughClientTransactionID(fs, true);\n+      AbfsDfsClient abfsClient = mockIngressClientHandler(fs);\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      final List<AbfsHttpHeader> headers = new ArrayList<>();\n+      TestAbfsClient.mockAbfsOperationCreation(abfsClient,\n+          new MockIntercept<AbfsRestOperation>() {\n+            private int count = 0;\n+\n+            @Override\n+            public void answer(final AbfsRestOperation mockedObj,\n+                final InvocationOnMock answer)\n+                throws AbfsRestOperationException {\n+              if (count == 0) {\n+                count = 1;\n+                AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+                Mockito.doReturn(HTTP_METHOD_PUT).when(op).getMethod();\n+                Mockito.doReturn(EMPTY_STRING).when(op).getStorageErrorMessage();\n+                Mockito.doReturn(true).when(mockedObj).hasResult();\n+                Mockito.doReturn(op).when(mockedObj).getResult();\n+                Mockito.doReturn(HTTP_CONFLICT).when(op).getStatusCode();\n+                headers.addAll(mockedObj.getRequestHeaders());\n+                throw new AbfsRestOperationException(HTTP_CONFLICT,\n+                    AzureServiceErrorCode.PATH_CONFLICT.getErrorCode(), EMPTY_STRING,\n+                    null, op);\n+              }\n+            }\n+          });\n+      AbfsRestOperation getPathRestOp = Mockito.mock(AbfsRestOperation.class);\n+      AbfsHttpOperation op = Mockito.mock(AbfsHttpOperation.class);\n+      Mockito.doAnswer(answer -> {\n+        String requiredHeader = null;\n+        for (AbfsHttpHeader httpHeader : headers) {\n+          if (X_MS_CLIENT_TRANSACTION_ID.equalsIgnoreCase(\n+              httpHeader.getName())) {\n+            requiredHeader = httpHeader.getValue();\n+            break;\n+          }\n+        }\n+        return requiredHeader;\n+      }).when(op).getResponseHeader(X_MS_CLIENT_TRANSACTION_ID);\n+      Mockito.doReturn(true).when(getPathRestOp).hasResult();\n+      Mockito.doReturn(op).when(getPathRestOp).getResult();\n+      Mockito.doReturn(getPathRestOp).when(abfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+      fs.create(nonOverwriteFile, false);\n+    }\n+  }\n+\n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that when a new file is created, the Azure Blob FileSystem client\n+   * correctly includes the client transaction ID in the response header for the created file.\n+   * The test uses a configuration where client transaction ID is enabled and verifies\n+   * its presence after the file creation operation.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void getClientTransactionIdAfterCreate() throws Exception {\n\nReview Comment:\n   Done!\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:46:29.781+0000", "updated": "2025-02-24T06:46:29.781+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929593", "id": "17929593", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967110580\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeFalse(isAppendBlobEnabled());\n+    }\n+  }\n+\n+  /**\n+   * Mocks the behavior of adding a client transaction ID to the request headers\n+   * for the given AzureBlobFileSystem. This method generates a random transaction ID\n+   * and adds it to the headers of the {@link AbfsDfsClient}.\n+   *\n+   * @param abfsDfsClient The {@link AbfsDfsClient} mocked AbfsDfsClient.\n+   * @param clientTransactionId An array to hold the generated transaction ID.\n+   */\n+  protected void mockAddClientTransactionIdToHeader(AbfsDfsClient abfsDfsClient,\n+      String[] clientTransactionId) {\n+    Mockito.doAnswer(addClientTransactionId -> {\n+      clientTransactionId[0] = UUID.randomUUID().toString();\n+      List<AbfsHttpHeader> headers = addClientTransactionId.getArgument(0);\n+      headers.add(\n+          new AbfsHttpHeader(X_MS_CLIENT_TRANSACTION_ID,\n+              clientTransactionId[0]));\n+      return clientTransactionId[0];\n+    }).when(abfsDfsClient).addClientTransactionIdToHeader(Mockito.anyList());\n+  }\n }\n\nReview Comment:\n   So currently there are no integration tests running for thi feature that means.\r\n   Can you create a separate work item to make sure integration tests also run with this change post server deoployements completes??\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T06:57:58.298+0000", "updated": "2025-02-24T06:57:58.298+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929594", "id": "17929594", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967113352\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +737,53 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @param fs the AzureBlobFileSystem instance to check\n+   * @throws AzureBlobFileSystemException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(\n+      AzureBlobFileSystem fs, boolean isCreate)\n+      throws AzureBlobFileSystemException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n+    // Assumes that service type is DFS.\n+    assumeDfsServiceType();\n+    // Assumes that namespace is enabled for the given AzureBlobFileSystem.\n+    Assume.assumeTrue(\n+        fs.getIsNamespaceEnabled(getTestTracingContext(fs, true)));\n+    if (isCreate) {\n+      // Assume that create client is DFS client.\n+      Assume.assumeTrue(\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n+      // Assume that append blob is not enabled in DFS client.\n+      Assume.assumeFalse(isAppendBlobEnabled());\n+    }\n+  }\n+\n+  /**\n+   * Mocks the behavior of adding a client transaction ID to the request headers\n+   * for the given AzureBlobFileSystem. This method generates a random transaction ID\n+   * and adds it to the headers of the {@link AbfsDfsClient}.\n+   *\n+   * @param abfsDfsClient The {@link AbfsDfsClient} mocked AbfsDfsClient.\n+   * @param clientTransactionId An array to hold the generated transaction ID.\n+   */\n+  protected void mockAddClientTransactionIdToHeader(AbfsDfsClient abfsDfsClient,\n+      String[] clientTransactionId) {\n+    Mockito.doAnswer(addClientTransactionId -> {\n+      clientTransactionId[0] = UUID.randomUUID().toString();\n+      List<AbfsHttpHeader> headers = addClientTransactionId.getArgument(0);\n+      headers.add(\n+          new AbfsHttpHeader(X_MS_CLIENT_TRANSACTION_ID,\n+              clientTransactionId[0]));\n+      return clientTransactionId[0];\n+    }).when(abfsDfsClient).addClientTransactionIdToHeader(Mockito.anyList());\n+  }\n }\n\nReview Comment:\n   There are integration tests for this, but the clientTransactionIdEnabled flag is set to false, so they will not run. I have tested these cases locally by enabling the flag.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T07:01:46.904+0000", "updated": "2025-02-24T07:01:46.904+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929600", "id": "17929600", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967153604\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -757,12 +760,30 @@ protected void assumeRecoveryThroughClientTransactionID(\n     if (isCreate) {\n       // Assume that create client is DFS client.\n       Assume.assumeTrue(\n-          fs.getAbfsStore().getClientHandler().getIngressClient()\n-              instanceof AbfsDfsClient);\n+          AbfsServiceType.DFS.equals(\n+              fs.getAbfsStore().getAbfsConfiguration().getIngressServiceType()));\n\nReview Comment:\n   Done\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T07:49:02.904+0000", "updated": "2025-02-24T07:49:02.904+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929665", "id": "17929665", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2677932899\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 22s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 53s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  40m 14s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 27s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 43s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 135m 27s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/10/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux acb634312407 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7a0017b02c74e0024e0c803b561750294b55050f |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/10/testReport/ |\r\n   | Max. process+thread count | 527 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/10/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T10:04:04.936+0000", "updated": "2025-02-24T10:04:04.936+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929734", "id": "17929734", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967524789\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -216,6 +216,11 @@ private AbfsClient(final URL baseUrl,\n       encryptionType = EncryptionType.GLOBAL_KEY;\n     }\n \n+    // Version update needed to support x-ms-client-transaction-id header\n\nReview Comment:\n   Discussed offline. We will take it up as a separate WI\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T12:08:12.140+0000", "updated": "2025-02-24T12:08:12.140+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929817", "id": "17929817", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2678829422\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 26s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  37m 47s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 24s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 55s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 42s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 33s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 131m 50s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/11/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 7f6583c07090 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 39f387e1e4b8b67f473b034dcbd0317ce3bd9585 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/11/testReport/ |\r\n   | Max. process+thread count | 606 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/11/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T15:34:12.176+0000", "updated": "2025-02-24T15:34:12.176+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929824", "id": "17929824", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2678876261\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 52s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  38m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 43s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 16s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  38m 37s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 27s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m  6s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 44s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 129m 26s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/12/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 347811898daf 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ba0b3a1a423d8635ac4f6738317750e3f109171e |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/12/testReport/ |\r\n   | Max. process+thread count | 525 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/12/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T15:47:11.273+0000", "updated": "2025-02-24T15:47:11.273+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17929890", "id": "17929890", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2679322292\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 57s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  42m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 29s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  38m 51s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 17s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 44s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 134m 30s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/13/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 2e8619e80462 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / c03a11329236743824093c5da5252a90ed37f47f |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/13/testReport/ |\r\n   | Max. process+thread count | 528 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/13/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-24T18:31:46.096+0000", "updated": "2025-02-24T18:31:46.096+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930007", "id": "17930007", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1968915858\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/AbfsDriverException.java:\n##########\n@@ -51,4 +51,12 @@ public AbfsDriverException(final Exception innerException, final String activity\n             : ERROR_MESSAGE + \", rId: \" + activityId,\n         null);\n   }\n+\n+  public AbfsDriverException(final String errorMessage, final Exception innerException) {\n\nReview Comment:\n   I was wondering if the exception will have reqId or not.\r\n   Req id is part of abfsHttpOperation. Can we also pass down activity Id and append it to error message?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -705,6 +711,30 @@ public AbfsClientRenameResult renamePath(\n         throw e;\n       }\n \n+      // recovery using client transaction id only if it is a retried request.\n+      if (op.isARetriedRequest() && clientTransactionId != null\n+          && SOURCE_PATH_NOT_FOUND.getErrorCode().equalsIgnoreCase(\n+              op.getResult().getStorageErrorCode())) {\n+        try {\n+          final AbfsHttpOperation abfsHttpOperation =\n+              getPathStatus(destination, false,\n+                  tracingContext, null).getResult();\n+          if (clientTransactionId.equals(\n+              abfsHttpOperation.getResponseHeader(\n+                  X_MS_CLIENT_TRANSACTION_ID))) {\n+            return new AbfsClientRenameResult(\n+                getSuccessOp(AbfsRestOperationType.RenamePath,\n+                HTTP_METHOD_PUT, url, requestHeaders), true,\n+                isMetadataIncompleteState);\n+          }\n+        } catch (AzureBlobFileSystemException exception) {\n+          throw new AbfsDriverException(\n+              \"Error in getPathStatus while recovering from rename failure.\",\n\nReview Comment:\n   Let's define error string as constant in `AbfsErrors` class and add a mockito test to verify we get the proper exception thrown, if not already there.\r\n   Same for create as well.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -415,7 +416,9 @@ public AbfsRestOperation createPath(final String path,\n           String existingResource =\n               op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n           if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-            return op; //don't throw ex on mkdirs for existing directory\n+            //don't throw ex on mkdirs for existing directory\n+            return getSuccessOp(AbfsRestOperationType.CreatePath,\n\nReview Comment:\n   This is good function to have a cleaner code, let's define it in base class and use it everywhere we are setting hard result. Even in Blob Client\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1766,4 +1745,69 @@ public void getClientTransactionIdAfterRename() throws Exception {\n           .isEqualTo(clientTransactionId[0]);\n     }\n   }\n+\n+  @Test\n+  public void failureInGetPathStatusDuringRenameRecovery() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(false);\n+      AbfsDfsClient abfsDfsClient = (AbfsDfsClient) Mockito.spy(fs.getAbfsClient());\n+      fs.getAbfsStore().setClient(abfsDfsClient);\n+      final String[] clientTransactionId = new String[1];\n+      mockAddClientTransactionIdToHeader(abfsDfsClient, clientTransactionId);\n+      mockRetriedRequest(abfsDfsClient, new ArrayList<>());\n+      boolean[] flag = new boolean[1];\n+      Mockito.doAnswer(getPathStatus -> {\n+        if (!flag[0]) {\n+          flag[0] = true;\n+          throw new AbfsRestOperationException(HTTP_CLIENT_TIMEOUT, \"\", \"\", new Exception());\n+        }\n+        return getPathStatus.callRealMethod();\n+      }).when(abfsDfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+\n+      Path sourceDir = path(\"/testSrc\");\n+      assertMkdirs(fs, sourceDir);\n+      String filename = \"file1\";\n+      Path sourceFilePath = new Path(sourceDir, filename);\n+      touch(sourceFilePath);\n+      Path destFilePath = new Path(sourceDir, \"file2\");\n+\n+      String errorMessage = intercept(AbfsDriverException.class,\n+          () -> fs.rename(sourceFilePath, destFilePath)).getErrorMessage();\n+\n+      Assertions.assertThat(errorMessage)\n+          .describedAs(\"getPathStatus should fail while recovering\")\n+          .contains(\"Error in getPathStatus while recovering from rename failure.\");\n\nReview Comment:\n   Same as above\r\n   \n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemCreate.java:\n##########\n@@ -2213,6 +2193,49 @@ public void testClientTransactionIdAfterTwoCreateCalls() throws Exception {\n     }\n   }\n \n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that when a new file is created, the Azure Blob FileSystem client\n+   * correctly includes the client transaction ID in the response header for the created file.\n+   * The test uses a configuration where client transaction ID is enabled and verifies\n+   * its presence after the file creation operation.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void failureInGetPathStatusDuringCreateRecovery() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(true);\n+      final String[] clientTransactionId = new String[1];\n+      AbfsDfsClient abfsDfsClient = mockIngressClientHandler(fs);\n+      mockAddClientTransactionIdToHeader(abfsDfsClient, clientTransactionId);\n+      mockRetriedRequest(abfsDfsClient, new ArrayList<>());\n+      boolean[] flag = new boolean[1];\n+      Mockito.doAnswer(getPathStatus -> {\n+        if (!flag[0]) {\n+          flag[0] = true;\n+          throw new AbfsRestOperationException(HTTP_CLIENT_TIMEOUT, \"\", \"\", new Exception());\n+        }\n+        return getPathStatus.callRealMethod();\n+      }).when(abfsDfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      String errorMessage = intercept(AbfsDriverException.class,\n+          () -> fs.create(nonOverwriteFile, false)).getErrorMessage();\n+\n+      Assertions.assertThat(errorMessage)\n+          .describedAs(\"getPathStatus should fail while recovering\")\n+          .contains(\"Error in getPathStatus while recovering from create failure.\");\n\nReview Comment:\n   Okay seems like this is the test I was referring to. Let's use constants here for error message.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T05:20:24.873+0000", "updated": "2025-02-25T05:20:24.873+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930009", "id": "17930009", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1968961964\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1641,4 +1653,180 @@ public void testRenameSrcDirDeleteEmitDeletionCountInClientRequestId()\n             Mockito.any(TracingContext.class));\n     fs.rename(new Path(dirPathStr), new Path(\"/dst/\"));\n   }\n+\n+  /**\n+   * Test to verify the idempotency of the `rename` operation in Azure Blob File System when retrying\n+   * after a failure. The test simulates a \"path not found\" error (HTTP 404) on the first attempt,\n+   * checks that the operation correctly retries using the appropriate transaction ID,\n+   * and ensures that the source file is renamed to the destination path once successful.\n+   *\n+   * @throws Exception if an error occurs during the file system operations or mocking\n+   */\n+  @Test\n+  public void renamePathRetryIdempotency() throws Exception {\n\nReview Comment:\n   Test function names should start with test as all others. This might look like a utility method\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T05:30:15.504+0000", "updated": "2025-02-25T05:30:15.504+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930010", "id": "17930010", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1968975147\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/exceptions/AbfsDriverException.java:\n##########\n@@ -51,4 +51,12 @@ public AbfsDriverException(final Exception innerException, final String activity\n             : ERROR_MESSAGE + \", rId: \" + activityId,\n         null);\n   }\n+\n+  public AbfsDriverException(final String errorMessage, final Exception innerException) {\n\nReview Comment:\n   I think this is already taken care fo, inner exception will be on type AbfsRestOperationException only having reqId\r\n   Resolving this now.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T05:41:31.540+0000", "updated": "2025-02-25T05:41:31.540+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930011", "id": "17930011", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1968975576\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1641,4 +1653,180 @@ public void testRenameSrcDirDeleteEmitDeletionCountInClientRequestId()\n             Mockito.any(TracingContext.class));\n     fs.rename(new Path(dirPathStr), new Path(\"/dst/\"));\n   }\n+\n+  /**\n+   * Test to verify the idempotency of the `rename` operation in Azure Blob File System when retrying\n+   * after a failure. The test simulates a \"path not found\" error (HTTP 404) on the first attempt,\n+   * checks that the operation correctly retries using the appropriate transaction ID,\n+   * and ensures that the source file is renamed to the destination path once successful.\n+   *\n+   * @throws Exception if an error occurs during the file system operations or mocking\n+   */\n+  @Test\n+  public void renamePathRetryIdempotency() throws Exception {\n\nReview Comment:\n   Fix this for all new tests added.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T05:41:57.887+0000", "updated": "2025-02-25T05:41:57.887+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930077", "id": "17930077", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969079430\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -705,6 +711,30 @@ public AbfsClientRenameResult renamePath(\n         throw e;\n       }\n \n+      // recovery using client transaction id only if it is a retried request.\n+      if (op.isARetriedRequest() && clientTransactionId != null\n+          && SOURCE_PATH_NOT_FOUND.getErrorCode().equalsIgnoreCase(\n+              op.getResult().getStorageErrorCode())) {\n+        try {\n+          final AbfsHttpOperation abfsHttpOperation =\n+              getPathStatus(destination, false,\n+                  tracingContext, null).getResult();\n+          if (clientTransactionId.equals(\n+              abfsHttpOperation.getResponseHeader(\n+                  X_MS_CLIENT_TRANSACTION_ID))) {\n+            return new AbfsClientRenameResult(\n+                getSuccessOp(AbfsRestOperationType.RenamePath,\n+                HTTP_METHOD_PUT, url, requestHeaders), true,\n+                isMetadataIncompleteState);\n+          }\n+        } catch (AzureBlobFileSystemException exception) {\n+          throw new AbfsDriverException(\n+              \"Error in getPathStatus while recovering from rename failure.\",\n\nReview Comment:\n   Done\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T06:58:21.863+0000", "updated": "2025-02-25T06:58:21.863+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930078", "id": "17930078", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969080607\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -415,7 +416,9 @@ public AbfsRestOperation createPath(final String path,\n           String existingResource =\n               op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n           if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-            return op; //don't throw ex on mkdirs for existing directory\n+            //don't throw ex on mkdirs for existing directory\n+            return getSuccessOp(AbfsRestOperationType.CreatePath,\n\nReview Comment:\n   Done\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemCreate.java:\n##########\n@@ -2213,6 +2193,49 @@ public void testClientTransactionIdAfterTwoCreateCalls() throws Exception {\n     }\n   }\n \n+  /**\n+   * Test to verify that the client transaction ID is included in the response header\n+   * during the creation of a new file in Azure Blob Storage.\n+   * <p>\n+   * This test ensures that when a new file is created, the Azure Blob FileSystem client\n+   * correctly includes the client transaction ID in the response header for the created file.\n+   * The test uses a configuration where client transaction ID is enabled and verifies\n+   * its presence after the file creation operation.\n+   * </p>\n+   *\n+   * @throws Exception if any error occurs during test execution\n+   */\n+  @Test\n+  public void failureInGetPathStatusDuringCreateRecovery() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(true);\n+      final String[] clientTransactionId = new String[1];\n+      AbfsDfsClient abfsDfsClient = mockIngressClientHandler(fs);\n+      mockAddClientTransactionIdToHeader(abfsDfsClient, clientTransactionId);\n+      mockRetriedRequest(abfsDfsClient, new ArrayList<>());\n+      boolean[] flag = new boolean[1];\n+      Mockito.doAnswer(getPathStatus -> {\n+        if (!flag[0]) {\n+          flag[0] = true;\n+          throw new AbfsRestOperationException(HTTP_CLIENT_TIMEOUT, \"\", \"\", new Exception());\n+        }\n+        return getPathStatus.callRealMethod();\n+      }).when(abfsDfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+\n+      final Path nonOverwriteFile = new Path(\n+          \"/NonOverwriteTest_FileName_\" + UUID.randomUUID());\n+      String errorMessage = intercept(AbfsDriverException.class,\n+          () -> fs.create(nonOverwriteFile, false)).getErrorMessage();\n+\n+      Assertions.assertThat(errorMessage)\n+          .describedAs(\"getPathStatus should fail while recovering\")\n+          .contains(\"Error in getPathStatus while recovering from create failure.\");\n\nReview Comment:\n   Done\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T06:59:31.997+0000", "updated": "2025-02-25T06:59:31.997+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930079", "id": "17930079", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969080817\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1766,4 +1745,69 @@ public void getClientTransactionIdAfterRename() throws Exception {\n           .isEqualTo(clientTransactionId[0]);\n     }\n   }\n+\n+  @Test\n+  public void failureInGetPathStatusDuringRenameRecovery() throws Exception {\n+    try (AzureBlobFileSystem fs = getFileSystem()) {\n+      assumeRecoveryThroughClientTransactionID(false);\n+      AbfsDfsClient abfsDfsClient = (AbfsDfsClient) Mockito.spy(fs.getAbfsClient());\n+      fs.getAbfsStore().setClient(abfsDfsClient);\n+      final String[] clientTransactionId = new String[1];\n+      mockAddClientTransactionIdToHeader(abfsDfsClient, clientTransactionId);\n+      mockRetriedRequest(abfsDfsClient, new ArrayList<>());\n+      boolean[] flag = new boolean[1];\n+      Mockito.doAnswer(getPathStatus -> {\n+        if (!flag[0]) {\n+          flag[0] = true;\n+          throw new AbfsRestOperationException(HTTP_CLIENT_TIMEOUT, \"\", \"\", new Exception());\n+        }\n+        return getPathStatus.callRealMethod();\n+      }).when(abfsDfsClient).getPathStatus(\n+          Mockito.nullable(String.class), Mockito.nullable(Boolean.class),\n+          Mockito.nullable(TracingContext.class),\n+          Mockito.nullable(ContextEncryptionAdapter.class));\n+\n+      Path sourceDir = path(\"/testSrc\");\n+      assertMkdirs(fs, sourceDir);\n+      String filename = \"file1\";\n+      Path sourceFilePath = new Path(sourceDir, filename);\n+      touch(sourceFilePath);\n+      Path destFilePath = new Path(sourceDir, \"file2\");\n+\n+      String errorMessage = intercept(AbfsDriverException.class,\n+          () -> fs.rename(sourceFilePath, destFilePath)).getErrorMessage();\n+\n+      Assertions.assertThat(errorMessage)\n+          .describedAs(\"getPathStatus should fail while recovering\")\n+          .contains(\"Error in getPathStatus while recovering from rename failure.\");\n\nReview Comment:\n   Done\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1641,4 +1653,180 @@ public void testRenameSrcDirDeleteEmitDeletionCountInClientRequestId()\n             Mockito.any(TracingContext.class));\n     fs.rename(new Path(dirPathStr), new Path(\"/dst/\"));\n   }\n+\n+  /**\n+   * Test to verify the idempotency of the `rename` operation in Azure Blob File System when retrying\n+   * after a failure. The test simulates a \"path not found\" error (HTTP 404) on the first attempt,\n+   * checks that the operation correctly retries using the appropriate transaction ID,\n+   * and ensures that the source file is renamed to the destination path once successful.\n+   *\n+   * @throws Exception if an error occurs during the file system operations or mocking\n+   */\n+  @Test\n+  public void renamePathRetryIdempotency() throws Exception {\n\nReview Comment:\n   Done\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T06:59:46.694+0000", "updated": "2025-02-25T06:59:46.694+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930148", "id": "17930148", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969224763\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -1658,4 +1638,22 @@ public String addClientTransactionIdToHeader(List<AbfsHttpHeader> requestHeaders\n     }\n     return clientTransactionId;\n   }\n+\n+  /**\n+   * Get the dummy success operation.\n+   * @param operationType type of the operation\n+   * @param httpMethod http method\n+   * @param url url to be used\n+   * @param requestHeaders list of headers to be sent with the request\n+   * @return success operation\n+   * @throws AzureBlobFileSystemException if rest operation fails.\n+   */\n+  private AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationType,\n\nReview Comment:\n   This method should go in AbfsClient class\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T08:16:05.417+0000", "updated": "2025-02-25T08:16:05.417+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930244", "id": "17930244", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969437578\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -1658,4 +1638,22 @@ public String addClientTransactionIdToHeader(List<AbfsHttpHeader> requestHeaders\n     }\n     return clientTransactionId;\n   }\n+\n+  /**\n+   * Get the dummy success operation.\n+   * @param operationType type of the operation\n+   * @param httpMethod http method\n+   * @param url url to be used\n+   * @param requestHeaders list of headers to be sent with the request\n+   * @return success operation\n+   * @throws AzureBlobFileSystemException if rest operation fails.\n+   */\n+  private AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationType,\n\nReview Comment:\n   Moved to AbfsClient\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T10:02:39.427+0000", "updated": "2025-02-25T10:02:39.427+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930292", "id": "17930292", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969581000\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java:\n##########\n@@ -733,4 +733,28 @@ protected void checkFuturesForExceptions(List<Future<?>> futures, int exceptionV\n     }\n     assertEquals(exceptionCaught, exceptionVal);\n   }\n+\n+  /**\n+   * Assumes that recovery through client transaction ID is enabled.\n+   * Namespace is enabled for the given AzureBlobFileSystem.\n+   * Service type is DFS.\n+   * Assumes that the client transaction ID is enabled in the configuration.\n+   *\n+   * @throws IOException in case of an error\n+   */\n+  protected void assumeRecoveryThroughClientTransactionID(boolean isCreate)\n+      throws IOException {\n+    // Assumes that recovery through client transaction ID is enabled.\n+    Assume.assumeTrue(getConfiguration().getIsClientTransactionIdEnabled());\n\nReview Comment:\n   Add descirption message to tell use which config need to be enabled.\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T11:29:41.735+0000", "updated": "2025-02-25T11:29:41.735+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930322", "id": "17930322", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1969722624\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -415,7 +416,9 @@ public AbfsRestOperation createPath(final String path,\n           String existingResource =\n               op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n           if (existingResource != null && existingResource.equals(DIRECTORY)) {\n-            return op; //don't throw ex on mkdirs for existing directory\n+            //don't throw ex on mkdirs for existing directory\n+            return getSuccessOp(AbfsRestOperationType.CreatePath,\n\nReview Comment:\n   There are a few places this is also used in `AbfsBlobCient` we can call the new method there as well.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T12:52:19.336+0000", "updated": "2025-02-25T12:52:19.336+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930361", "id": "17930361", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2682255026\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 57s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 51s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 13s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 32s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 44s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 132m 59s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/14/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 9aa3f277e7ec 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b0ad61c8bffa38fbb8be5ea080aafe023c417d6a |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/14/testReport/ |\r\n   | Max. process+thread count | 581 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/14/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T14:52:22.421+0000", "updated": "2025-02-25T14:52:22.421+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930378", "id": "17930378", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2682428624\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  18m 31s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 12s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 28s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 49s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 59s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 49s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 151m 55s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/15/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux c810928ed5bb 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7c930585881eb4a86946d2f3bc5b4620b75beb0b |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/15/testReport/ |\r\n   | Max. process+thread count | 599 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/15/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T15:42:52.097+0000", "updated": "2025-02-25T15:42:52.097+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930380", "id": "17930380", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2682434970\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 38s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 16s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 35s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 56s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 35s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 31s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 15s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 48s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 38s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 143m 21s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/16/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7364 |\r\n   | JIRA Issue | HADOOP-19450 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 41d9cc2dba4d 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 7c930585881eb4a86946d2f3bc5b4620b75beb0b |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/16/testReport/ |\r\n   | Max. process+thread count | 530 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7364/16/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-25T15:44:38.745+0000", "updated": "2025-02-25T15:44:38.745+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930537", "id": "17930537", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#issuecomment-2683965336\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 770, Failures: 0, Errors: 0, Skipped: 143\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 1\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 773, Failures: 0, Errors: 0, Skipped: 97\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 1\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 612, Failures: 0, Errors: 0, Skipped: 199\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 770, Failures: 0, Errors: 0, Skipped: 148\r\n   [WARNING] Tests run: 124, Failures: 0, Errors: 0, Skipped: 2\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 615, Failures: 0, Errors: 0, Skipped: 142\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 609, Failures: 0, Errors: 0, Skipped: 200\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 612, Failures: 0, Errors: 0, Skipped: 143\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 610, Failures: 0, Errors: 0, Skipped: 160\r\n   [WARNING] Tests run: 124, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 644, Failures: 0, Errors: 0, Skipped: 146\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 1\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 609, Failures: 0, Errors: 0, Skipped: 198\r\n   [WARNING] Tests run: 147, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-26T05:51:29.863+0000", "updated": "2025-02-26T05:51:29.863+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930579", "id": "17930579", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "snvijaya commented on code in PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364#discussion_r1967174996\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -216,6 +216,11 @@ private AbfsClient(final URL baseUrl,\n       encryptionType = EncryptionType.GLOBAL_KEY;\n     }\n \n+    // Version update needed to support x-ms-client-transaction-id header\n\nReview Comment:\n   API versions arent configurable to avoid too forks in API + versions supported. Earlier there was a fork for CPK support but that was because global deployment wasn't complete at service end. moving to the latest API version is fine as long as all validations (all test combinations) are complete. \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-26T07:47:13.777+0000", "updated": "2025-02-26T07:47:13.777+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930784", "id": "17930784", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7364:\nURL: https://github.com/apache/hadoop/pull/7364\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-26T18:23:29.874+0000", "updated": "2025-02-26T18:23:29.874+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17930979", "id": "17930979", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 opened a new pull request, #7436:\nURL: https://github.com/apache/hadoop/pull/7436\n\n   Description\r\n   -----------------------------------------------------------------------------------------------------------------------------------------------\r\n   CreatePath and RenamePath APIs are idempotent as subsequent retries on same resource don\u2019t change the server state[[1]](bookmark://rfcIdempotency). However, when client experiences connection break on the CreatePath and the RenamePath APIs, client cannot make sense if the request is accepted by the server or not. \r\n   \r\n   On connection failure, the client retries the request. The server might return 404 (sourceNotFound) in case of RenamePath API and 409 (pathAlreadyExists) in case of CreatePath (overwrite=false) API. Now the client doesn\u2019t have a path forward. Reason being, in case of CreatePath, client doesn\u2019t know if the path was created on the original request or the path was already there for some other request, in case of RenamePath, client doesn\u2019t know if the source was removed because of the original-try or it was not there on the first place.\r\n   \r\n   Proposed Solution\r\n   ---------------------------------------------------------------------------------------------------------------------------------------------\r\n   Driver will send addition header \"x-ms-client-transaction-id\" which will store by the server. In case first call fails because of time out and retry happens and server throw source not found (in case of rename) and path already exist (in case of create call). Driver will do list call on the path and check whether the \"x-ms-client-transaction-id\" returned by server same as what driver has at its end. In such case driver will return success to the caller.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-27T05:35:58.284+0000", "updated": "2025-02-27T05:35:58.284+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17931011", "id": "17931011", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7436:\nURL: https://github.com/apache/hadoop/pull/7436#issuecomment-2687065696\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   7m 11s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 7 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m  4s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 27s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 45s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  18m 49s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 14s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 12s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 15s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m  3s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m  3s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 24s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  76m 26s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7436/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7436 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux ef0287de7548 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / 8007dab74f2bf5d3f4d0f02c0c7a8e7c48793e3f |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7436/1/testReport/ |\r\n   | Max. process+thread count | 554 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7436/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-27T06:53:23.876+0000", "updated": "2025-02-27T06:53:23.876+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17931114", "id": "17931114", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on PR #7436:\nURL: https://github.com/apache/hadoop/pull/7436#issuecomment-2687586863\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 782, Failures: 0, Errors: 0, Skipped: 155\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 25\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 782, Failures: 0, Errors: 0, Skipped: 106\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 25\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 766, Failures: 0, Errors: 0, Skipped: 353\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 782, Failures: 0, Errors: 0, Skipped: 160\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 49\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 766, Failures: 0, Errors: 0, Skipped: 293\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 28\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 766, Failures: 0, Errors: 0, Skipped: 357\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 766, Failures: 0, Errors: 0, Skipped: 297\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 28\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 766, Failures: 0, Errors: 0, Skipped: 316\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 52\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 782, Failures: 0, Errors: 0, Skipped: 284\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 25\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 766, Failures: 0, Errors: 0, Skipped: 355\r\n   [WARNING] Tests run: 171, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 262, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-27T10:50:58.775+0000", "updated": "2025-02-27T10:50:58.775+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13607595/comment/17931124", "id": "17931124", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7436:\nURL: https://github.com/apache/hadoop/pull/7436\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-02-27T11:34:05.823+0000", "updated": "2025-02-27T11:34:05.823+0000"}], "maxResults": 71, "total": 71, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}