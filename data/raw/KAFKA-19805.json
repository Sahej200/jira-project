{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13631781", "self": "https://issues.apache.org/jira/rest/api/2/issue/13631781", "key": "KAFKA-19805", "fields": {"summary": "Add acks dimension to BrokerTopicMetrics for produce requests", "description": "h3. *Title*\r\n\r\nAdd {{acks}} dimension to {{BrokerTopicMetrics}} to measure per-acks produce performance impact\r\n----\r\nh3. *Summary*\r\n\r\nCurrently, Kafka\u2019s {{BrokerTopicMetrics}} only tracks produce metrics such as {{{}BytesInPerSec{}}}, {{{}MessagesInPerSec{}}}, and {{ProduceRequestsPerSec}} at the topic level. However, these metrics do not distinguish between different producer acknowledgment ({{{}acks{}}}) configurations ({{{}acks=0{}}}, {{{}acks=1{}}}, {{{}acks=-1{}}}).\r\nIn high-throughput environments, different {{acks}} levels have significantly different impacts on broker CPU, I/O, and network utilization.\r\nThis proposal introduces an additional {{acks}} label to existing topic-level metrics, enabling more granular visibility into broker performance under various producer reliability modes.\r\n----\r\nh3. *Motivation*\r\n\r\nThe current aggregated produce metrics make it difficult to assess the performance and stability implications of different {{acks}} settings on brokers.\r\nFor example, asynchronous ({{{}acks=0{}}}) and fully acknowledged ({{{}acks=-1{}}}) produces can have very different effects on disk I/O, request queues, and replication latency, but these effects are hidden in current metrics.\r\n\r\nBy introducing an {{acks}} dimension, operators and performance engineers can:\r\n * Quantify the resource cost of different producer acknowledgment strategies.\r\n\r\n * Analyze how {{acks}} configuration affects cluster throughput, replication load, and latency.\r\n\r\n * Perform fine-grained benchmarking and capacity planning.\r\n\r\n----\r\nh3. *Proposed Changes*\r\n # *Extend {{BrokerTopicStats}}*\r\nAdd a new {{perTopicAcksStats}} structure to track metrics per {{(topic, acks)}} combination:\r\n\r\n{code:java}\r\nval perTopicAcksStats = new Pool[(String, Short), BrokerTopicMetrics](\r\nSome((key) => new BrokerTopicMetrics(Some(s\"${key._1},ack=${key._2}\")))\r\n){code}\r\n # *Instrument Produce Handling*\r\nIn {{{}KafkaApis.handleProduceRequest{}}}, extract the producer {{acks}} value and record metrics accordingly:\r\n\r\n{code:java}\r\nval ackVal = produceRequest.acks()\r\nbrokerTopicStats.topicStats(topic).bytesInRate.mark(bytes)\r\nbrokerTopicStats.topicAcksStats(topic, ackVal).bytesInRate.mark(bytes){code}\r\nThe same logic applies to:\r\n * \r\n ** {{messagesInRate}}\r\n\r\n * \r\n ** {{produceRequestsRate}}\r\n\r\n # *Automatic Metric Naming*\r\nSince {{BrokerTopicMetrics}} extends {{{}KafkaMetricsGroup{}}}, the new label will automatically generate JMX metrics like:\r\n\r\n{{kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=perf-test,ack=-1\r\nkafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=perf-test,ack=1\r\nkafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=perf-test,ack=0}}\r\n # *Performance Considerations*\r\n\r\n * \r\n ** {{perTopicAcksStats}} uses lazy initialization and caching via {{Pool}} to avoid excessive metric object creation.\r\n\r\n * \r\n ** Expiration or cleanup logic can be added for inactive metrics.\r\n\r\n----\r\nh3. *Example Metrics Output*\r\n\r\n\u00a0\r\n{code:java}\r\nkafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=perf-test,ack=0\r\nkafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=perf-test,ack=1\r\nkafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=perf-test,ack=-1{code}\r\n----\r\nh3. *Compatibility & Impact*\r\n * No breaking changes to existing metrics.\r\n\r\n * Existing metric names and topic-level aggregation remain unaffected.\r\n\r\n * New metrics are additive and optional.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=jasirvoriya", "name": "jasirvoriya", "key": "JIRAUSER311227", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "\u4f0d\u5b66\u660e", "active": true, "timeZone": "Asia/Shanghai"}, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}