{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13632675", "self": "https://issues.apache.org/jira/rest/api/2/issue/13632675", "key": "SPARK-54058", "fields": {"summary": "Fix Flaky Test: `KafkaMicroBatchV1SourceWithConsumerSuite.Query with Trigger.AvailableNow should throw error when topic partitions got unavailable during subsequent batches`", "description": "Recently, `KafkaMicroBatchV1SourceWithConsumerSuite.Query with Trigger.AvailableNow should throw error when topic partitions got unavailable during subsequent batches` frequently fails.\r\n\r\n[https://github.com/apache/spark/actions/runs/18872699886/job/53854858890]\r\n\r\n\u00a0\r\n{code:java}\r\n[info] - Query with Trigger.AvailableNow should throw error when topic partitions got unavailable during subsequent batches *** FAILED *** (1 minute)\r\n[info]   java.lang.AssertionError: assertion failed: Exception tree doesn't contain the expected exception with message: Some of partitions in Kafka topic(s) have been lost during running query with Trigger.AvailableNow.\r\n[info] org.scalatest.exceptions.TestFailedException: isPropagated was false Partition [topic-41, 1] metadata not propagated after timeout\r\n[info] \tat org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:472)\r\n[info] \tat org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:471)\r\n[info] \tat org.scalatest.Assertions$.newAssertionFailedException(Assertions.scala:1231)\r\n[info] \tat org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:1295)\r\n[info] \tat org.apache.spark.sql.kafka010.KafkaTestUtils.$anonfun$waitUntilMetadataIsPropagated$1(KafkaTestUtils.scala:614)\r\n[info] \tat org.scalatest.enablers.Retrying$$anon$4.makeAValiantAttempt$1(Retrying.scala:184)\r\n[info] \tat org.scalatest.enablers.Retrying$$anon$4.tryTryAgain$2(Retrying.scala:196)\r\n[info] \tat org.scalatest.enablers.Retrying$$anon$4.retry(Retrying.scala:226)\r\n[info] \tat org.scalatest.concurrent.Eventually.eventually(Eventually.scala:348)\r\n[info] \tat org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:347)\r\n[info] \tat org.scalatest.concurrent.Eventually$.eventually(Eventually.scala:457)\r\n[info] \tat org.apache.spark.sql.kafka010.KafkaTestUtils.waitUntilMetadataIsPropagated(KafkaTestUtils.scala:613)\r\n[info] \tat org.apache.spark.sql.kafka010.KafkaTestUtils.$anonfun$createTopic$1(KafkaTestUtils.scala:378)\r\n[info] \tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:256)\r\n[info] \tat org.apache.spark.sql.kafka010.KafkaTestUtils.createTopic(KafkaTestUtils.scala:377)\r\n[info] \tat org.apache.spark.sql.kafka010.KafkaMicroBatchSourceSuiteBase.$anonfun$new$11(KafkaMicroBatchSourceSuite.scala:352)\r\n[info] \tat org.apache.spark.sql.kafka010.KafkaMicroBatchSourceSuiteBase.$anonfun$new$11$adapted(KafkaMicroBatchSourceSuite.scala:349)\r\n[info] \tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.callBatchWriter(ForeachBatchSink.scala:56)\r\n[info] \tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:49)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runBatch$19(MicroBatchExecution.scala:1063)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:176)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:284)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:138)\r\n[info] \tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n[info] \tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n[info] \tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\r\n[info] \tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:138)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:307)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:137)\r\n[info] \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:91)\r\n[info] \tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runBatch$18(MicroBatchExecution.scala:1054)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runBatch(MicroBatchExecution.scala:1054)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$executeOneBatch$2(MicroBatchExecution.scala:513)\r\n[info] \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.ProgressContext.reportTimeTaken(ProgressReporter.scala:200)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.executeOneBatch(MicroBatchExecution.scala:478)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:458)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.$anonfun$runActivatedStream$1$adapted(MicroBatchExecution.scala:458)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch(TriggerExecutor.scala:40)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.TriggerExecutor.runOneBatch$(TriggerExecutor.scala:38)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MultiBatchExecutor.runOneBatch(TriggerExecutor.scala:60)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MultiBatchExecutor.execute(TriggerExecutor.scala:65)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:458)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:347)\r\n[info] \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n[info] \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution.org$apache$spark$sql$execution$streaming$runtime$StreamExecution$$runStream(StreamExecution.scala:307)\r\n[info] \tat org.apache.spark.sql.execution.streaming.runtime.StreamExecution$$anon$1.run(StreamExecution.scala:230)\r\n[info]   at scala.Predef$.assert(Predef.scala:279)\r\n[info]   at org.apache.spark.TestUtils$.assertExceptionMsg(TestUtils.scala:198)\r\n[info]   at org.apache.spark.sql.kafka010.KafkaMicroBatchSourceSuiteBase.$anonfun$new$9(KafkaMicroBatchSourceSuite.scala:374)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n[info]   at org.scalatest.enablers.Timed$$anon$1.timeoutAfter(Timed.scala:127)\r\n[info]   at org.scalatest.concurrent.TimeLimits$.failAfterImpl(TimeLimits.scala:282)\r\n[info]   at org.scalatest.concurrent.TimeLimits.failAfter(TimeLimits.scala:231)\r\n[info]   at org.scalatest.concurrent.TimeLimits.failAfter$(TimeLimits.scala:230)\r\n[info]   at org.apache.spark.SparkFunSuite.failAfter(SparkFunSuite.scala:68)\r\n[info]   at org.apache.spark.SparkFunSuite.$anonfun$test$2(SparkFunSuite.scala:154)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\r\n[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)\r\n[info]   at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:226)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)\r\n[info]   at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterEach$$super$runTest(SparkFunSuite.scala:68)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)\r\n[info]   at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:68)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:323)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1114)\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1096)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)\r\n[info]   at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:68)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:68)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)\r\n[info]   at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n[info]   at java.base/java.lang.Thread.run(Thread.java:840) {code}", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=sarutak", "name": "sarutak", "key": "sarutak", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=sarutak&avatarId=20842", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=sarutak&avatarId=20842", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=sarutak&avatarId=20842", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=sarutak&avatarId=20842"}, "displayName": "Kousuke Saruta", "active": true, "timeZone": "Asia/Tokyo"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13632675/comment/18033662", "id": "18033662", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=dongjoon", "name": "dongjoon", "key": "dongjoon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=dongjoon&avatarId=42503", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dongjoon&avatarId=42503", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dongjoon&avatarId=42503", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dongjoon&avatarId=42503"}, "displayName": "Dongjoon Hyun", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Issue resolved by pull request 52766\n[https://github.com/apache/spark/pull/52766]", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=dongjoon", "name": "dongjoon", "key": "dongjoon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=dongjoon&avatarId=42503", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=dongjoon&avatarId=42503", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=dongjoon&avatarId=42503", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=dongjoon&avatarId=42503"}, "displayName": "Dongjoon Hyun", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-28T19:07:45.864+0000", "updated": "2025-10-28T19:07:45.864+0000"}], "maxResults": 1, "total": 1, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}