{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13614928", "self": "https://issues.apache.org/jira/rest/api/2/issue/13614928", "key": "HADOOP-19536", "fields": {"summary": "S3A : Add option for custom S3 tags while writing and deleting S3 objects", "description": "Custom S3 object [tags|https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-tagging.html] can be added to S3 objects while writing and deleting.\r\n\r\n*Use Case:*\r\n\r\nS3 tags can be used to categorize the [objects|https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-tagging.html] and potentially apply bucket level polices to take some actions.\r\n\r\nFor example : objects can be marked as \"to-be-glacier\" and based on some bucket policy the written objects can be moved to Glacier tier after sometime for cost savings.\r\n\r\nApache iceberg's [S3FileIO|#s3-tags]] also uses S3 Tags for soft deletes.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=srahman", "name": "srahman", "key": "srahman", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"}, "displayName": "Syed Shameerur Rahman", "active": true, "timeZone": "Etc/UTC"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/17944352", "id": "17944352", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "* would this be a bucket setting?\r\n* or in file creation\r\n\r\ntags can be changed, cant they? which means the xattr api should be used to get at them.\r\n\r\n* we already use xattr to read headers (though we got the naming of those attrs wrong in a way which complicates some apps)\r\n* we could extend this to allow get *and set* of tags\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-04-14T12:25:22.075+0000", "updated": "2025-04-14T12:25:22.075+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010306", "id": "18010306", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "body": "Hey [~stevel@apache.org] , I will be working on this ticket.\r\n\r\nTo answer your questions this will be a feature of S3A which will be operated through configs. Any component when interacting to S3 using S3A, if provided with relevant configs (which will be newly created) then the tags will be applied in S3. These configs can be added while creating an object or deleting an object in S3.\u00a0\r\n\r\nConfig for adding the tag : fs.s3a.object.tag.* (comma separated key and values) or fs.s3a.object.tag.\\{TAG_NAME} (separate configs)\r\n\r\nConfig for deleting the tag : {{fs.s3a.soft.delete.enabled=true}}\r\n\r\nExample :\u00a0\r\n\r\n1. hadoop fs -Dfs.s3a.object.tag.department=finance,project=alpha -put file.txt s3a://bucket/path/\r\n\r\nor adding conf in different lines : --conf spark.hadoop.fs.s3a.object.tag.department=finance \\\r\n--conf spark.hadoop.fs.s3a.object.tag.project=alpha \\\r\n\r\nThis command will add tags with key as department and project and value as finance and alpha respectively.\r\n\r\n2. hadoop fs \\\r\n-Dfs.s3a.soft.delete.enabled=true \\\r\n-Dfs.s3a.soft.delete.tag.key=archive \\\r\n-Dfs.s3a.soft.delete.tag.value=true \\\r\n-rm s3a://ayshukla-emr-dev/tagged-file27.txt\r\n\r\nIn this tagged-file27.txt will not be deleted. Instead a tag will be added with key as archive and value as true (since those are defined by user).\r\n\r\nHere if no key and value tag are added then a default delete tag can be added. For example key is status and value as deleted.\r\n\r\nDocumented this in the attached pdf.\u00a0\r\n\r\n\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-28T09:07:38.364+0000", "updated": "2025-07-28T09:12:03.135+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010413", "id": "18010413", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "ok. \r\n* soft delete is special, as that is mapping a delete call to a tag update\r\n* can you help me get my impala PR for bulk delete in (https://github.com/apache/iceberg/pull/10233) )especially why those tests don't work, as that will reduce delete time by an order of magnitude, with shipping hadoop releases. Then tagging can be done. \r\n\r\nnow, can you put the design up, ideally as a doc in a PR ()e.g. hadoop-aws/src/main/site/..../tagging.md  so that we can review it. thanks", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-07-28T13:54:29.971+0000", "updated": "2025-07-28T13:54:29.971+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010663", "id": "18010663", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ayush1300 opened a new pull request, #7834:\nURL: https://github.com/apache/hadoop/pull/7834\n\n   <!--\r\n     Thanks for sending a pull request!\r\n       1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute\r\n       2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.\r\n   -->\r\n   \r\n   ### Description of PR\r\n   - The PR is created to add the DOC section of the tagging functionality which is to be added for S3A connector.\r\n   - Issue URL : https://issues.apache.org/jira/browse/HADOOP-19536\r\n   \r\n   ### How was this patch tested?\r\n   - Doc added \r\n   \r\n   ### For code changes:\r\n   \r\n   - [Yes] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T12:53:33.185+0000", "updated": "2025-07-29T12:53:33.185+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010664", "id": "18010664", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "body": "Hey [~stevel@apache.org] thanks. Please find my PR : [https://github.com/apache/hadoop/pull/7834]\r\n\r\nSure I will look into your PR and see how can I support.\r\n\r\nThanks!!", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T12:55:03.329+0000", "updated": "2025-07-29T12:55:03.329+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010697", "id": "18010697", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#issuecomment-3133027709\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 29s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  45m 14s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 43s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  86m  9s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  40m 31s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  asflicense  |   0m 38s | [/results-asflicense.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7834/1/artifact/out/results-asflicense.txt) |  The patch generated 1 ASF License warnings.  |\r\n   |  |   | 149m 59s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7834/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7834 |\r\n   | Optional Tests | dupname asflicense mvnsite codespell detsecrets markdownlint |\r\n   | uname | Linux 842afd4dd444 5.15.0-143-generic #153-Ubuntu SMP Fri Jun 13 19:10:45 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 95bfec724dbe0f329153a7b43ae106389a672fd0 |\r\n   | Max. process+thread count | 611 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7834/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-29T15:24:57.019+0000", "updated": "2025-07-29T15:24:57.019+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010883", "id": "18010883", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#discussion_r2242160657\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3aTagging.md:\n##########\n@@ -0,0 +1,298 @@\n+# S3 Object Tagging Support in Hadoop S3A Filesystem\n+\n+## Overview\n+\n+The Hadoop S3A filesystem connector now supports S3 object tagging, allowing users to automatically assign metadata tags to S3 objects during creation and soft deletion operations. This feature enables better data organization, cost allocation, access control, and lifecycle management for S3-stored data.\n+\n+**JIRA Issue**: [HADOOP-19536](https://issues.apache.org/jira/browse/HADOOP-19536#s3-tags)\n+\n+## Table of Contents\n+\n+- [Motivation](#motivation)\n+- [S3 Object Tagging Capabilities](#s3-object-tagging-capabilities)\n+- [Use Cases](#use-cases)\n+- [Configuration](#configuration)\n+- [Usage Examples](#usage-examples)\n+- [Soft Delete Feature](#soft-delete-feature)\n+- [Best Practices](#best-practices)\n+- [Limitations](#limitations)\n+\n+## Motivation\n+\n+Amazon S3 supports tagging objects with key-value pairs, providing several critical benefits:\n+\n+1. **Cost Allocation**: Track and allocate S3 storage costs across departments, projects, or cost centers\n+2. **Access Control**: Use tags in IAM policies to control object access permissions\n+3. **Lifecycle Management**: Trigger automated lifecycle policies for object transitions and expiration\n+4. **Data Classification**: Organize and classify data for compliance, security, and business requirements\n+5. **Analytics and Reporting**: Enable detailed analytics and reporting based on object metadata\n+\n+Previously, the Hadoop S3A connector lacked native support for object tagging, requiring users to implement custom solutions or use separate tools to tag objects post-creation.\n+\n+## S3 Object Tagging Capabilities\n+\n+### Tag Specifications\n+- **Maximum Tags**: Up to 10 tags per object\n+- **Structure**: Key-value pairs\n+- **Key Length**: Up to 128 Unicode characters\n+- **Value Length**: Up to 256 Unicode characters\n+- **Case Sensitivity**: Keys and values are case-sensitive\n+- **Uniqueness**: Tag keys must be unique per object (no duplicate keys)\n+\n+### Allowed Characters\n+Tag keys and values can contain:\n+- Letters (a-z, A-Z)\n+- Numbers (0-9)\n+- Spaces\n+- Special symbols: `. : + - = _ / @`\n+\n+## Use Cases\n+\n+### 1. Access Control with IAM Policies\n+\n+Control object access based on tags:\n+\n+```json\n+{\n+    \"Effect\": \"Allow\",\n+    \"Action\": \"s3:GetObject\",\n+    \"Resource\": \"*\",\n+    \"Condition\": {\n+        \"StringEquals\": {\n+            \"s3:ExistingObjectTag/department\": \"finance\"\n+        }\n+    }\n+}\n+```\n+\n+### 2. Lifecycle Management\n+\n+Trigger lifecycle rules based on tags:\n+\n+```json\n+{\n+    \"Rules\": [\n+        {\n+            \"Status\": \"Enabled\",\n+            \"Filter\": {\n+                \"Tag\": {\n+                    \"Key\": \"retention\",\n+                    \"Value\": \"temporary\"\n+                }\n+            },\n+            \"Expiration\": {\n+                \"Days\": 30\n+            }\n+        }\n+    ]\n+}\n+```\n+\n+### 3. Cost Allocation and Tracking\n+\n+- Use tags for cost tracking in AWS Cost Explorer\n+- Allocate costs across different business units or projects\n+- Generate detailed billing reports by tag dimensions\n+\n+### 4. Data Analytics and Filtering\n+\n+- Use S3 Analytics to filter and analyze data by tags\n+- Create custom reports based on tagged object metadata\n+- Enable data governance and compliance reporting\n+\n+## Configuration\n+\n+### Object Creation Tags\n+\n+#### Method 1: Comma-Separated List\n+```properties\n+fs.s3a.object.tags=department=finance,project=alpha,owner=data-team\n+```\n+\n+#### Method 2: Individual Tag Properties\n+```properties\n+fs.s3a.object.tag.department=finance\n+fs.s3a.object.tag.project=alpha\n+fs.s3a.object.tag.owner=data-team\n+fs.s3a.object.tag.environment=production\n+```\n+\n+### Soft Delete Tags\n+```properties\n+fs.s3a.soft.delete.enabled=true\n+fs.s3a.soft.delete.tag.key=archive\n+fs.s3a.soft.delete.tag.value=true\n+```\n+\n+## Usage Examples\n+\n+### Spark Applications\n+\n+#### Using Comma-Separated Tags\n+```bash\n+spark-submit \\\n+  --conf spark.hadoop.fs.s3a.object.tags=department=finance,project=alpha,environment=prod \\\n+  --class MySparkApp \\\n+  my-app.jar\n+```\n+\n+#### Using Individual Tag Configurations\n+```bash\n+spark-submit \\\n+  --conf spark.hadoop.fs.s3a.object.tag.department=finance \\\n+  --conf spark.hadoop.fs.s3a.object.tag.project=alpha \\\n+  --conf spark.hadoop.fs.s3a.object.tag.owner=data-team \\\n+  --conf spark.hadoop.fs.s3a.object.tag.cost-center=engineering \\\n+  --class MySparkApp \\\n+  my-app.jar\n+```\n+\n+### Hadoop Commands\n+\n+#### File Upload with Tags\n+```bash\n+hadoop fs \\\n+  -Dfs.s3a.object.tag.department=finance \\\n+  -Dfs.s3a.object.tag.project=quarterly-report \\\n+  -put local-file.txt s3a://my-bucket/reports/\n+```\n+\n+#### Directory Operations with Tags\n+```bash\n+hadoop fs \\\n+  -Dfs.s3a.object.tags=team=analytics,retention=long-term \\\n+  -put /local/data/ s3a://my-bucket/analytics/\n+```\n+\n+### MapReduce Jobs\n+\n+```bash\n+hadoop jar my-job.jar \\\n+  -Dfs.s3a.object.tag.job-type=etl \\\n+  -Dfs.s3a.object.tag.priority=high \\\n+  input s3a://my-bucket/output/\n+```\n+\n+## Soft Delete Feature\n+\n+The soft delete feature allows you to tag objects instead of permanently deleting them, enabling data retention policies and recovery options.\n\nReview Comment:\n   or people use versioned buckets, obviously\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3aTagging.md:\n##########\n@@ -0,0 +1,298 @@\n+# S3 Object Tagging Support in Hadoop S3A Filesystem\n+\n+## Overview\n+\n+The Hadoop S3A filesystem connector now supports S3 object tagging, allowing users to automatically assign metadata tags to S3 objects during creation and soft deletion operations. This feature enables better data organization, cost allocation, access control, and lifecycle management for S3-stored data.\n+\n+**JIRA Issue**: [HADOOP-19536](https://issues.apache.org/jira/browse/HADOOP-19536#s3-tags)\n+\n+## Table of Contents\n+\n+- [Motivation](#motivation)\n+- [S3 Object Tagging Capabilities](#s3-object-tagging-capabilities)\n+- [Use Cases](#use-cases)\n+- [Configuration](#configuration)\n+- [Usage Examples](#usage-examples)\n+- [Soft Delete Feature](#soft-delete-feature)\n+- [Best Practices](#best-practices)\n+- [Limitations](#limitations)\n+\n+## Motivation\n+\n+Amazon S3 supports tagging objects with key-value pairs, providing several critical benefits:\n+\n+1. **Cost Allocation**: Track and allocate S3 storage costs across departments, projects, or cost centers\n+2. **Access Control**: Use tags in IAM policies to control object access permissions\n+3. **Lifecycle Management**: Trigger automated lifecycle policies for object transitions and expiration\n+4. **Data Classification**: Organize and classify data for compliance, security, and business requirements\n+5. **Analytics and Reporting**: Enable detailed analytics and reporting based on object metadata\n+\n+Previously, the Hadoop S3A connector lacked native support for object tagging, requiring users to implement custom solutions or use separate tools to tag objects post-creation.\n+\n+## S3 Object Tagging Capabilities\n+\n+### Tag Specifications\n+- **Maximum Tags**: Up to 10 tags per object\n+- **Structure**: Key-value pairs\n+- **Key Length**: Up to 128 Unicode characters\n+- **Value Length**: Up to 256 Unicode characters\n+- **Case Sensitivity**: Keys and values are case-sensitive\n+- **Uniqueness**: Tag keys must be unique per object (no duplicate keys)\n+\n+### Allowed Characters\n+Tag keys and values can contain:\n+- Letters (a-z, A-Z)\n+- Numbers (0-9)\n+- Spaces\n+- Special symbols: `. : + - = _ / @`\n+\n+## Use Cases\n+\n+### 1. Access Control with IAM Policies\n+\n+Control object access based on tags:\n+\n+```json\n+{\n+    \"Effect\": \"Allow\",\n+    \"Action\": \"s3:GetObject\",\n+    \"Resource\": \"*\",\n+    \"Condition\": {\n+        \"StringEquals\": {\n+            \"s3:ExistingObjectTag/department\": \"finance\"\n+        }\n+    }\n+}\n+```\n+\n+### 2. Lifecycle Management\n+\n+Trigger lifecycle rules based on tags:\n+\n+```json\n+{\n+    \"Rules\": [\n+        {\n+            \"Status\": \"Enabled\",\n+            \"Filter\": {\n+                \"Tag\": {\n+                    \"Key\": \"retention\",\n+                    \"Value\": \"temporary\"\n+                }\n+            },\n+            \"Expiration\": {\n+                \"Days\": 30\n+            }\n+        }\n+    ]\n+}\n+```\n+\n+### 3. Cost Allocation and Tracking\n+\n+- Use tags for cost tracking in AWS Cost Explorer\n+- Allocate costs across different business units or projects\n+- Generate detailed billing reports by tag dimensions\n+\n+### 4. Data Analytics and Filtering\n+\n+- Use S3 Analytics to filter and analyze data by tags\n+- Create custom reports based on tagged object metadata\n+- Enable data governance and compliance reporting\n+\n+## Configuration\n+\n+### Object Creation Tags\n+\n+#### Method 1: Comma-Separated List\n+```properties\n+fs.s3a.object.tags=department=finance,project=alpha,owner=data-team\n+```\n+\n+#### Method 2: Individual Tag Properties\n+```properties\n+fs.s3a.object.tag.department=finance\n+fs.s3a.object.tag.project=alpha\n+fs.s3a.object.tag.owner=data-team\n+fs.s3a.object.tag.environment=production\n+```\n+\n+### Soft Delete Tags\n+```properties\n+fs.s3a.soft.delete.enabled=true\n\nReview Comment:\n   is the idea that when enabled, each delete(path) call is remapped to tagging the object for deletion?\r\n   \r\n   is this for recovery or for a performance benefit?\n\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3aTagging.md:\n##########\n@@ -0,0 +1,298 @@\n+# S3 Object Tagging Support in Hadoop S3A Filesystem\n+\n+## Overview\n+\n+The Hadoop S3A filesystem connector now supports S3 object tagging, allowing users to automatically assign metadata tags to S3 objects during creation and soft deletion operations. This feature enables better data organization, cost allocation, access control, and lifecycle management for S3-stored data.\n+\n+**JIRA Issue**: [HADOOP-19536](https://issues.apache.org/jira/browse/HADOOP-19536#s3-tags)\n+\n+## Table of Contents\n+\n+- [Motivation](#motivation)\n+- [S3 Object Tagging Capabilities](#s3-object-tagging-capabilities)\n+- [Use Cases](#use-cases)\n+- [Configuration](#configuration)\n+- [Usage Examples](#usage-examples)\n+- [Soft Delete Feature](#soft-delete-feature)\n+- [Best Practices](#best-practices)\n+- [Limitations](#limitations)\n+\n+## Motivation\n+\n+Amazon S3 supports tagging objects with key-value pairs, providing several critical benefits:\n+\n+1. **Cost Allocation**: Track and allocate S3 storage costs across departments, projects, or cost centers\n+2. **Access Control**: Use tags in IAM policies to control object access permissions\n+3. **Lifecycle Management**: Trigger automated lifecycle policies for object transitions and expiration\n+4. **Data Classification**: Organize and classify data for compliance, security, and business requirements\n+5. **Analytics and Reporting**: Enable detailed analytics and reporting based on object metadata\n+\n+Previously, the Hadoop S3A connector lacked native support for object tagging, requiring users to implement custom solutions or use separate tools to tag objects post-creation.\n+\n+## S3 Object Tagging Capabilities\n+\n+### Tag Specifications\n+- **Maximum Tags**: Up to 10 tags per object\n+- **Structure**: Key-value pairs\n+- **Key Length**: Up to 128 Unicode characters\n+- **Value Length**: Up to 256 Unicode characters\n+- **Case Sensitivity**: Keys and values are case-sensitive\n+- **Uniqueness**: Tag keys must be unique per object (no duplicate keys)\n+\n+### Allowed Characters\n+Tag keys and values can contain:\n+- Letters (a-z, A-Z)\n+- Numbers (0-9)\n+- Spaces\n+- Special symbols: `. : + - = _ / @`\n+\n+## Use Cases\n+\n+### 1. Access Control with IAM Policies\n+\n+Control object access based on tags:\n+\n+```json\n+{\n+    \"Effect\": \"Allow\",\n+    \"Action\": \"s3:GetObject\",\n+    \"Resource\": \"*\",\n+    \"Condition\": {\n+        \"StringEquals\": {\n+            \"s3:ExistingObjectTag/department\": \"finance\"\n+        }\n+    }\n+}\n+```\n+\n+### 2. Lifecycle Management\n+\n+Trigger lifecycle rules based on tags:\n+\n+```json\n+{\n+    \"Rules\": [\n+        {\n+            \"Status\": \"Enabled\",\n+            \"Filter\": {\n+                \"Tag\": {\n+                    \"Key\": \"retention\",\n+                    \"Value\": \"temporary\"\n+                }\n+            },\n+            \"Expiration\": {\n+                \"Days\": 30\n+            }\n+        }\n+    ]\n+}\n+```\n+\n+### 3. Cost Allocation and Tracking\n+\n+- Use tags for cost tracking in AWS Cost Explorer\n+- Allocate costs across different business units or projects\n+- Generate detailed billing reports by tag dimensions\n+\n+### 4. Data Analytics and Filtering\n+\n+- Use S3 Analytics to filter and analyze data by tags\n+- Create custom reports based on tagged object metadata\n+- Enable data governance and compliance reporting\n+\n+## Configuration\n+\n+### Object Creation Tags\n+\n+#### Method 1: Comma-Separated List\n+```properties\n+fs.s3a.object.tags=department=finance,project=alpha,owner=data-team\n+```\n+\n+#### Method 2: Individual Tag Properties\n+```properties\n+fs.s3a.object.tag.department=finance\n+fs.s3a.object.tag.project=alpha\n+fs.s3a.object.tag.owner=data-team\n+fs.s3a.object.tag.environment=production\n+```\n+\n+### Soft Delete Tags\n+```properties\n+fs.s3a.soft.delete.enabled=true\n+fs.s3a.soft.delete.tag.key=archive\n+fs.s3a.soft.delete.tag.value=true\n+```\n+\n+## Usage Examples\n+\n+### Spark Applications\n+\n+#### Using Comma-Separated Tags\n+```bash\n+spark-submit \\\n+  --conf spark.hadoop.fs.s3a.object.tags=department=finance,project=alpha,environment=prod \\\n+  --class MySparkApp \\\n+  my-app.jar\n+```\n+\n+#### Using Individual Tag Configurations\n+```bash\n+spark-submit \\\n+  --conf spark.hadoop.fs.s3a.object.tag.department=finance \\\n+  --conf spark.hadoop.fs.s3a.object.tag.project=alpha \\\n+  --conf spark.hadoop.fs.s3a.object.tag.owner=data-team \\\n+  --conf spark.hadoop.fs.s3a.object.tag.cost-center=engineering \\\n+  --class MySparkApp \\\n+  my-app.jar\n+```\n+\n+### Hadoop Commands\n+\n+#### File Upload with Tags\n+```bash\n+hadoop fs \\\n+  -Dfs.s3a.object.tag.department=finance \\\n+  -Dfs.s3a.object.tag.project=quarterly-report \\\n+  -put local-file.txt s3a://my-bucket/reports/\n+```\n+\n+#### Directory Operations with Tags\n+```bash\n+hadoop fs \\\n+  -Dfs.s3a.object.tags=team=analytics,retention=long-term \\\n+  -put /local/data/ s3a://my-bucket/analytics/\n+```\n+\n+### MapReduce Jobs\n+\n+```bash\n+hadoop jar my-job.jar \\\n+  -Dfs.s3a.object.tag.job-type=etl \\\n+  -Dfs.s3a.object.tag.priority=high \\\n+  input s3a://my-bucket/output/\n+```\n+\n+## Soft Delete Feature\n+\n+The soft delete feature allows you to tag objects instead of permanently deleting them, enabling data retention policies and recovery options.\n+\n+### Important Behavior Notes\n+\n+- **Default Tags**: If no tag key and value are specified, default tags are used as defined in the configuration\n+- **Tag Replacement**: When soft delete is performed, **all existing tags on the object are removed** and replaced with only the soft delete tag specified by the user\n+\n+### Current Implementation\n+\n+```bash\n+# Using custom soft delete tags\n+hadoop fs \\\n+  -Dfs.s3a.soft.delete.enabled=true \\\n+  -Dfs.s3a.soft.delete.tag.key=archive \\\n+  -Dfs.s3a.soft.delete.tag.value=true \\\n+  -rm s3a://my-bucket/file-to-archive.txt\n+\n+# Using default soft delete tags (if configured)\n+hadoop fs \\\n+  -Dfs.s3a.soft.delete.enabled=true \\\n+  -rm s3a://my-bucket/file-to-archive.txt\n+```\n+\n+### Future Capabilities (Planned)\n\nReview Comment:\n   don't make these commitments as they get complex fast. e.g \r\n   \r\n   * what if a path has nothing but soft deleted files underneath. Does it exist? can I do a non-recursive rm of a directory with nothing but soft delete entries underneath? we'd reject now as a LIST call would say stuff is there, and we don't do a HEAD on each file looking for a soft-delete marker.\r\n   * what if I rename a soft-deleted file? does it come back into existence?\r\n   * what if I create a file, the header is set to not create if a file is there, but there's a soft deleted entry?\r\n   \r\n   Better to say\r\n   \r\n   While tagged as soft delete, the files are still visible to filesystem operations\r\n   such as list and create.\r\n   \r\n   \r\n   \r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-07-30T10:18:03.693+0000", "updated": "2025-07-30T10:18:03.693+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18010971", "id": "18010971", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "the getXattr setXattr API should be usable for this as it will allow an existing public hadoop-common API to set the tags.\r\n\r\n* a new path capability declares that an fs supports the api for tag updates (must be something third party store deployments will need to disable)\r\n* the getter and setter calls read/write the attrs.\r\n\r\nwe already use the listXAttrs to list custom headers; tags will need to come in somehow too\r\n\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-07-30T16:21:21.758+0000", "updated": "2025-07-30T16:21:21.758+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011419", "id": "18011419", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ayush1300 commented on code in PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#discussion_r2247805315\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3aTagging.md:\n##########\n@@ -0,0 +1,298 @@\n+# S3 Object Tagging Support in Hadoop S3A Filesystem\n+\n+## Overview\n+\n+The Hadoop S3A filesystem connector now supports S3 object tagging, allowing users to automatically assign metadata tags to S3 objects during creation and soft deletion operations. This feature enables better data organization, cost allocation, access control, and lifecycle management for S3-stored data.\n+\n+**JIRA Issue**: [HADOOP-19536](https://issues.apache.org/jira/browse/HADOOP-19536#s3-tags)\n+\n+## Table of Contents\n+\n+- [Motivation](#motivation)\n+- [S3 Object Tagging Capabilities](#s3-object-tagging-capabilities)\n+- [Use Cases](#use-cases)\n+- [Configuration](#configuration)\n+- [Usage Examples](#usage-examples)\n+- [Soft Delete Feature](#soft-delete-feature)\n+- [Best Practices](#best-practices)\n+- [Limitations](#limitations)\n+\n+## Motivation\n+\n+Amazon S3 supports tagging objects with key-value pairs, providing several critical benefits:\n+\n+1. **Cost Allocation**: Track and allocate S3 storage costs across departments, projects, or cost centers\n+2. **Access Control**: Use tags in IAM policies to control object access permissions\n+3. **Lifecycle Management**: Trigger automated lifecycle policies for object transitions and expiration\n+4. **Data Classification**: Organize and classify data for compliance, security, and business requirements\n+5. **Analytics and Reporting**: Enable detailed analytics and reporting based on object metadata\n+\n+Previously, the Hadoop S3A connector lacked native support for object tagging, requiring users to implement custom solutions or use separate tools to tag objects post-creation.\n+\n+## S3 Object Tagging Capabilities\n+\n+### Tag Specifications\n+- **Maximum Tags**: Up to 10 tags per object\n+- **Structure**: Key-value pairs\n+- **Key Length**: Up to 128 Unicode characters\n+- **Value Length**: Up to 256 Unicode characters\n+- **Case Sensitivity**: Keys and values are case-sensitive\n+- **Uniqueness**: Tag keys must be unique per object (no duplicate keys)\n+\n+### Allowed Characters\n+Tag keys and values can contain:\n+- Letters (a-z, A-Z)\n+- Numbers (0-9)\n+- Spaces\n+- Special symbols: `. : + - = _ / @`\n+\n+## Use Cases\n+\n+### 1. Access Control with IAM Policies\n+\n+Control object access based on tags:\n+\n+```json\n+{\n+    \"Effect\": \"Allow\",\n+    \"Action\": \"s3:GetObject\",\n+    \"Resource\": \"*\",\n+    \"Condition\": {\n+        \"StringEquals\": {\n+            \"s3:ExistingObjectTag/department\": \"finance\"\n+        }\n+    }\n+}\n+```\n+\n+### 2. Lifecycle Management\n+\n+Trigger lifecycle rules based on tags:\n+\n+```json\n+{\n+    \"Rules\": [\n+        {\n+            \"Status\": \"Enabled\",\n+            \"Filter\": {\n+                \"Tag\": {\n+                    \"Key\": \"retention\",\n+                    \"Value\": \"temporary\"\n+                }\n+            },\n+            \"Expiration\": {\n+                \"Days\": 30\n+            }\n+        }\n+    ]\n+}\n+```\n+\n+### 3. Cost Allocation and Tracking\n+\n+- Use tags for cost tracking in AWS Cost Explorer\n+- Allocate costs across different business units or projects\n+- Generate detailed billing reports by tag dimensions\n+\n+### 4. Data Analytics and Filtering\n+\n+- Use S3 Analytics to filter and analyze data by tags\n+- Create custom reports based on tagged object metadata\n+- Enable data governance and compliance reporting\n+\n+## Configuration\n+\n+### Object Creation Tags\n+\n+#### Method 1: Comma-Separated List\n+```properties\n+fs.s3a.object.tags=department=finance,project=alpha,owner=data-team\n+```\n+\n+#### Method 2: Individual Tag Properties\n+```properties\n+fs.s3a.object.tag.department=finance\n+fs.s3a.object.tag.project=alpha\n+fs.s3a.object.tag.owner=data-team\n+fs.s3a.object.tag.environment=production\n+```\n+\n+### Soft Delete Tags\n+```properties\n+fs.s3a.soft.delete.enabled=true\n\nReview Comment:\n   1. Yes the object will be tagged according to the tag given by the user or some default tag for deletion.\r\n   2. It is for recovery. Users can archive some s3 objects on the basis of tags and recover that in future when they need.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T12:02:42.515+0000", "updated": "2025-08-01T12:02:42.515+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011420", "id": "18011420", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ayush1300 commented on code in PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#discussion_r2247806685\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3aTagging.md:\n##########\n@@ -0,0 +1,298 @@\n+# S3 Object Tagging Support in Hadoop S3A Filesystem\n+\n+## Overview\n+\n+The Hadoop S3A filesystem connector now supports S3 object tagging, allowing users to automatically assign metadata tags to S3 objects during creation and soft deletion operations. This feature enables better data organization, cost allocation, access control, and lifecycle management for S3-stored data.\n+\n+**JIRA Issue**: [HADOOP-19536](https://issues.apache.org/jira/browse/HADOOP-19536#s3-tags)\n+\n+## Table of Contents\n+\n+- [Motivation](#motivation)\n+- [S3 Object Tagging Capabilities](#s3-object-tagging-capabilities)\n+- [Use Cases](#use-cases)\n+- [Configuration](#configuration)\n+- [Usage Examples](#usage-examples)\n+- [Soft Delete Feature](#soft-delete-feature)\n+- [Best Practices](#best-practices)\n+- [Limitations](#limitations)\n+\n+## Motivation\n+\n+Amazon S3 supports tagging objects with key-value pairs, providing several critical benefits:\n+\n+1. **Cost Allocation**: Track and allocate S3 storage costs across departments, projects, or cost centers\n+2. **Access Control**: Use tags in IAM policies to control object access permissions\n+3. **Lifecycle Management**: Trigger automated lifecycle policies for object transitions and expiration\n+4. **Data Classification**: Organize and classify data for compliance, security, and business requirements\n+5. **Analytics and Reporting**: Enable detailed analytics and reporting based on object metadata\n+\n+Previously, the Hadoop S3A connector lacked native support for object tagging, requiring users to implement custom solutions or use separate tools to tag objects post-creation.\n+\n+## S3 Object Tagging Capabilities\n+\n+### Tag Specifications\n+- **Maximum Tags**: Up to 10 tags per object\n+- **Structure**: Key-value pairs\n+- **Key Length**: Up to 128 Unicode characters\n+- **Value Length**: Up to 256 Unicode characters\n+- **Case Sensitivity**: Keys and values are case-sensitive\n+- **Uniqueness**: Tag keys must be unique per object (no duplicate keys)\n+\n+### Allowed Characters\n+Tag keys and values can contain:\n+- Letters (a-z, A-Z)\n+- Numbers (0-9)\n+- Spaces\n+- Special symbols: `. : + - = _ / @`\n+\n+## Use Cases\n+\n+### 1. Access Control with IAM Policies\n+\n+Control object access based on tags:\n+\n+```json\n+{\n+    \"Effect\": \"Allow\",\n+    \"Action\": \"s3:GetObject\",\n+    \"Resource\": \"*\",\n+    \"Condition\": {\n+        \"StringEquals\": {\n+            \"s3:ExistingObjectTag/department\": \"finance\"\n+        }\n+    }\n+}\n+```\n+\n+### 2. Lifecycle Management\n+\n+Trigger lifecycle rules based on tags:\n+\n+```json\n+{\n+    \"Rules\": [\n+        {\n+            \"Status\": \"Enabled\",\n+            \"Filter\": {\n+                \"Tag\": {\n+                    \"Key\": \"retention\",\n+                    \"Value\": \"temporary\"\n+                }\n+            },\n+            \"Expiration\": {\n+                \"Days\": 30\n+            }\n+        }\n+    ]\n+}\n+```\n+\n+### 3. Cost Allocation and Tracking\n+\n+- Use tags for cost tracking in AWS Cost Explorer\n+- Allocate costs across different business units or projects\n+- Generate detailed billing reports by tag dimensions\n+\n+### 4. Data Analytics and Filtering\n+\n+- Use S3 Analytics to filter and analyze data by tags\n+- Create custom reports based on tagged object metadata\n+- Enable data governance and compliance reporting\n+\n+## Configuration\n+\n+### Object Creation Tags\n+\n+#### Method 1: Comma-Separated List\n+```properties\n+fs.s3a.object.tags=department=finance,project=alpha,owner=data-team\n+```\n+\n+#### Method 2: Individual Tag Properties\n+```properties\n+fs.s3a.object.tag.department=finance\n+fs.s3a.object.tag.project=alpha\n+fs.s3a.object.tag.owner=data-team\n+fs.s3a.object.tag.environment=production\n+```\n+\n+### Soft Delete Tags\n+```properties\n+fs.s3a.soft.delete.enabled=true\n+fs.s3a.soft.delete.tag.key=archive\n+fs.s3a.soft.delete.tag.value=true\n+```\n+\n+## Usage Examples\n+\n+### Spark Applications\n+\n+#### Using Comma-Separated Tags\n+```bash\n+spark-submit \\\n+  --conf spark.hadoop.fs.s3a.object.tags=department=finance,project=alpha,environment=prod \\\n+  --class MySparkApp \\\n+  my-app.jar\n+```\n+\n+#### Using Individual Tag Configurations\n+```bash\n+spark-submit \\\n+  --conf spark.hadoop.fs.s3a.object.tag.department=finance \\\n+  --conf spark.hadoop.fs.s3a.object.tag.project=alpha \\\n+  --conf spark.hadoop.fs.s3a.object.tag.owner=data-team \\\n+  --conf spark.hadoop.fs.s3a.object.tag.cost-center=engineering \\\n+  --class MySparkApp \\\n+  my-app.jar\n+```\n+\n+### Hadoop Commands\n+\n+#### File Upload with Tags\n+```bash\n+hadoop fs \\\n+  -Dfs.s3a.object.tag.department=finance \\\n+  -Dfs.s3a.object.tag.project=quarterly-report \\\n+  -put local-file.txt s3a://my-bucket/reports/\n+```\n+\n+#### Directory Operations with Tags\n+```bash\n+hadoop fs \\\n+  -Dfs.s3a.object.tags=team=analytics,retention=long-term \\\n+  -put /local/data/ s3a://my-bucket/analytics/\n+```\n+\n+### MapReduce Jobs\n+\n+```bash\n+hadoop jar my-job.jar \\\n+  -Dfs.s3a.object.tag.job-type=etl \\\n+  -Dfs.s3a.object.tag.priority=high \\\n+  input s3a://my-bucket/output/\n+```\n+\n+## Soft Delete Feature\n+\n+The soft delete feature allows you to tag objects instead of permanently deleting them, enabling data retention policies and recovery options.\n+\n+### Important Behavior Notes\n+\n+- **Default Tags**: If no tag key and value are specified, default tags are used as defined in the configuration\n+- **Tag Replacement**: When soft delete is performed, **all existing tags on the object are removed** and replaced with only the soft delete tag specified by the user\n+\n+### Current Implementation\n+\n+```bash\n+# Using custom soft delete tags\n+hadoop fs \\\n+  -Dfs.s3a.soft.delete.enabled=true \\\n+  -Dfs.s3a.soft.delete.tag.key=archive \\\n+  -Dfs.s3a.soft.delete.tag.value=true \\\n+  -rm s3a://my-bucket/file-to-archive.txt\n+\n+# Using default soft delete tags (if configured)\n+hadoop fs \\\n+  -Dfs.s3a.soft.delete.enabled=true \\\n+  -rm s3a://my-bucket/file-to-archive.txt\n+```\n+\n+### Future Capabilities (Planned)\n\nReview Comment:\n   Got it, I will remove this section/rename this accordingly.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T12:03:34.991+0000", "updated": "2025-08-01T12:03:34.991+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011427", "id": "18011427", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "body": "Hi [~stevel@apache.org] ,\r\nWe will get these configs(tag setting configs) as part of initialize method during initialisation of the class.\r\n\u00a0\r\n{code:java}\r\npublic void initialize(URI name, Configuration originalConf){code}\r\nThis class get some original configs. Is there a possibility to set the configs after the initialisation of the class?\r\n\r\nNot clear why we should use getXattr? Please mention if I am missing something here.\r\n\r\nThanks!!\r\n\r\n\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-01T12:45:19.887+0000", "updated": "2025-08-01T12:47:15.756+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011826", "id": "18011826", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ayush1300 closed pull request #7834: HADOOP-19536. S3A : Add option for custom S3 tags while writing and deleting S3 objects\nURL: https://github.com/apache/hadoop/pull/7834\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T09:46:10.897+0000", "updated": "2025-08-04T09:46:10.897+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011837", "id": "18011837", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#issuecomment-3149978209\n\n   @ayush1300 why did you close this?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T10:19:13.652+0000", "updated": "2025-08-04T10:19:13.652+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011841", "id": "18011841", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "body": "Hey [~stevel@apache.org] I was creating the PR on a new branch. Hence closed that PR. I will be creating on a new branch named HADOOP-19536", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ayshukla", "name": "ayshukla", "key": "JIRAUSER310557", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Ayush Shukla", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T10:40:46.819+0000", "updated": "2025-08-04T10:40:46.819+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18011845", "id": "18011845", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#issuecomment-3150184613\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  14m 32s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   9m 46s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  shadedclient  |  45m 16s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  shadedclient  |  34m  4s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  asflicense  |   0m 47s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  96m 42s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.51 ServerAPI=1.51 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7834/2/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7834 |\r\n   | Optional Tests | dupname asflicense |\r\n   | uname | Linux 043bfbb40995 5.15.0-140-generic #150-Ubuntu SMP Sat Apr 12 06:00:09 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / cf4f97def51fa2fd1cca30e67148533a3ad870f5 |\r\n   | Max. process+thread count | 717 (vs. ulimit of 5500) |\r\n   | modules | C:  U:  |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7834/2/console |\r\n   | versions | git=2.25.1 maven=3.6.3 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-04T11:16:22.003+0000", "updated": "2025-08-04T11:16:22.003+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18012182", "id": "18012182", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7834:\nURL: https://github.com/apache/hadoop/pull/7834#issuecomment-3156044267\n\n   oh yes, I remember. I even asked for it. thanks\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-08-05T17:43:28.448+0000", "updated": "2025-08-05T17:43:28.448+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13614928/comment/18012417", "id": "18012417", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "[~ayshukla]\r\n\r\nbq. This class get some original configs. Is there a possibility to set the configs after the initialisation of the class?\r\n\r\ncreateFile() API is a builder API for file creation -add tagging there. With tests, obviously. always the tests, where i expect the same quality as production code, including non-repetition of code\r\n\r\nFor deletion: no equivalent, and changing the semantics of delete() would be so traumatic.\r\n\r\nWhat you could consider proposing is that the s3a bulk delete API is modified so that instead of issuing delete calls it tags the files. The semantics of the API are \"files only, no safety checks and success means files no long exist\" -but maybe that could be tuned to do \"if FS created with fs.s3a.bulk.delete.custom.tags=\"tag=value, t2=v2\"  then instead of deleting, the files are tagged.\r\n\r\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-08-06T17:25:49.209+0000", "updated": "2025-08-06T17:25:49.209+0000"}], "maxResults": 17, "total": 17, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}