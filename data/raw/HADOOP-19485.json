{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13610938", "self": "https://issues.apache.org/jira/rest/api/2/issue/13610938", "key": "HADOOP-19485", "fields": {"summary": "S3A: Upgrade AWS V2 SDK to 2.29.52", "description": "Upgrade to 2.29.52 -the last version compatible with third party stores until there are fixes in the AWS SDK or workarounds added in the S3A connector\r\n\r\nThis SDK update doesn't need to come with some changes to disable some new features (default integrity protections),\r\nand to apply critical changes related to the SDK\r\n\r\nDefault integrity protection came with 2.30, and is on unless disabled.\r\nhttps://github.com/aws/aws-sdk-java-v2/issues/5801\r\n\r\nAs well as being incompatible with third party stores, it has also affected S3 multiregion Access Points: https://github.com/aws/aws-sdk-java-v2/issues/5878\r\n\r\nThis has broken most interaction with third party stores, hence fixes in Iceberg https://github.com/apache/iceberg/pull/12264 and Trinio https://github.com/trinodb/trino/pull/24954\r\n\r\nThere's also [AWS v2.30 SDK InputStream behavior changes #5859](AWS v2.30 SDK InputStream behavior changes).\r\nIt looks like our code is safer from that, but it did require code review.\r\n\r\nSDK 2.30.19 seems good with this\r\n", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933271", "id": "17933271", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #7479:\nURL: https://github.com/apache/hadoop/pull/7479\n\n   \r\n   Upgrade to 2.30.27\r\n   \r\n   \r\n   ### How was this patch tested?\r\n   \r\n   Regression testing in progress\r\n   \r\n   ### For code changes:\r\n   \r\n   - [ ] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T10:53:48.516+0000", "updated": "2025-03-07T10:53:48.516+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933272", "id": "17933272", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2706147948\n\n   testing in progress; also writing a new, expanded and very strict doc on qualifying a release, based on the experience of recent upgrades.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T10:55:44.492+0000", "updated": "2025-03-07T10:55:44.492+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933273", "id": "17933273", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2706148652\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 16s |  |  https://github.com/apache/hadoop/pull/7479 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/1/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T10:56:06.409+0000", "updated": "2025-03-07T10:56:06.409+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933275", "id": "17933275", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2706154284\n\n   Test failures with the 2.30.27\r\n   \r\n   The issue of [HADOOP-19272](https://issues.apache.org/jira/browse/HADOOP-19272) #7048; _S3A: AWS SDK 2.25.53 warnings logged about transfer manager not using CRT client_ has been fixed\r\n   \r\n   ```\r\n   java.lang.AssertionError: \r\n   [LOG output does not contain the forbidden text. Has the SDK been fixed?] \r\n   Expecting:\r\n    <\"\">\r\n   to contain:\r\n    <\"The provided S3AsyncClient is an instance of MultipartS3AsyncClient\"> \r\n           at org.apache.hadoop.fs.s3a.impl.ITestAwsSdkWorkarounds.testNoisyLogging(ITestAwsSdkWorkarounds.java:100)\r\n           at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n           at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n           at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n           at java.lang.reflect.Method.invoke(Method.java:498)\r\n           at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\r\n           at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n           at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\r\n           at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n           at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n           at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n           at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)\r\n           at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)\r\n           at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)\r\n           at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n           at java.lang.Thread.run(Thread.java:750)\r\n   \r\n   ```\r\n   \r\n   this test can be culled\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T10:58:53.933+0000", "updated": "2025-03-07T10:58:53.933+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933276", "id": "17933276", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2706160113\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 16s |  |  https://github.com/apache/hadoop/pull/7479 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/2/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T11:01:43.998+0000", "updated": "2025-03-07T11:01:43.998+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933371", "id": "17933371", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "\r\nfailures in {{ITestS3AEndpointRegion}} appear to be caused by AWS SDK change #5562, which modified the {{AwsExecutionAttribute.ENDPOINT_OVERRIDDEN}} attribute we are making assertions on.\r\n\r\nThis attributed appears to be no longer valid.\r\n\r\nActions\r\n* turn off those asserts\r\n* comment in the aws jira", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-03-07T17:04:47.402+0000", "updated": "2025-03-07T17:04:47.402+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933376", "id": "17933376", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2706982989\n\n   `ITestS3AEndpointRegion` failures are *probably* caused by https://github.com/aws/aws-sdk-java-v2/pull/5562 or a related change. Key: some of the attributes we used to make assertions about are no longer being set.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T17:12:17.804+0000", "updated": "2025-03-07T17:12:17.804+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933397", "id": "17933397", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2707100932\n\n   Testing with third party stores shows the MD-5 thing is there. Also shows that no SDK testing is ever performed against third-party stores, which is something to consider\r\n   ```\r\n          org.apache.hadoop.fs.s3a.AWSBadRequestException: Remove S3 Files on s3a://dellecs/job-00-fork-0003/test/test: software.amazon.awssdk.services.s3.model.InvalidRequestException: Missing required header for this request: Content-MD5 (Service: S3, Status Code: 400, Request ID: 0c07c879:1953935cbee:1a45b:1d85, Extended Request ID: 85e1d41b57b608d4e58222b552dea52902e93b05a12f63f54730ae77769df8d1) (SDK Attempt Count: 1):InvalidRequest: Missing required header for this request: Content-MD5 (Service: S3, Status Code: 400, Request ID: 0c07c879:1953935cbee:1a45b:1d85, Extended Request ID: 85e1d41b57b608d4e58222b552dea52902e93b05a12f63f54730ae77769df8d1) (SDK Attempt Count: 1)\r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T18:16:15.343+0000", "updated": "2025-03-07T18:16:15.343+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933417", "id": "17933417", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2707218849\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 15s |  |  https://github.com/apache/hadoop/pull/7479 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/3/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T19:13:35.081+0000", "updated": "2025-03-07T19:13:35.081+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933428", "id": "17933428", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2707264103\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 17s |  |  https://github.com/apache/hadoop/pull/7479 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/4/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-07T19:40:39.776+0000", "updated": "2025-03-07T19:40:39.776+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933745", "id": "17933745", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r1986733172\n\n\n##########\nhadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/auth/IAMInstanceCredentialsProvider.java:\n##########\n@@ -62,6 +63,12 @@ public class IAMInstanceCredentialsProvider\n   private static final Logger LOG =\n       LoggerFactory.getLogger(IAMInstanceCredentialsProvider.class);\n \n+  /**\n+   * How far in advance of credential expiry must IAM credentials be refreshed.\n+   * See HADOOP-19181. S3A: IAMCredentialsProvider throttling results in AWS auth failures\n+   */\n+  public static final Duration TIME_BEFORE_EXPIRY = Duration.ofMinutes(1);\n\nReview Comment:\n   Is it good to have this configurable ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T07:24:27.505+0000", "updated": "2025-03-10T07:24:27.505+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933747", "id": "17933747", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r1986734552\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEndpointRegion.java:\n##########\n@@ -106,6 +106,10 @@ public class ITestS3AEndpointRegion extends AbstractS3ATestBase {\n \n   public static final String EXCEPTION_THROWN_BY_INTERCEPTOR = \"Exception thrown by interceptor\";\n \n+  /**\n+   * Text to include in asseertions\n\nReview Comment:\n   nit: `assertions`\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T07:25:41.591+0000", "updated": "2025-03-10T07:25:41.591+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933748", "id": "17933748", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "shameersss1 commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2709656232\n\n   @steveloughran  - I can help you test with S3 express storage bucket for this change. Please do let me know once everything is ready\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T07:27:53.915+0000", "updated": "2025-03-10T07:27:53.915+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933841", "id": "17933841", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2710317208\n\n   going to have to go with a 2.29 release; those 2.30 releases brake 3rd party stores and I'm not going to get into the work of trying to fix that before a release. And although the stance of SDK dev team is \r\n   \r\n   > The AWS SDKs and CLI are designed for usage with official AWS services.\r\n   > We may introduce and enable new features by default, such as these new default integrity protections,\r\n   > prior to them being supported or otherwise handled by third-party service implementations.\r\n   \r\n   My stance is: they just broke everything. Unless they want downstream apps to stay on 2.29 for a long time -they need to restore the old behaviour. I've tried to get their recommended workaround in -but it doesn't fix the tests failures.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T11:48:41.271+0000", "updated": "2025-03-10T11:48:41.271+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933967", "id": "17933967", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2711155439\n\n   latest PR updates to 2.29.52; avoids all the new checksum stuff -but also means that IAM throttling fix isn't in either. Pulled that out.\r\n   \r\n   chain now has\r\n   * sdk update\r\n   * test regressions\r\n   * improve sdk logging\r\n   * more tests skipping on non-AWS stores.\r\n   \r\n   That's all.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T16:25:53.345+0000", "updated": "2025-03-10T16:25:53.345+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933973", "id": "17933973", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2711242921\n\n   Output of `TestAWSV2SDK` indicates unshaded classes in bundle.jar including reactivestreams. \r\n   The software/amazon are a false negative; test should be updated\r\n   \r\n   ```\r\n   025-03-10 16:50:46,429 [JUnit-testShadedClasses] WARN  sdk.TestAWSV2SDK (TestAWSV2SDK.java:testShadedClasses(68)) - Unshaded Classes Found :33\r\n   2025-03-10 16:50:46,430 [JUnit-testShadedClasses] WARN  sdk.TestAWSV2SDK (TestAWSV2SDK.java:testShadedClasses(69)) - List of unshaded classes:[org/reactivestreams/FlowAdapters$FlowPublisherFromReactive.class, org/reactivestreams/FlowAdapters$FlowToReactiveProcessor.class, org/reactivestreams/FlowAdapters$FlowToReactiveSubscriber.class, org/reactivestreams/FlowAdapters$FlowToReactiveSubscription.class, org/reactivestreams/FlowAdapters$ReactivePublisherFromFlow.class, org/reactivestreams/FlowAdapters$ReactiveToFlowProcessor.class, org/reactivestreams/FlowAdapters$ReactiveToFlowSubscriber.class, org/reactivestreams/FlowAdapters$ReactiveToFlowSubscription.class, org/reactivestreams/FlowAdapters.class, org/reactivestreams/Processor.class, org/reactivestreams/Publisher.class, org/reactivestreams/Subscriber.class, org/reactivestreams/Subscription.class, software/amazon/eventstream/Checksums.class, software/amazon/eventstream/HeaderValue$IntegerValue.class, software/amazon/eventstream/HeaderValue$BooleanValue.class, software/amazon/eventstream/MessageDecoder.class, software/amazon/eventstream/HeaderValue$ByteValue.class, software/amazon/eventstream/Header.class, software/amazon/eventstream/HeaderValue$1.class, software/amazon/eventstream/HeaderType.class, software/amazon/eventstream/HeaderValue$TimestampValue.class, software/amazon/eventstream/HeaderValue$LongValue.class, software/amazon/eventstream/Utils.class, software/amazon/eventstream/HeaderValue$ShortValue.class, software/amazon/eventstream/MessageBuilder.class, software/amazon/eventstream/HeaderValue$StringValue.class, software/amazon/eventstream/HeaderValue$ByteArrayValue.class, software/amazon/eventstream/Prelude.class, software/amazon/eventstream/HeaderValue.class, software/amazon/eventstream/HeaderValue$UuidValue.class, software/amazon/eventstream/Message.class, META-INF/versions/9/module-info.class]\r\n   ```\r\n   \r\n   looking at the output of a branch-3.4 release they are not new; this not a regression,\r\n   just unwelcome (and how did this get in?)\r\n   ```\r\n   2025-03-10 16:54:11,588 [JUnit-testShadedClasses] WARN  sdk.TestAWSV2SDK (TestAWSV2SDK.java:testShadedClasses(68)) - Unshaded Classes Found :32\r\n   2025-03-10 16:54:11,588 [JUnit-testShadedClasses] WARN  sdk.TestAWSV2SDK (TestAWSV2SDK.java:testShadedClasses(69)) - List of unshaded classes:[org/reactivestreams/FlowAdapters$FlowPublisherFromReactive.class, org/reactivestreams/FlowAdapters$FlowToReactiveProcessor.class, org/reactivestreams/FlowAdapters$FlowToReactiveSubscriber.class, org/reactivestreams/FlowAdapters$FlowToReactiveSubscription.class, org/reactivestreams/FlowAdapters$ReactivePublisherFromFlow.class, org/reactivestreams/FlowAdapters$ReactiveToFlowProcessor.class, org/reactivestreams/FlowAdapters$ReactiveToFlowSubscriber.class, org/reactivestreams/FlowAdapters$ReactiveToFlowSubscription.class, org/reactivestreams/FlowAdapters.class, org/reactivestreams/Processor.class, org/reactivestreams/Publisher.class, org/reactivestreams/Subscriber.class, org/reactivestreams/Subscription.class, software/amazon/eventstream/Checksums.class, software/amazon/eventstream/HeaderValue$IntegerValue.class, software/amazon/eventstream/HeaderValue$BooleanValue.class, software/amazon/eventstream/MessageDecoder.class, software/amazon/eventstream/HeaderValue$ByteValue.class, software/amazon/eventstream/Header.class, software/amazon/eventstream/HeaderValue$1.class, software/amazon/eventstream/HeaderType.class, software/amazon/eventstream/HeaderValue$TimestampValue.class, software/amazon/eventstream/HeaderValue$LongValue.class, software/amazon/eventstream/Utils.class, software/amazon/eventstream/HeaderValue$ShortValue.class, software/amazon/eventstream/MessageBuilder.class, software/amazon/eventstream/HeaderValue$StringValue.class, software/amazon/eventstream/HeaderValue$ByteArrayValue.class, software/amazon/eventstream/Prelude.class, software/amazon/eventstream/HeaderValue.class, software/amazon/eventstream/HeaderValue$UuidValue.class, software/amazon/eventstream/Message.class]\r\n   ```\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T16:56:08.935+0000", "updated": "2025-03-10T16:56:08.935+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933988", "id": "17933988", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2711397748\n\n   @shameersss1 would love that s3-express stuff, and any manual testing you can do.\r\n   \r\n   The ILoad* tests against that and s3standard from within aws infra would be good too -I'm now suspecting the SDK doesn't escalate a 503 from within a bulk delete response into a 503 for the whole request -so nothing is retrying it. \r\n   \r\n   Here's my WiP design of a new test process, and yes it is strict and time consuming. \r\n   \r\n   https://github.com/steveloughran/engineering-proposals/blob/trunk/qualifying-an-SDK-upgrade.md\r\n   \r\n   I already think it's too many buckets to be realistically tested -but we do need that mix.\r\n   \r\n   Please do as much as you can. And I'll add \"seek help!\" to the doc -not just to save time but to ensure even broader test setups.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-10T17:56:36.724+0000", "updated": "2025-03-10T17:56:36.724+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17933990", "id": "17933990", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "body": "I've just stuck a draft up of a new qualification doc, there's enough surfacing with this release that's evolving quite rapidly", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevel%40apache.org", "name": "stevel@apache.org", "key": "stevel@apache.org", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=stevel%40apache.org&avatarId=16513", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=stevel%40apache.org&avatarId=16513", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=stevel%40apache.org&avatarId=16513", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=stevel%40apache.org&avatarId=16513"}, "displayName": "Steve Loughran", "active": true, "timeZone": "Europe/London"}, "created": "2025-03-10T17:58:20.338+0000", "updated": "2025-03-10T17:58:20.338+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17934208", "id": "17934208", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2714129305\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m  0s |  |  Docker mode activated.  |\r\n   | -1 :x: |  patch  |   0m 17s |  |  https://github.com/apache/hadoop/pull/7479 does not apply to trunk. Rebase required? Wrong Branch? See https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute for help.  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/5/console |\r\n   | versions | git=2.34.1 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-11T12:59:53.968+0000", "updated": "2025-03-11T12:59:53.968+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17934658", "id": "17934658", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2719140801\n\n   Will need to re-base.\n   \n   Note that when I merge this, I will split it into three patches \n   -SDK update\n   -sdk internals logging\n   -code changes -most of which are test tuning, especially skipping more tests on third party stores. Guess what I've been doing \ud83d\ude00\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-12T21:11:21.544+0000", "updated": "2025-03-12T21:11:21.544+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938107", "id": "17938107", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2750126766\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 22s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   6m 15s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 18s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m  4s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 16s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 53s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 44s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  36m 57s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 41s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  17m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 55s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   7m 55s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 13s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   7m 13s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/artifact/out/blanks-eol.txt) |  The patch has 1 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 53s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 9 new + 12 unchanged - 1 fixed = 21 total (was 13)  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 14s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 59s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  hadoop-project has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 48s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) |  hadoop-tools/hadoop-aws generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | -1 :x: |  spotbugs  |  17m 43s | [/new-spotbugs-root.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/artifact/out/new-spotbugs-root.html) |  root generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 55s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 487m 49s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  0s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 688m 49s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-aws |\r\n   |  |  Return value of AwsSdkWorkarounds.prepareLogging() ignored, but method has no side effect  At ClientManagerImpl.java:but method has no side effect  At ClientManagerImpl.java:[line 126] |\r\n   | SpotBugs | module:root |\r\n   |  |  Return value of AwsSdkWorkarounds.prepareLogging() ignored, but method has no side effect  At ClientManagerImpl.java:but method has no side effect  At ClientManagerImpl.java:[line 126] |\r\n   | Failed junit tests | hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints |\r\n   |   | hadoop.yarn.client.api.impl.TestNMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMProxy |\r\n   |   | hadoop.yarn.client.api.impl.TestYarnClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 00feaf71057c 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 12dc3b341ef762f8070193a19aa127f176711570 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/testReport/ |\r\n   | Max. process+thread count | 3719 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-25T05:25:26.905+0000", "updated": "2025-03-25T05:25:26.905+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938360", "id": "17938360", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2752588086\n\n   FYI all good with the 2.29 upgrade against aws and 2 external stores; https://issues.apache.org/jira/browse/HADOOP-19512 highlights issues -but those all seem unrelated.\r\n   \r\n   The main bit remaining is dependency audit.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-25T21:28:01.269+0000", "updated": "2025-03-25T21:28:01.269+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938506", "id": "17938506", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2753673994\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 18s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   6m 21s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m 25s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 17s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 16s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  13m 53s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 19s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 57s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 26s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  36m 40s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 39s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  17m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  0s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m  8s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   7m  8s |  |  the patch passed  |\r\n   | -1 :x: |  blanks  |   0m  0s | [/blanks-eol.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/artifact/out/blanks-eol.txt) |  The patch has 3 line(s) that end in blanks. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply  |\r\n   | -0 :warning: |  checkstyle  |   1m 57s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 9 new + 12 unchanged - 1 fixed = 21 total (was 13)  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  1s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 49s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 55s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  hadoop-project has no data from spotbugs  |\r\n   | -1 :x: |  spotbugs  |   0m 53s | [/new-spotbugs-hadoop-tools_hadoop-aws.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/artifact/out/new-spotbugs-hadoop-tools_hadoop-aws.html) |  hadoop-tools/hadoop-aws generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | -1 :x: |  spotbugs  |  17m 37s | [/new-spotbugs-root.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/artifact/out/new-spotbugs-root.html) |  root generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 20s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 487m 19s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  0s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 700m 22s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-aws |\r\n   |  |  Return value of AwsSdkWorkarounds.prepareLogging() ignored, but method has no side effect  At ClientManagerImpl.java:but method has no side effect  At ClientManagerImpl.java:[line 126] |\r\n   | SpotBugs | module:root |\r\n   |  |  Return value of AwsSdkWorkarounds.prepareLogging() ignored, but method has no side effect  At ClientManagerImpl.java:but method has no side effect  At ClientManagerImpl.java:[line 126] |\r\n   | Failed junit tests | hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints |\r\n   |   | hadoop.yarn.client.api.impl.TestNMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMProxy |\r\n   |   | hadoop.yarn.client.api.impl.TestYarnClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 954bebe9706c 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / f376a12f18172e5f89b21b7e0400e577641a3b52 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/testReport/ |\r\n   | Max. process+thread count | 3643 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T09:07:27.977+0000", "updated": "2025-03-26T09:07:27.977+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938661", "id": "17938661", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2755095840\n\n   dependencies are good\r\n   ```\r\n   [INFO] +- org.apache.hadoop:hadoop-aws:jar:3.5.0-SNAPSHOT:compile\r\n   [INFO] |  +- software.amazon.awssdk:bundle:jar:2.29.52:compile\r\n   [INFO] |  +- software.amazon.s3.analyticsaccelerator:analyticsaccelerator-s3:jar:1.0.0:compile\r\n   [INFO] |  \\- org.wildfly.openssl:wildfly-openssl:jar:2.1.4.Final:compile\r\n   ```\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T16:54:45.093+0000", "updated": "2025-03-26T16:54:45.093+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938724", "id": "17938724", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2755658666\n\n   Current status\r\n   \r\n   CLI tests happy with\r\n   * s3 standard\r\n   * gcs\r\n   * s3 express (with log changes related to HADOOP-19516)\r\n   * Dell ECS\r\n   \r\n   ITests\r\n   * all good with S3 standard after (HADOOP-19485. S3A: Test failures after SDK upgrade )\r\n   * some failures/flakiness with the third party stores. _HADOOP-19492. S3A: some tests failing on third-party stores_ addresses much of this\r\n   \r\n   Main ITest pain point is S3 Express\r\n   * failures related to role generated for restricted access. Assumption: not creating the S3Express permissions, so unrelated.\r\n   * ITestConnectionTimeouts\r\n   I don't think that stuff should be a blocker, as it is more test failures surfacing which were previously not run\r\n   \r\n   IMO This chain is ready to go!\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T20:19:36.475+0000", "updated": "2025-03-26T20:19:36.475+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938744", "id": "17938744", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r2014947803\n\n\n##########\nhadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java:\n##########\n@@ -211,12 +213,20 @@ private <BuilderT extends S3BaseClientBuilder<BuilderT, ClientT>, ClientT> Build\n     final ClientOverrideConfiguration.Builder override =\n         createClientOverrideConfiguration(parameters, conf);\n \n-    S3BaseClientBuilder s3BaseClientBuilder = builder\n+    S3BaseClientBuilder<BuilderT, ClientT> s3BaseClientBuilder = builder\n         .overrideConfiguration(override.build())\n         .credentialsProvider(parameters.getCredentialSet())\n         .disableS3ExpressSessionAuth(!parameters.isExpressCreateSession())\n         .serviceConfiguration(serviceConfiguration);\n \n+    if (LOG.isTraceEnabled()) {\n+      // if this log is set to debug then we turn on logging of SDK metrics.\n\nReview Comment:\n   Is this meant to say \"...set to trace..\"? The if statement is looking for trace.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T20:27:35.120+0000", "updated": "2025-03-26T20:27:35.120+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17938836", "id": "17938836", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2757036070\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 21s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   6m 15s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 12s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m  7s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 55s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  13m 58s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 25s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 54s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 56s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  17m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  2s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  2s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 15s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   7m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   1m 54s | [/results-checkstyle-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/8/artifact/out/results-checkstyle-root.txt) |  root: The patch generated 2 new + 12 unchanged - 1 fixed = 14 total (was 13)  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m  8s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 56s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  37m  7s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 488m 54s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/8/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 59s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 693m 21s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints |\r\n   |   | hadoop.yarn.client.api.impl.TestNMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMProxy |\r\n   |   | hadoop.yarn.client.api.impl.TestYarnClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 5ed05bda1f40 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3ca156e787bdc5ef998970e673836742f024238a |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/8/testReport/ |\r\n   | Max. process+thread count | 3496 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-27T07:46:11.540+0000", "updated": "2025-03-27T07:46:11.540+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17939035", "id": "17939035", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r2017316254\n\n\n##########\nhadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java:\n##########\n@@ -211,12 +213,20 @@ private <BuilderT extends S3BaseClientBuilder<BuilderT, ClientT>, ClientT> Build\n     final ClientOverrideConfiguration.Builder override =\n         createClientOverrideConfiguration(parameters, conf);\n \n-    S3BaseClientBuilder s3BaseClientBuilder = builder\n+    S3BaseClientBuilder<BuilderT, ClientT> s3BaseClientBuilder = builder\n         .overrideConfiguration(override.build())\n         .credentialsProvider(parameters.getCredentialSet())\n         .disableS3ExpressSessionAuth(!parameters.isExpressCreateSession())\n         .serviceConfiguration(serviceConfiguration);\n \n+    if (LOG.isTraceEnabled()) {\n+      // if this log is set to debug then we turn on logging of SDK metrics.\n\nReview Comment:\n   good catch. let me change the doc; I tried with debug first but it was waay too noisy\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-27T17:56:23.010+0000", "updated": "2025-03-27T17:56:23.010+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17939045", "id": "17939045", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r2017380125\n\n\n##########\nhadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java:\n##########\n@@ -211,12 +213,20 @@ private <BuilderT extends S3BaseClientBuilder<BuilderT, ClientT>, ClientT> Build\n     final ClientOverrideConfiguration.Builder override =\n         createClientOverrideConfiguration(parameters, conf);\n \n-    S3BaseClientBuilder s3BaseClientBuilder = builder\n+    S3BaseClientBuilder<BuilderT, ClientT> s3BaseClientBuilder = builder\n         .overrideConfiguration(override.build())\n         .credentialsProvider(parameters.getCredentialSet())\n         .disableS3ExpressSessionAuth(!parameters.isExpressCreateSession())\n         .serviceConfiguration(serviceConfiguration);\n \n+    if (LOG.isTraceEnabled()) {\n+      // if this log is set to debug then we turn on logging of SDK metrics.\n\nReview Comment:\n   chris; fixed this..pushed up a whole new pr as I have the chain of patches to merge independently...I've added this and the yetus complaints to the relevant commits\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-27T18:15:38.466+0000", "updated": "2025-03-27T18:15:38.466+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17939141", "id": "17939141", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2760332614\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   5m 58s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m 51s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 14s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 16s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   2m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  13m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 22s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 58s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 40s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 33s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  17m 50s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  1s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m  7s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   7m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 55s |  |  root: The patch generated 0 new + 12 unchanged - 1 fixed = 12 total (was 13)  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 17s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  2s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 12s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 15s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 518m 12s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/9/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  2s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 722m 36s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints |\r\n   |   | hadoop.yarn.client.api.impl.TestNMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMProxy |\r\n   |   | hadoop.yarn.client.api.impl.TestYarnClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 08814370e83e 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 26bca7c3c0fa782eb468244b9ea55a7de06d6155 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/9/testReport/ |\r\n   | Max. process+thread count | 3598 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/9/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-28T06:17:55.201+0000", "updated": "2025-03-28T06:17:55.201+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17939194", "id": "17939194", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2760789671\n\n   yarn is in the process of upgrading tests to junit 5; consider these failures unrelated\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-28T10:01:14.780+0000", "updated": "2025-03-28T10:01:14.780+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17939736", "id": "17939736", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "cnauroth commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r2021301416\n\n\n##########\nhadoop-tools/hadoop-aws/src/test/resources/log4j.properties:\n##########\n@@ -102,3 +102,6 @@ log4j.logger.org.apache.hadoop.fs.s3a.S3AStorageStatistics=INFO\n # services it launches itself.\n # log4.logger.org.apache.hadoop.service=DEBUG\n \n+# log this at trace to trigger enabling the\n\nReview Comment:\n   Is there more text intended here? e.g. \"...enabling the AWS SDK metrics logging.\"\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-31T15:50:02.020+0000", "updated": "2025-03-31T15:50:02.020+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940115", "id": "17940115", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r2023091772\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/troubleshooting_s3a.md:\n##########\n@@ -1359,6 +1359,48 @@ execchain.MainClientExec (MainClientExec.java:execute(284)) - Connection can be\n \n ```\n \n+\n+To log the output of the AWS SDK metrics, set the log\n+`org.apache.hadoop.fs.s3a.DefaultS3ClientFactory` to `TRACE`.\n+This will then turn on logging of the internal SDK metrics.4\n+\n+These will actually be logged at INFO in the log\n+```\n+software.amazon.awssdk.metrics.LoggingMetricPublisher\n+```\n+\n+```text\n+INFO  metrics.LoggingMetricPublisher (LoggerAdapter.java:info(165)) - Metrics published:\n\nReview Comment:\n   qq: is this logged on every request, or at some fixed interval?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-01T15:24:32.041+0000", "updated": "2025-04-01T15:24:32.041+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940233", "id": "17940233", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2771243683\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m  4s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   5m 53s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m 29s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 20s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 12s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   2m  0s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  14m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 21s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 57s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 43s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 42s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m  5s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  0s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  0s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 19s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   7m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 52s |  |  root: The patch generated 0 new + 12 unchanged - 1 fixed = 12 total (was 13)  |\r\n   | +1 :green_heart: |  mvnsite  |  11m 56s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 27s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 56s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 13s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 519m 47s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/10/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 58s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 732m 52s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints |\r\n   |   | hadoop.yarn.client.api.impl.TestNMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMProxy |\r\n   |   | hadoop.yarn.client.api.impl.TestYarnClient |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/10/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 81b09fec382e 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 1664b949e110657c170395a923fdcedf0602502a |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/10/testReport/ |\r\n   | Max. process+thread count | 3700 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/10/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T03:20:40.895+0000", "updated": "2025-04-02T03:20:40.895+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940386", "id": "17940386", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on code in PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#discussion_r2025056763\n\n\n##########\nhadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/troubleshooting_s3a.md:\n##########\n@@ -1359,6 +1359,48 @@ execchain.MainClientExec (MainClientExec.java:execute(284)) - Connection can be\n \n ```\n \n+\n+To log the output of the AWS SDK metrics, set the log\n+`org.apache.hadoop.fs.s3a.DefaultS3ClientFactory` to `TRACE`.\n+This will then turn on logging of the internal SDK metrics.4\n+\n+These will actually be logged at INFO in the log\n+```\n+software.amazon.awssdk.metrics.LoggingMetricPublisher\n+```\n+\n+```text\n+INFO  metrics.LoggingMetricPublisher (LoggerAdapter.java:info(165)) - Metrics published:\n\nReview Comment:\n   oh, it's noisy. It's the ultimate way to see what is happening in the SDK. I'd been meaning to do this for a while, but trying to see what the 2.30 SDK was up to motivated me.\r\n   \r\n   It is very much emergency use only -those situations where you turn on all of the http traffic logging. But it is now avaiable for those emergencies\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T15:15:05.264+0000", "updated": "2025-04-02T15:15:05.264+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940387", "id": "17940387", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2772919077\n\n   thanks for approval, I will manually merge in very carefully \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T15:15:45.418+0000", "updated": "2025-04-02T15:15:45.418+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940390", "id": "17940390", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2772929843\n\n   thanks @steveloughran , once this is in could you also give the CRT PR another look. Can cut the 3.4.2 branch by the end of the week hopefully, once these are in. What did you decide about conditional writes: https://github.com/apache/hadoop/pull/7011 , do we want to wait for that?\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T15:19:07.694+0000", "updated": "2025-04-02T15:19:07.694+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940396", "id": "17940396", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran closed pull request #7479: HADOOP-19485. S3A: upgrade AWS SDK to 2.29.52\nURL: https://github.com/apache/hadoop/pull/7479\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T15:34:48.231+0000", "updated": "2025-04-02T15:34:48.231+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940397", "id": "17940397", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2772978075\n\n   manually merged\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T15:35:03.364+0000", "updated": "2025-04-02T15:35:03.364+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940415", "id": "17940415", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran opened a new pull request, #7573:\nURL: https://github.com/apache/hadoop/pull/7573\n\n   \r\n   ### Description of PR\r\n   \r\n   HADOOP-19485. S3A: Upgrade AWS V2 SDK to 2.29.52\r\n   HADOOP-19485. S3A: Test failures after SDK upgrade \r\n   HADOOP-19455. S3A: SDK client to log metrics at TRACE\r\n   HADOOP-19492. S3A: Some tests failing on third-party stores\r\n   HADOOP-19516. S3A: SDK reads content twice during PUT to S3 Express store.\r\n   \r\n   ### How was this patch tested?\r\n   \r\n   s3 london\r\n   \r\n   ### For code changes:\r\n   \r\n   - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n   - [X] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?\r\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n   - [X] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T17:31:23.399+0000", "updated": "2025-04-02T17:31:23.399+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940416", "id": "17940416", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7573:\nURL: https://github.com/apache/hadoop/pull/7573#issuecomment-2773266165\n\n   one failure I'm getting on the tests (other than the known v4 signing regression) is that the vector IO tests are failing 412 \"not satisfied\". \r\n   \r\n   going to rebuild without the library update to see if the issue exists there too.\r\n   \r\n   ```\r\n   [ERROR] testVectoredReadAfterNormalRead[Buffer type : direct](org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead)  Time elapsed: 3.967 s  <<< ERROR!\r\n   java.io.IOException: Cannot read block file\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.data.Block.getDataWithRetries(Block.java:239)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.data.Block.read(Block.java:187)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.data.Blob.read(Blob.java:112)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.impl.PhysicalIOImpl.lambda$read$3(PhysicalIOImpl.java:162)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.DefaultTelemetry.measure(DefaultTelemetry.java:102)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.Telemetry.measureVerbose(Telemetry.java:243)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.impl.PhysicalIOImpl.read(PhysicalIOImpl.java:151)\r\n           at software.amazon.s3.analyticsaccelerator.io.logical.impl.DefaultLogicalIOImpl.lambda$read$1(DefaultLogicalIOImpl.java:92)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.DefaultTelemetry.measureConditionally(DefaultTelemetry.java:141)\r\n           at software.amazon.s3.analyticsaccelerator.io.logical.impl.DefaultLogicalIOImpl.read(DefaultLogicalIOImpl.java:81)\r\n           at software.amazon.s3.analyticsaccelerator.S3SeekableInputStream.lambda$read$3(S3SeekableInputStream.java:155)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.DefaultTelemetry.measure(DefaultTelemetry.java:102)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.Telemetry.measureVerbose(Telemetry.java:243)\r\n           at software.amazon.s3.analyticsaccelerator.S3SeekableInputStream.read(S3SeekableInputStream.java:145)\r\n           at org.apache.hadoop.fs.s3a.impl.streams.AnalyticsStream.read(AnalyticsStream.java:123)\r\n           at java.io.DataInputStream.readFully(DataInputStream.java:195)\r\n           at org.apache.hadoop.fs.contract.AbstractContractVectoredReadTest.testVectoredReadAfterNormalRead(AbstractContractVectoredReadTest.java:490)\r\n           at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n           at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n           at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n           at java.lang.reflect.Method.invoke(Method.java:498)\r\n           at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\r\n           at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n           at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\r\n           at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n           at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n           at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n           at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)\r\n           at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)\r\n           at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)\r\n           at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n           at java.lang.Thread.run(Thread.java:750)\r\n   Caused by: software.amazon.awssdk.services.s3.model.S3Exception: At least one of the pre-conditions you specified did not hold (Service: S3, Status Code: 412, Request ID: JPZ41WS486WJK5JB, Extended Request ID: M9cC1AT7UK5wKNwQzvq6hYMBvY/syM3cTF2L6sCsnkasjNBLCCBOcYLRdyeqKXdhZyab1rXsagHm7R8rUqi/+hU4FAGXHlxj)\r\n           at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:104)\r\n           at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:58)\r\n           at software.amazon.awssdk.protocols.query.internal.unmarshall.AwsXmlErrorUnmarshaller.unmarshall(AwsXmlErrorUnmarshaller.java:98)\r\n           at software.amazon.awssdk.protocols.query.unmarshall.AwsXmlErrorProtocolUnmarshaller.handle(AwsXmlErrorProtocolUnmarshaller.java:102)\r\n           at software.amazon.awssdk.protocols.query.unmarshall.AwsXmlErrorProtocolUnmarshaller.handle(AwsXmlErrorProtocolUnmarshaller.java:82)\r\n           at software.amazon.awssdk.core.http.MetricCollectingHttpResponseHandler.lambda$handle$0(MetricCollectingHttpResponseHandler.java:52)\r\n           at software.amazon.awssdk.core.internal.util.MetricUtils.measureDurationUnsafe(MetricUtils.java:102)\r\n           at software.amazon.awssdk.core.internal.util.MetricUtils.measureDurationUnsafe(MetricUtils.java:95)\r\n           at software.amazon.awssdk.core.http.MetricCollectingHttpResponseHandler.handle(MetricCollectingHttpResponseHandler.java:52)\r\n           at software.amazon.awssdk.core.internal.http.async.AsyncResponseHandler.lambda$prepare$0(AsyncResponseHandler.java:92)\r\n           at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:966)\r\n           at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:940)\r\n           at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n           at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\r\n           at software.amazon.awssdk.core.internal.http.async.AsyncResponseHandler$BaosSubscriber.onComplete(AsyncResponseHandler.java:135)\r\n           at software.amazon.awssdk.core.internal.metrics.BytesReadTrackingPublisher$BytesReadTracker.onComplete(BytesReadTrackingPublisher.java:74)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler$DataCountingPublisher$1.onComplete(ResponseHandler.java:519)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.runAndLogError(ResponseHandler.java:254)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.access$600(ResponseHandler.java:77)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler$PublisherAdapter$1.onComplete(ResponseHandler.java:375)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher.publishMessage(HandlerPublisher.java:402)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher.flushBuffer(HandlerPublisher.java:338)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher.receivedDemand(HandlerPublisher.java:291)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher.access$200(HandlerPublisher.java:61)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher$ChannelSubscription$1.run(HandlerPublisher.java:495)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:566)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n           ... 1 more\r\n   \r\n   [ERROR] testVectoredReadAfterNormalRead[Buffer type : array](org.apache.hadoop.fs.contract.s3a.ITestS3AContractAnalyticsStreamVectoredRead)  Time elapsed: 5.592 s  <<< ERROR!\r\n   java.io.IOException: Cannot read block file\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.data.Block.getDataWithRetries(Block.java:239)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.data.Block.read(Block.java:187)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.data.Blob.read(Blob.java:112)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.impl.PhysicalIOImpl.lambda$read$3(PhysicalIOImpl.java:162)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.DefaultTelemetry.measure(DefaultTelemetry.java:102)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.Telemetry.measureVerbose(Telemetry.java:243)\r\n           at software.amazon.s3.analyticsaccelerator.io.physical.impl.PhysicalIOImpl.read(PhysicalIOImpl.java:151)\r\n           at software.amazon.s3.analyticsaccelerator.io.logical.impl.DefaultLogicalIOImpl.lambda$read$1(DefaultLogicalIOImpl.java:92)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.DefaultTelemetry.measureConditionally(DefaultTelemetry.java:141)\r\n           at software.amazon.s3.analyticsaccelerator.io.logical.impl.DefaultLogicalIOImpl.read(DefaultLogicalIOImpl.java:81)\r\n           at software.amazon.s3.analyticsaccelerator.S3SeekableInputStream.lambda$read$3(S3SeekableInputStream.java:155)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.DefaultTelemetry.measure(DefaultTelemetry.java:102)\r\n           at software.amazon.s3.analyticsaccelerator.common.telemetry.Telemetry.measureVerbose(Telemetry.java:243)\r\n           at software.amazon.s3.analyticsaccelerator.S3SeekableInputStream.read(S3SeekableInputStream.java:145)\r\n           at org.apache.hadoop.fs.s3a.impl.streams.AnalyticsStream.read(AnalyticsStream.java:123)\r\n           at java.io.DataInputStream.readFully(DataInputStream.java:195)\r\n           at org.apache.hadoop.fs.contract.AbstractContractVectoredReadTest.testVectoredReadAfterNormalRead(AbstractContractVectoredReadTest.java:490)\r\n           at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n           at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n           at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n           at java.lang.reflect.Method.invoke(Method.java:498)\r\n           at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\r\n           at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n           at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\r\n           at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n           at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n           at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n           at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)\r\n           at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)\r\n           at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)\r\n           at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n           at java.lang.Thread.run(Thread.java:750)\r\n   Caused by: software.amazon.awssdk.services.s3.model.S3Exception: At least one of the pre-conditions you specified did not hold (Service: S3, Status Code: 412, Request ID: 9YKDJ797E6XNRPY1, Extended Request ID: XatMA7lK+Ww1G1oyMoYRZOf2kSta5/+wkzHW7HXbAJu227n4vPx6RaJmFltbGg6p96hKSy5WnX/e2XgX9x0L/5YE8XGHAHyA)\r\n           at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:104)\r\n           at software.amazon.awssdk.services.s3.model.S3Exception$BuilderImpl.build(S3Exception.java:58)\r\n           at software.amazon.awssdk.protocols.query.internal.unmarshall.AwsXmlErrorUnmarshaller.unmarshall(AwsXmlErrorUnmarshaller.java:98)\r\n           at software.amazon.awssdk.protocols.query.unmarshall.AwsXmlErrorProtocolUnmarshaller.handle(AwsXmlErrorProtocolUnmarshaller.java:102)\r\n           at software.amazon.awssdk.protocols.query.unmarshall.AwsXmlErrorProtocolUnmarshaller.handle(AwsXmlErrorProtocolUnmarshaller.java:82)\r\n           at software.amazon.awssdk.core.http.MetricCollectingHttpResponseHandler.lambda$handle$0(MetricCollectingHttpResponseHandler.java:52)\r\n           at software.amazon.awssdk.core.internal.util.MetricUtils.measureDurationUnsafe(MetricUtils.java:102)\r\n           at software.amazon.awssdk.core.internal.util.MetricUtils.measureDurationUnsafe(MetricUtils.java:95)\r\n           at software.amazon.awssdk.core.http.MetricCollectingHttpResponseHandler.handle(MetricCollectingHttpResponseHandler.java:52)\r\n           at software.amazon.awssdk.core.internal.http.async.AsyncResponseHandler.lambda$prepare$0(AsyncResponseHandler.java:92)\r\n           at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:966)\r\n           at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:940)\r\n           at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\r\n           at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\r\n           at software.amazon.awssdk.core.internal.http.async.AsyncResponseHandler$BaosSubscriber.onComplete(AsyncResponseHandler.java:135)\r\n           at software.amazon.awssdk.core.internal.metrics.BytesReadTrackingPublisher$BytesReadTracker.onComplete(BytesReadTrackingPublisher.java:74)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler$DataCountingPublisher$1.onComplete(ResponseHandler.java:519)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.runAndLogError(ResponseHandler.java:254)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler.access$600(ResponseHandler.java:77)\r\n           at software.amazon.awssdk.http.nio.netty.internal.ResponseHandler$PublisherAdapter$1.onComplete(ResponseHandler.java:375)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher.complete(HandlerPublisher.java:447)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HandlerPublisher.handlerRemoved(HandlerPublisher.java:435)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.callHandlerRemoved(AbstractChannelHandlerContext.java:1138)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.DefaultChannelPipeline.callHandlerRemoved0(DefaultChannelPipeline.java:586)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.DefaultChannelPipeline.remove(DefaultChannelPipeline.java:426)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.DefaultChannelPipeline.remove(DefaultChannelPipeline.java:372)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HttpStreamsHandler.removeHandlerIfActive(HttpStreamsHandler.java:370)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HttpStreamsHandler.handleReadHttpContent(HttpStreamsHandler.java:232)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HttpStreamsHandler.channelRead(HttpStreamsHandler.java:203)\r\n           at software.amazon.awssdk.http.nio.netty.internal.nrs.HttpStreamsClientHandler.channelRead(HttpStreamsClientHandler.java:173)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.logging.LoggingHandler.channelRead(LoggingHandler.java:280)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1503)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1366)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1415)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:530)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:469)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n           at software.amazon.awssdk.thirdparty.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:289)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\r\n           at software.amazon.awssdk.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\r\n           at software.amazon.awssdk.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n           ... 1 more\r\n   \r\n   ```\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T17:35:13.885+0000", "updated": "2025-04-02T17:35:13.885+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940420", "id": "17940420", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2773308374\n\n   @ahmarsuhail will look at the CRT, but still getting this chain backported.\r\n   \r\n   All good except for HADOOP-19527 -which now seems to happen everywhere.\r\n   \r\n   w.r.t conditional -plan for end of week.\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-02T17:55:22.592+0000", "updated": "2025-04-02T17:55:22.592+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940520", "id": "17940520", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7479:\nURL: https://github.com/apache/hadoop/pull/7479#issuecomment-2774368388\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 19s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  1s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  1s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   6m  6s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  18m 35s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   8m 15s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   7m 15s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 57s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |  12m 21s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   5m 34s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   5m  4s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 15s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 18s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 36s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  17m 43s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   8m  3s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   8m  3s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   7m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   7m 25s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   1m 53s |  |  root: The patch generated 0 new + 12 unchanged - 1 fixed = 12 total (was 13)  |\r\n   | +1 :green_heart: |  mvnsite  |  12m  1s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   5m 16s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   4m 58s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 14s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  36m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | -1 :x: |  unit  | 520m 16s | [/patch-unit-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/11/artifact/out/patch-unit-root.txt) |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m  1s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 724m 33s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | Failed junit tests | hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints |\r\n   |   | hadoop.yarn.client.api.impl.TestNMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n   |   | hadoop.yarn.client.api.impl.TestAMRMProxy |\r\n   |   | hadoop.yarn.client.api.impl.TestYarnClient |\r\n   |   | hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/11/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7479 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux f6a0118c7a09 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / aebf99e772c6a27820f011a0a742eadfee12b617 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/11/testReport/ |\r\n   | Max. process+thread count | 3767 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7479/11/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-03T03:24:29.118+0000", "updated": "2025-04-03T03:24:29.118+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17940659", "id": "17940659", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7573:\nURL: https://github.com/apache/hadoop/pull/7573#issuecomment-2775467874\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  11m 42s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +0 :ok: |  markdownlint  |   0m  0s |  |  markdownlint was not available.  |\r\n   | +0 :ok: |  shelldocs  |   0m  0s |  |  Shelldocs was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 8 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   1m 59s |  |  Maven dependency ordering for branch  |\r\n   | +1 :green_heart: |  mvninstall  |  33m 22s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |  16m 33s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |  14m 55s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   4m  6s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |  17m 15s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   8m 18s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 25s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 20s |  |  branch/hadoop-project no spotbugs output file (spotbugsXml.xml)  |\r\n   | -1 :x: |  spotbugs  |  29m 44s | [/branch-spotbugs-root-warnings.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7573/1/artifact/out/branch-spotbugs-root-warnings.html) |  root in branch-3.4 has 1 extant spotbugs warnings.  |\r\n   | +1 :green_heart: |  shadedclient  |  34m 49s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +0 :ok: |  mvndep  |   0m 57s |  |  Maven dependency ordering for patch  |\r\n   | +1 :green_heart: |  mvninstall  |  30m 38s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 52s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |  15m 52s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |  15m 10s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |  15m 10s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   4m  7s |  |  root: The patch generated 0 new + 11 unchanged - 1 fixed = 11 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |  17m 47s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shellcheck  |   0m  0s |  |  No new issues.  |\r\n   | +1 :green_heart: |  javadoc  |   8m  8s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   7m 23s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +0 :ok: |  spotbugs  |   0m 20s |  |  hadoop-project has no data from spotbugs  |\r\n   | +1 :green_heart: |  shadedclient  |  61m  5s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  | 730m 25s |  |  root in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   1m 51s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 1081m  7s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7573/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7573 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient codespell detsecrets xmllint spotbugs checkstyle markdownlint shellcheck shelldocs |\r\n   | uname | Linux 40ab38e987b1 5.15.0-134-generic #145-Ubuntu SMP Wed Feb 12 20:08:39 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / a13da89615fe4e05299a8064c407a0666d476d0d |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7573/1/testReport/ |\r\n   | Max. process+thread count | 4261 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-project hadoop-tools/hadoop-aws . U: . |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7573/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 shellcheck=0.7.0 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-03T11:33:49.690+0000", "updated": "2025-04-03T11:33:49.690+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17941824", "id": "17941824", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "ahmarsuhail commented on PR #7573:\nURL: https://github.com/apache/hadoop/pull/7573#issuecomment-2785732609\n\n   looking at this failure now\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-08T08:59:32.305+0000", "updated": "2025-04-08T08:59:32.305+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17941848", "id": "17941848", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran closed pull request #7573: HADOOP-19485. S3A: Upgrade AWS V2 SDK to 2.29.52\nURL: https://github.com/apache/hadoop/pull/7573\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-08T10:34:22.066+0000", "updated": "2025-04-08T10:34:22.066+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610938/comment/17941849", "id": "17941849", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "steveloughran commented on PR #7573:\nURL: https://github.com/apache/hadoop/pull/7573#issuecomment-2785990350\n\n   merge is done now; closing\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-08T10:34:22.968+0000", "updated": "2025-04-08T10:34:22.968+0000"}], "maxResults": 47, "total": 47, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}