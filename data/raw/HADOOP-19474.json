{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13610099", "self": "https://issues.apache.org/jira/rest/api/2/issue/13610099", "key": "HADOOP-19474", "fields": {"summary": "ABFS: [FnsOverBlob] Listing Optimizations to avoid multiple iteration over list response.", "description": "On blob endpoint, there are a couple of handling that is needed to be done on client side.\r\nThis involves:\r\n # Parsing of xml response and converting them to VersionedFileStatus list\r\n # Removing duplicate entries for non-empty explicit directories coming due to presence of the marker files\r\n # Trigerring Rename recovery on the previously failed rename indicated by the presence of pending json file.\r\n\r\nCurrently all three are done in a separate iteration over whole list. This is to pbring all those things to a common place so that single iteration over list reposne can handle all three.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=anujmodi", "name": "anujmodi", "key": "JIRAUSER307456", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"}, "displayName": "Anuj Modi", "active": true, "timeZone": "Asia/Kolkata"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932040", "id": "17932040", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2695179276\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 20s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  26m 34s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 23s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 20s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 23s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 19s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  24m  1s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  24m 12s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 16s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  1s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/4/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 17 new + 12 unchanged - 0 fixed = 29 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 18s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 14s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/4/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 generated 2 new + 10 unchanged - 0 fixed = 12 total (was 10)  |\r\n   | -1 :x: |  javadoc  |   0m 15s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/4/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06.txt) |  hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 generated 2 new + 10 unchanged - 0 fixed = 12 total (was 10)  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 40s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  24m 33s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 23s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 23s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  84m 22s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/4/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux 5e009114837d 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / ec1419b47587389823a2b6175322bb8541a25e34 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/4/testReport/ |\r\n   | Max. process+thread count | 559 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/4/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-03T18:06:57.051+0000", "updated": "2025-03-03T18:06:57.051+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932045", "id": "17932045", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2695226615\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  10m 41s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  36m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 57s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 39s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 32s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  35m 38s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  35m 58s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 32s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/3/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 18 new + 12 unchanged - 0 fixed = 30 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | -1 :x: |  javadoc  |   0m 25s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/3/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04.txt) |  hadoop-tools_hadoop-azure-jdkUbuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 generated 2 new + 10 unchanged - 0 fixed = 12 total (was 10)  |\r\n   | -1 :x: |  javadoc  |   0m 27s | [/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/3/artifact/out/results-javadoc-javadoc-hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06.txt) |  hadoop-tools_hadoop-azure-jdkPrivateBuild-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 generated 2 new + 10 unchanged - 0 fixed = 12 total (was 10)  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  37m 49s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 50s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 135m  4s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/3/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets |\r\n   | uname | Linux b3d24f968b2c 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / b37c3d2bdb5f8771b1dbad0a179be307cf3444b1 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/3/testReport/ |\r\n   | Max. process+thread count | 761 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/3/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-03T18:30:19.867+0000", "updated": "2025-03-03T18:30:19.867+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932271", "id": "17932271", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2697120282\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 54s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 59s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 30s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 33s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 10s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 49s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  40m 11s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 31s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 14s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  1s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 137m 10s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/5/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux 8621c9c4dac7 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 3edab0f5b5ab5d0def2b79d9ac394d4c72001e8e |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/5/testReport/ |\r\n   | Max. process+thread count | 524 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/5/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-04T11:05:58.068+0000", "updated": "2025-03-04T11:05:58.068+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932851", "id": "17932851", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r1982759645\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n\nReview Comment:\n   Is this class expected to be in the contracts folder ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-06T06:24:26.486+0000", "updated": "2025-03-06T06:24:26.486+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932857", "id": "17932857", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r1982780815\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1583,26 +1590,40 @@ public Hashtable<String, String> getXMSProperties(AbfsHttpOperation result)\n \n   /**\n    * Parse the XML response body returned by ListBlob API on Blob Endpoint.\n-   * @param stream InputStream contains the response from server.\n-   * @return BlobListResultSchema containing the list of entries.\n-   * @throws IOException if parsing fails.\n+   * @param result InputStream contains the response from server.\n+   * @param uri to be used for path conversion.\n+   * @return {@link ListResponseData}. containing listing response.\n+   * @throws AzureBlobFileSystemException if parsing fails.\n    */\n   @Override\n-  public ListResultSchema parseListPathResults(final InputStream stream) throws IOException {\n-    if (stream == null) {\n-      return null;\n-    }\n+  public ListResponseData parseListPathResults(AbfsHttpOperation result, URI uri)\n+      throws AzureBlobFileSystemException {\n     BlobListResultSchema listResultSchema;\n-    try {\n-      final SAXParser saxParser = saxParserThreadLocal.get();\n-      saxParser.reset();\n-      listResultSchema = new BlobListResultSchema();\n-      saxParser.parse(stream, new BlobListXmlParser(listResultSchema, getBaseUrl().toString()));\n-    } catch (SAXException | IOException e) {\n-      throw new RuntimeException(e);\n+    try (InputStream stream = result.getListResultStream()) {\n+      if (stream == null) {\n+        return null;\n+      }\n+      try {\n+        final SAXParser saxParser = saxParserThreadLocal.get();\n+        saxParser.reset();\n+        listResultSchema = new BlobListResultSchema();\n+        saxParser.parse(stream,\n+            new BlobListXmlParser(listResultSchema, getBaseUrl().toString()));\n+        result.setListResultSchema(listResultSchema);\n+      } catch (SAXException | IOException e) {\n+        throw new AbfsDriverException(e);\n+      }\n+    } catch (IOException e) {\n+      LOG.error(\"Unable to deserialize list results\", e);\n\nReview Comment:\n   Given we have the uri now, should we include that in the error log as well ?\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-06T06:45:03.422+0000", "updated": "2025-03-06T06:45:03.422+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932862", "id": "17932862", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r1982791170\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1903,39 +1916,57 @@ private List<AbfsHttpHeader> getMetadataHeadersList(final Hashtable<String, Stri\n    * This is to handle duplicate listing entries returned by Blob Endpoint for\n    * implicit paths that also has a marker file created for them.\n    * This will retain entry corresponding to marker file and remove the BlobPrefix entry.\n+   * This will also filter out all the rename pending json files in listing output.\n    * @param listResultSchema List of entries returned by Blob Endpoint.\n+   * @param uri URI to be used for path conversion.\n    * @return List of entries after removing duplicates.\n    */\n-  private BlobListResultSchema removeDuplicateEntries(BlobListResultSchema listResultSchema) {\n-    List<BlobListResultEntrySchema> uniqueEntries = new ArrayList<>();\n+  private ListResponseData filterDuplicateEntriesAndRenamePendingFiles(\n+      BlobListResultSchema listResultSchema, URI uri) throws IOException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    Map<Path, Integer> renamePendingJsonPaths = new HashMap<>();\n     TreeMap<String, BlobListResultEntrySchema> nameToEntryMap = new TreeMap<>();\n \n     for (BlobListResultEntrySchema entry : listResultSchema.paths()) {\n       if (StringUtils.isNotEmpty(entry.eTag())) {\n         // This is a blob entry. It is either a file or a marker blob.\n         // In both cases we will add this.\n         nameToEntryMap.put(entry.name(), entry);\n+        fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n+\n+        if (isRenamePendingJsonPathEntry(entry)) {\n+          renamePendingJsonPaths.put(entry.path(), entry.contentLength().intValue());\n+        }\n       } else {\n         // This is a BlobPrefix entry. It is a directory with file inside\n         // This might have already been added as a marker blob.\n         if (!nameToEntryMap.containsKey(entry.name())) {\n           nameToEntryMap.put(entry.name(), entry);\n+          fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n         }\n       }\n     }\n \n-    uniqueEntries.addAll(nameToEntryMap.values());\n-    listResultSchema.withPaths(uniqueEntries);\n-    return listResultSchema;\n+    ListResponseData listResponseData = new ListResponseData();\n+    listResponseData.setFileStatusList(fileStatuses);\n+    listResponseData.setRenamePendingJsonPaths(renamePendingJsonPaths);\n+    listResponseData.setContinuationToken(listResultSchema.getNextMarker());\n+    return listResponseData;\n+  }\n+\n+  private boolean isRenamePendingJsonPathEntry(BlobListResultEntrySchema entry) {\n\nReview Comment:\n   missing javadocs\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-06T06:54:38.910+0000", "updated": "2025-03-06T06:54:38.910+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17932863", "id": "17932863", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r1982792319\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1903,39 +1916,57 @@ private List<AbfsHttpHeader> getMetadataHeadersList(final Hashtable<String, Stri\n    * This is to handle duplicate listing entries returned by Blob Endpoint for\n    * implicit paths that also has a marker file created for them.\n    * This will retain entry corresponding to marker file and remove the BlobPrefix entry.\n+   * This will also filter out all the rename pending json files in listing output.\n    * @param listResultSchema List of entries returned by Blob Endpoint.\n+   * @param uri URI to be used for path conversion.\n    * @return List of entries after removing duplicates.\n    */\n-  private BlobListResultSchema removeDuplicateEntries(BlobListResultSchema listResultSchema) {\n-    List<BlobListResultEntrySchema> uniqueEntries = new ArrayList<>();\n+  private ListResponseData filterDuplicateEntriesAndRenamePendingFiles(\n+      BlobListResultSchema listResultSchema, URI uri) throws IOException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    Map<Path, Integer> renamePendingJsonPaths = new HashMap<>();\n     TreeMap<String, BlobListResultEntrySchema> nameToEntryMap = new TreeMap<>();\n \n     for (BlobListResultEntrySchema entry : listResultSchema.paths()) {\n       if (StringUtils.isNotEmpty(entry.eTag())) {\n         // This is a blob entry. It is either a file or a marker blob.\n         // In both cases we will add this.\n         nameToEntryMap.put(entry.name(), entry);\n+        fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n+\n+        if (isRenamePendingJsonPathEntry(entry)) {\n+          renamePendingJsonPaths.put(entry.path(), entry.contentLength().intValue());\n+        }\n       } else {\n         // This is a BlobPrefix entry. It is a directory with file inside\n         // This might have already been added as a marker blob.\n         if (!nameToEntryMap.containsKey(entry.name())) {\n           nameToEntryMap.put(entry.name(), entry);\n+          fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n         }\n       }\n     }\n \n-    uniqueEntries.addAll(nameToEntryMap.values());\n-    listResultSchema.withPaths(uniqueEntries);\n-    return listResultSchema;\n+    ListResponseData listResponseData = new ListResponseData();\n+    listResponseData.setFileStatusList(fileStatuses);\n+    listResponseData.setRenamePendingJsonPaths(renamePendingJsonPaths);\n+    listResponseData.setContinuationToken(listResultSchema.getNextMarker());\n+    return listResponseData;\n+  }\n+\n+  private boolean isRenamePendingJsonPathEntry(BlobListResultEntrySchema entry) {\n\nReview Comment:\n   Can be simplified to this :- private boolean isRenamePendingJsonPathEntry(BlobListResultEntrySchema entry) {\r\n       String path = entry.path() != null ? entry.path().toUri().getPath() : null;\r\n       return path != null && !entry.path().isRoot() && isAtomicRenameKey(path) && path.endsWith(RenameAtomicity.SUFFIX);\r\n   }\r\n   \n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-06T06:55:43.988+0000", "updated": "2025-03-06T06:55:43.988+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17936273", "id": "17936273", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2730515526\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  18m 55s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 56s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 44s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 38s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 24s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 46s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 42s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  1s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 154m  5s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/6/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux ace099d34769 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 10163c81b7a2b4eecd1458b2e081e3681fc00872 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/6/testReport/ |\r\n   | Max. process+thread count | 528 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/6/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-17T18:45:09.909+0000", "updated": "2025-03-17T18:45:09.909+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17936378", "id": "17936378", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2731787866\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 49s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 49s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 50s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 12s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/7/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 12 unchanged - 0 fixed = 14 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m  6s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 59s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 35s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 42s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/7/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux 70d7863dee1e 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 2b13bbd62de448279735425a934b61c869149183 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/7/testReport/ |\r\n   | Max. process+thread count | 527 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/7/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-18T06:12:03.643+0000", "updated": "2025-03-18T06:12:03.643+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17936401", "id": "17936401", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2732032241\n\n   :broken_heart: **-1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 48s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 50s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 42s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 32s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 40s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 45s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m  7s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 34s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 19s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/8/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 2 new + 12 unchanged - 0 fixed = 14 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 26s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | -1 :x: |  spotbugs  |   1m  9s | [/new-spotbugs-hadoop-tools_hadoop-azure.html](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/8/artifact/out/new-spotbugs-hadoop-tools_hadoop-azure.html) |  hadoop-tools/hadoop-azure generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 57s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 59s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 133m 27s |  |  |\r\n   \r\n   \r\n   | Reason | Tests |\r\n   |-------:|:------|\r\n   | SpotBugs | module:hadoop-tools/hadoop-azure |\r\n   |  |  Nullcheck of tracingContext at line 388 of value previously dereferenced in org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient.listPath(String, boolean, int, String, TracingContext, URI, boolean)  At AbfsBlobClient.java:388 of value previously dereferenced in org.apache.hadoop.fs.azurebfs.services.AbfsBlobClient.listPath(String, boolean, int, String, TracingContext, URI, boolean)  At AbfsBlobClient.java:[line 382] |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/8/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux ca71da58e766 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5d34f65d098fb7cbf8da25c2dd7a81160ef1ca11 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/8/testReport/ |\r\n   | Max. process+thread count | 524 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/8/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-18T08:05:50.725+0000", "updated": "2025-03-18T08:05:50.725+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17937002", "id": "17937002", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2004818573\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n\nReview Comment:\n   Hmm.\r\n   Not very sure. All other classes related to List parsing were there only so kept it there.\r\n   But again this is used in public interfaces. What do you suggest will be a good place for this?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-20T05:07:45.712+0000", "updated": "2025-03-20T05:07:45.712+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17937003", "id": "17937003", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2004822284\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1583,26 +1590,40 @@ public Hashtable<String, String> getXMSProperties(AbfsHttpOperation result)\n \n   /**\n    * Parse the XML response body returned by ListBlob API on Blob Endpoint.\n-   * @param stream InputStream contains the response from server.\n-   * @return BlobListResultSchema containing the list of entries.\n-   * @throws IOException if parsing fails.\n+   * @param result InputStream contains the response from server.\n+   * @param uri to be used for path conversion.\n+   * @return {@link ListResponseData}. containing listing response.\n+   * @throws AzureBlobFileSystemException if parsing fails.\n    */\n   @Override\n-  public ListResultSchema parseListPathResults(final InputStream stream) throws IOException {\n-    if (stream == null) {\n-      return null;\n-    }\n+  public ListResponseData parseListPathResults(AbfsHttpOperation result, URI uri)\n+      throws AzureBlobFileSystemException {\n     BlobListResultSchema listResultSchema;\n-    try {\n-      final SAXParser saxParser = saxParserThreadLocal.get();\n-      saxParser.reset();\n-      listResultSchema = new BlobListResultSchema();\n-      saxParser.parse(stream, new BlobListXmlParser(listResultSchema, getBaseUrl().toString()));\n-    } catch (SAXException | IOException e) {\n-      throw new RuntimeException(e);\n+    try (InputStream stream = result.getListResultStream()) {\n+      if (stream == null) {\n+        return null;\n+      }\n+      try {\n+        final SAXParser saxParser = saxParserThreadLocal.get();\n+        saxParser.reset();\n+        listResultSchema = new BlobListResultSchema();\n+        saxParser.parse(stream,\n+            new BlobListXmlParser(listResultSchema, getBaseUrl().toString()));\n+        result.setListResultSchema(listResultSchema);\n+      } catch (SAXException | IOException e) {\n+        throw new AbfsDriverException(e);\n+      }\n+    } catch (IOException e) {\n+      LOG.error(\"Unable to deserialize list results\", e);\n\nReview Comment:\n   Nice, taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-20T05:11:41.373+0000", "updated": "2025-03-20T05:11:41.373+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17937007", "id": "17937007", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2004848126\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -1903,39 +1916,57 @@ private List<AbfsHttpHeader> getMetadataHeadersList(final Hashtable<String, Stri\n    * This is to handle duplicate listing entries returned by Blob Endpoint for\n    * implicit paths that also has a marker file created for them.\n    * This will retain entry corresponding to marker file and remove the BlobPrefix entry.\n+   * This will also filter out all the rename pending json files in listing output.\n    * @param listResultSchema List of entries returned by Blob Endpoint.\n+   * @param uri URI to be used for path conversion.\n    * @return List of entries after removing duplicates.\n    */\n-  private BlobListResultSchema removeDuplicateEntries(BlobListResultSchema listResultSchema) {\n-    List<BlobListResultEntrySchema> uniqueEntries = new ArrayList<>();\n+  private ListResponseData filterDuplicateEntriesAndRenamePendingFiles(\n+      BlobListResultSchema listResultSchema, URI uri) throws IOException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    Map<Path, Integer> renamePendingJsonPaths = new HashMap<>();\n     TreeMap<String, BlobListResultEntrySchema> nameToEntryMap = new TreeMap<>();\n \n     for (BlobListResultEntrySchema entry : listResultSchema.paths()) {\n       if (StringUtils.isNotEmpty(entry.eTag())) {\n         // This is a blob entry. It is either a file or a marker blob.\n         // In both cases we will add this.\n         nameToEntryMap.put(entry.name(), entry);\n+        fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n+\n+        if (isRenamePendingJsonPathEntry(entry)) {\n+          renamePendingJsonPaths.put(entry.path(), entry.contentLength().intValue());\n+        }\n       } else {\n         // This is a BlobPrefix entry. It is a directory with file inside\n         // This might have already been added as a marker blob.\n         if (!nameToEntryMap.containsKey(entry.name())) {\n           nameToEntryMap.put(entry.name(), entry);\n+          fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n         }\n       }\n     }\n \n-    uniqueEntries.addAll(nameToEntryMap.values());\n-    listResultSchema.withPaths(uniqueEntries);\n-    return listResultSchema;\n+    ListResponseData listResponseData = new ListResponseData();\n+    listResponseData.setFileStatusList(fileStatuses);\n+    listResponseData.setRenamePendingJsonPaths(renamePendingJsonPaths);\n+    listResponseData.setContinuationToken(listResultSchema.getNextMarker());\n+    return listResponseData;\n+  }\n+\n+  private boolean isRenamePendingJsonPathEntry(BlobListResultEntrySchema entry) {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-20T05:40:23.753+0000", "updated": "2025-03-20T05:40:23.753+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17937039", "id": "17937039", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2739497784\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 50s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  1s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  1s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  1s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  1s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  41m 47s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 45s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 35s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 42s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 11s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 19s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 40s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 31s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 37s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 36s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 29s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 29s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/9/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 12 unchanged - 0 fixed = 13 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 34s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  41m 27s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  1s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 137m 48s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/9/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux a54f24fbde59 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 5b1374cc37c7dec7f0703a3229b25e6b07c351c7 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/9/testReport/ |\r\n   | Max. process+thread count | 523 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/9/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-20T07:57:16.361+0000", "updated": "2025-03-20T07:57:16.361+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17937343", "id": "17937343", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2742841478\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  20m 44s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  40m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 31s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 41s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 56s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m 18s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 20s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/10/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 7 new + 12 unchanged - 0 fixed = 19 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  8s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  39m 19s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 153m 56s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/10/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux ea04b4a9351f 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 21f590ab6b6d580a05e38954251123d2367e2665 |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/10/testReport/ |\r\n   | Max. process+thread count | 544 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/10/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-21T09:44:34.423+0000", "updated": "2025-03-21T09:44:34.423+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938498", "id": "17938498", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2753543331\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   8m 19s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 39s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 24s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 28s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 28s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 20s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 46s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  20m  1s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  20m 14s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 19s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | -0 :warning: |  checkstyle  |   0m 11s | [/results-checkstyle-hadoop-tools_hadoop-azure.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/11/artifact/out/results-checkstyle-hadoop-tools_hadoop-azure.txt) |  hadoop-tools/hadoop-azure: The patch generated 1 new + 12 unchanged - 0 fixed = 13 total (was 12)  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 46s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 50s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 28s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 24s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  80m 19s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/11/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux c5625fee2e40 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / e5a021a00bbcacd9e026eee61ebadf82badadeaa |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/11/testReport/ |\r\n   | Max. process+thread count | 683 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/11/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T08:10:11.809+0000", "updated": "2025-03-26T08:10:11.809+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938508", "id": "17938508", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "bhattmanish98 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013589793\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1277,57 +1275,14 @@ public String listStatus(final Path path, final String startFrom,\n \n     do {\n       try (AbfsPerfInfo perfInfo = startTracking(\"listStatus\", \"listPath\")) {\n-        AbfsRestOperation op = listingClient.listPath(relativePath, false,\n-            abfsConfiguration.getListMaxResults(), continuation,\n-            tracingContext);\n+        ListResponseData listResponseData = listingClient.listPath(relativePath,\n\nReview Comment:\n   Should we perform a null check on listResponseData in this case?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsAHCHttpOperation.java:\n##########\n@@ -194,26 +192,14 @@ String getConnResponseMessage() throws IOException {\n   public void processResponse(final byte[] buffer,\n       final int offset,\n       final int length) throws IOException {\n-    try {\n-      if (!isPayloadRequest) {\n-        prepareRequest();\n-        LOG.debug(\"Sending request: {}\", httpRequestBase);\n-        httpResponse = executeRequest();\n-        LOG.debug(\"Request sent: {}; response {}\", httpRequestBase,\n-            httpResponse);\n-      }\n-      parseResponseHeaderAndBody(buffer, offset, length);\n-    } finally {\n\nReview Comment:\n   Any reason for removing this part of code?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n+      try {\n+        primaryUserGroup = UserGroupInformation.getCurrentUser().getPrimaryGroupName();\n+      } catch (IOException ex) {\n+        LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\n+            getPrimaryUser());\n+        primaryUserGroup = getPrimaryUser();\n+      }\n+    } else {\n+      //Provide a default group name\n+      primaryUserGroup = getPrimaryUser();\n+    }\n+    return primaryUserGroup;\n+  }\n+\n+  private String getPrimaryUser() throws AzureBlobFileSystemException {\n\nReview Comment:\n   Java doc missing\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/VersionedFileStatus.java:\n##########\n@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.EtagSource;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * A File status with version info extracted from the etag value returned\n+ * in a LIST or HEAD request.\n+ * The etag is included in the java serialization.\n+ */\n+public class VersionedFileStatus extends FileStatus implements EtagSource {\n+\n+  /**\n+   * The superclass is declared serializable; this subclass can also\n+   * be serialized.\n+   */\n+  private static final long serialVersionUID = -2009013240419749458L;\n+\n+  /**\n+   * The etag of an object.\n+   * Not-final so that serialization via reflection will preserve the value.\n+   */\n+  private String version;\n+\n+  private String encryptionContext;\n+\n+  public VersionedFileStatus(\n+      final String owner, final String group, final FsPermission fsPermission, final boolean hasAcl,\n+      final long length, final boolean isdir, final int blockReplication,\n+      final long blocksize, final long modificationTime, final Path path,\n+      final String version, final String encryptionContext) {\n+    super(length, isdir, blockReplication, blocksize, modificationTime, 0,\n+        fsPermission,\n+        owner,\n+        group,\n+        null,\n+        path,\n+        hasAcl, false, false);\n+\n+    this.version = version;\n+    this.encryptionContext = encryptionContext;\n+  }\n+\n+  /** Compare if this object is equal to another object.\n+   * @param   obj the object to be compared.\n+   * @return  true if two file status has the same path name; false if not.\n+   */\n+  @Override\n+  public boolean equals(Object obj) {\n+    if (!(obj instanceof FileStatus)) {\n+      return false;\n+    }\n+\n+    FileStatus other = (FileStatus) obj;\n+\n+    if (!this.getPath().equals(other.getPath())) {// compare the path\n+      return false;\n+    }\n+\n+    if (other instanceof VersionedFileStatus) {\n+      return this.version.equals(((VersionedFileStatus) other).version);\n+    }\n+\n+    return true;\n+  }\n+\n+  /**\n+   * Returns a hash code value for the object, which is defined as\n+   * the hash code of the path name.\n+   *\n+   * @return  a hash code value for the path name and version\n+   */\n+  @Override\n+  public int hashCode() {\n+    int hash = getPath().hashCode();\n+    hash = 89 * hash + (this.version != null ? this.version.hashCode() : 0);\n\nReview Comment:\n   What is the logic behind multiplying hash with 89?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -1464,20 +1472,41 @@ public Hashtable<String, String> getXMSProperties(AbfsHttpOperation result)\n \n   /**\n    * Parse the list file response from DFS ListPath API in Json format\n-   * @param stream InputStream contains the list results.\n-   * @throws IOException if parsing fails.\n+   * @param result InputStream contains the list results.\n+   * @param uri to be used for path conversion.\n+   * @return {@link ListResponseData}. containing listing response.\n+   * @throws AzureBlobFileSystemException if parsing fails.\n    */\n   @Override\n-  public ListResultSchema parseListPathResults(final InputStream stream) throws IOException {\n-    DfsListResultSchema listResultSchema;\n-    try {\n-      final ObjectMapper objectMapper = new ObjectMapper();\n-      listResultSchema = objectMapper.readValue(stream, DfsListResultSchema.class);\n+  public ListResponseData parseListPathResults(AbfsHttpOperation result, URI uri) throws AzureBlobFileSystemException {\n+    try (InputStream listResultInputStream = result.getListResultStream()) {\n+      DfsListResultSchema listResultSchema;\n+      try {\n+        final ObjectMapper objectMapper = new ObjectMapper();\n+        listResultSchema = objectMapper.readValue(listResultInputStream,\n+            DfsListResultSchema.class);\n+        result.setListResultSchema(listResultSchema);\n+        LOG.debug(\"ListPath listed {} paths with {} as continuation token\",\n+            listResultSchema.paths().size(),\n+            getContinuationFromResponse(result));\n+      } catch (IOException ex) {\n+        throw new AbfsDriverException(ex);\n\nReview Comment:\n   Please add some error message along with exception.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1780,19 +1782,19 @@ private Configuration createConfig(String producerQueueSize, String consumerMaxL\n   private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n       boolean isSrcExist, boolean isDstExist, boolean isJsonExist)\n       throws IOException {\n-    Assertions.assertThat(fs.exists(dst))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n-        .isEqualTo(isDstExist);\n     Assertions.assertThat(fs.exists(new Path(src.getParent(), src.getName() + SUFFIX)))\n         .describedAs(\"Renamed Pending Json file should exist.\")\n         .isEqualTo(isJsonExist);\n     Assertions.assertThat(fs.exists(src))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n+        .describedAs(\"Renamed Source directory should exist.\")\n\nReview Comment:\n   Could you please correct it to `Renamed Source directory should not exist.`\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n\nReview Comment:\n   We can simplify this method\r\n   ```\r\n   private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\r\n      if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\r\n         try {\r\n           return UserGroupInformation.getCurrentUser().getPrimaryGroupName();\r\n         } catch (IOException ex) {\r\n           LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\r\n               getPrimaryUser());\r\n         }\r\n       }\r\n       return getPrimaryUser();\r\n   }\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1277,57 +1275,14 @@ public String listStatus(final Path path, final String startFrom,\n \n     do {\n       try (AbfsPerfInfo perfInfo = startTracking(\"listStatus\", \"listPath\")) {\n-        AbfsRestOperation op = listingClient.listPath(relativePath, false,\n-            abfsConfiguration.getListMaxResults(), continuation,\n-            tracingContext);\n+        ListResponseData listResponseData = listingClient.listPath(relativePath,\n+            false, abfsConfiguration.getListMaxResults(), continuation,\n+            tracingContext, this.uri);\n+        AbfsRestOperation op = listResponseData.getOp();\n         perfInfo.registerResult(op.getResult());\n-        continuation = listingClient.getContinuationFromResponse(op.getResult());\n-        ListResultSchema retrievedSchema = op.getResult().getListResultSchema();\n-        if (retrievedSchema == null) {\n-          throw new AbfsRestOperationException(\n-                  AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n-                  AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n-                  \"listStatusAsync path not found\",\n-                  null, op.getResult());\n-        }\n-\n-        long blockSize = abfsConfiguration.getAzureBlockSize();\n-\n-        for (ListResultEntrySchema entry : retrievedSchema.paths()) {\n-          final String owner = identityTransformer.transformIdentityForGetRequest(entry.owner(), true, userName);\n-          final String group = identityTransformer.transformIdentityForGetRequest(entry.group(), false, primaryUserGroup);\n-          final String encryptionContext = entry.getXMsEncryptionContext();\n-          final FsPermission fsPermission = entry.permissions() == null\n-                  ? new AbfsPermission(FsAction.ALL, FsAction.ALL, FsAction.ALL)\n-                  : AbfsPermission.valueOf(entry.permissions());\n-          final boolean hasAcl = AbfsPermission.isExtendedAcl(entry.permissions());\n-\n-          long lastModifiedMillis = 0;\n-          long contentLength = entry.contentLength() == null ? 0 : entry.contentLength();\n-          boolean isDirectory = entry.isDirectory() == null ? false : entry.isDirectory();\n-          if (entry.lastModified() != null && !entry.lastModified().isEmpty()) {\n-            lastModifiedMillis = DateTimeUtils.parseLastModifiedTime(\n-                entry.lastModified());\n-          }\n-\n-          Path entryPath = new Path(File.separator + entry.name());\n-          entryPath = entryPath.makeQualified(this.uri, entryPath);\n-\n-          fileStatuses.add(\n-                  new VersionedFileStatus(\n-                          owner,\n-                          group,\n-                          fsPermission,\n-                          hasAcl,\n-                          contentLength,\n-                          isDirectory,\n-                          1,\n-                          blockSize,\n-                          lastModifiedMillis,\n-                          entryPath,\n-                          entry.eTag(),\n-                          encryptionContext));\n-        }\n+        continuation = listResponseData.getContinuationToken();\n+        List<FileStatus> fileStatusListInCurrItr = listResponseData.getFileStatusList();\n+        fileStatuses.addAll(fileStatusListInCurrItr);\n\nReview Comment:\n   Before adding it to fileStatuses, shouldn't we check if fileStatusListInCurrItr is null or empty?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation;\n+\n+/**\n+ * This class is used to hold the response data for list operations.\n+ * It contains a list of FileStatus objects, a map of rename pending JSON paths,\n+ * continuation token and the executed REST operation.\n+ */\n+public class ListResponseData {\n+\n+  private List<FileStatus> fileStatusList;\n+  private Map<Path, Integer> renamePendingJsonPaths;\n\nReview Comment:\n   Since content Length is long, we should keep it Map<Path, Long>.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -285,6 +298,18 @@ private AbfsClient(final URL baseUrl,\n           metricIdlePeriod);\n     }\n     this.abfsMetricUrl = abfsConfiguration.getMetricUri();\n+\n+    final Class<? extends IdentityTransformerInterface> identityTransformerClass =\n+        abfsConfiguration.getRawConfiguration().getClass(FS_AZURE_IDENTITY_TRANSFORM_CLASS, IdentityTransformer.class,\n+            IdentityTransformerInterface.class);\n+    try {\n+      this.identityTransformer =\n+          identityTransformerClass.getConstructor(Configuration.class).newInstance(abfsConfiguration.getRawConfiguration());\n+    } catch (IllegalAccessException | InstantiationException | IllegalArgumentException\n+             | InvocationTargetException | NoSuchMethodException e) {\n+      throw new IOException(e);\n\nReview Comment:\n   We can add some message as well along with exception for better understanding.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n+      try {\n+        primaryUserGroup = UserGroupInformation.getCurrentUser().getPrimaryGroupName();\n+      } catch (IOException ex) {\n+        LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\n+            getPrimaryUser());\n+        primaryUserGroup = getPrimaryUser();\n+      }\n+    } else {\n+      //Provide a default group name\n+      primaryUserGroup = getPrimaryUser();\n+    }\n+    return primaryUserGroup;\n+  }\n+\n+  private String getPrimaryUser() throws AzureBlobFileSystemException {\n+    try {\n+      return UserGroupInformation.getCurrentUser().getUserName();\n+    } catch (IOException ex) {\n+      throw new AbfsDriverException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Creates a VersionedFileStatus object from the ListResultEntrySchema.\n+   * @param entry ListResultEntrySchema object.\n+   * @param uri to be used for the path conversion.\n+   * @return VersionedFileStatus object.\n+   * @throws AzureBlobFileSystemException if transformation fails.\n+   */\n+  protected VersionedFileStatus getVersionedFileStatusFromEntry(\n+      ListResultEntrySchema entry, URI uri) throws AzureBlobFileSystemException {\n+    long blockSize = abfsConfiguration.getAzureBlockSize();\n+    final String owner, group;\n+    try{\n+      if (identityTransformer != null) {\n+        owner = identityTransformer.transformIdentityForGetRequest(\n+            entry.owner(), true, getPrimaryUser());\n+        group = identityTransformer.transformIdentityForGetRequest(\n+            entry.group(), false, getPrimaryUserGroup());\n+      } else {\n+        owner = null;\n\nReview Comment:\n   The default value for owner and group is null. Do we need to explicitly assign it to null here?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n\nReview Comment:\n   Java doc for this method\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n+      try {\n+        primaryUserGroup = UserGroupInformation.getCurrentUser().getPrimaryGroupName();\n+      } catch (IOException ex) {\n+        LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\n+            getPrimaryUser());\n+        primaryUserGroup = getPrimaryUser();\n+      }\n+    } else {\n+      //Provide a default group name\n+      primaryUserGroup = getPrimaryUser();\n+    }\n+    return primaryUserGroup;\n+  }\n+\n+  private String getPrimaryUser() throws AzureBlobFileSystemException {\n+    try {\n+      return UserGroupInformation.getCurrentUser().getUserName();\n+    } catch (IOException ex) {\n+      throw new AbfsDriverException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Creates a VersionedFileStatus object from the ListResultEntrySchema.\n+   * @param entry ListResultEntrySchema object.\n+   * @param uri to be used for the path conversion.\n+   * @return VersionedFileStatus object.\n+   * @throws AzureBlobFileSystemException if transformation fails.\n+   */\n+  protected VersionedFileStatus getVersionedFileStatusFromEntry(\n+      ListResultEntrySchema entry, URI uri) throws AzureBlobFileSystemException {\n+    long blockSize = abfsConfiguration.getAzureBlockSize();\n+    final String owner, group;\n+    try{\n+      if (identityTransformer != null) {\n+        owner = identityTransformer.transformIdentityForGetRequest(\n+            entry.owner(), true, getPrimaryUser());\n+        group = identityTransformer.transformIdentityForGetRequest(\n+            entry.group(), false, getPrimaryUserGroup());\n+      } else {\n+        owner = null;\n+        group = null;\n+      }\n+    } catch (IOException ex) {\n+      LOG.error(\"Failed to get owner/group for path {}\", entry.name(), ex);\n+      throw new AbfsDriverException(ex);\n+    }\n+    final String encryptionContext = entry.getXMsEncryptionContext();\n\nReview Comment:\n   Should we perform a null check on the entry before this, or will the entry always have a non-null value?\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java:\n##########\n@@ -668,6 +660,10 @@ protected boolean isConnectionDisconnectedOnError() {\n     return connectionDisconnectedOnError;\n   }\n \n+  protected void setListResultSchema(final ListResultSchema listResultSchema) {\n\nReview Comment:\n   Java doc missing\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -374,63 +380,68 @@ public AbfsRestOperation listPath(final String relativePath, final boolean recur\n         requestHeaders);\n \n     op.execute(tracingContext);\n-    // Filter the paths for which no rename redo operation is performed.\n-    fixAtomicEntriesInListResults(op, tracingContext);\n-    if (isEmptyListResults(op.getResult()) && is404CheckRequired) {\n+    ListResponseData listResponseData = parseListPathResults(op.getResult(), uri);\n+    listResponseData.setOp(op);\n+\n+    // Perform Pending Rename Redo Operation on Atomic Rename Paths.\n+    // Crashed HBase log rename recovery can be done by Filesystem.listStatus.\n+    if (tracingContext.getOpType() == FSOperationType.LISTSTATUS\n+        && op.getResult() != null\n+        && op.getResult().getStatusCode() == HTTP_OK) {\n+      retryRenameOnAtomicEntriesInListResults(tracingContext,\n+          listResponseData.getRenamePendingJsonPaths());\n\nReview Comment:\n   We are calculating renamePendingJsonPath in this method after this line. How listResponseData.getRenamePendingJsonPaths() will work here is not clear.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/VersionedFileStatus.java:\n##########\n@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.EtagSource;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * A File status with version info extracted from the etag value returned\n+ * in a LIST or HEAD request.\n+ * The etag is included in the java serialization.\n+ */\n+public class VersionedFileStatus extends FileStatus implements EtagSource {\n+\n+  /**\n+   * The superclass is declared serializable; this subclass can also\n+   * be serialized.\n+   */\n+  private static final long serialVersionUID = -2009013240419749458L;\n+\n+  /**\n+   * The etag of an object.\n+   * Not-final so that serialization via reflection will preserve the value.\n+   */\n+  private String version;\n+\n+  private String encryptionContext;\n+\n+  public VersionedFileStatus(\n+      final String owner, final String group, final FsPermission fsPermission, final boolean hasAcl,\n+      final long length, final boolean isdir, final int blockReplication,\n+      final long blocksize, final long modificationTime, final Path path,\n+      final String version, final String encryptionContext) {\n+    super(length, isdir, blockReplication, blocksize, modificationTime, 0,\n+        fsPermission,\n+        owner,\n+        group,\n+        null,\n+        path,\n+        hasAcl, false, false);\n+\n+    this.version = version;\n+    this.encryptionContext = encryptionContext;\n+  }\n+\n+  /** Compare if this object is equal to another object.\n+   * @param   obj the object to be compared.\n+   * @return  true if two file status has the same path name; false if not.\n+   */\n+  @Override\n+  public boolean equals(Object obj) {\n+    if (!(obj instanceof FileStatus)) {\n+      return false;\n+    }\n+\n+    FileStatus other = (FileStatus) obj;\n+\n+    if (!this.getPath().equals(other.getPath())) {// compare the path\n+      return false;\n+    }\n+\n+    if (other instanceof VersionedFileStatus) {\n+      return this.version.equals(((VersionedFileStatus) other).version);\n+    }\n+\n+    return true;\n+  }\n+\n+  /**\n+   * Returns a hash code value for the object, which is defined as\n+   * the hash code of the path name.\n+   *\n+   * @return  a hash code value for the path name and version\n+   */\n+  @Override\n+  public int hashCode() {\n+    int hash = getPath().hashCode();\n+    hash = 89 * hash + (this.version != null ? this.version.hashCode() : 0);\n+    return hash;\n+  }\n+\n+  /**\n+   * Returns the version of this FileStatus\n+   *\n+   * @return  a string value for the FileStatus version\n+   */\n+  public String getVersion() {\n+    return this.version;\n+  }\n+\n+  @Override\n+  public String getEtag() {\n\nReview Comment:\n   Java doc missing\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation;\n+\n+/**\n+ * This class is used to hold the response data for list operations.\n+ * It contains a list of FileStatus objects, a map of rename pending JSON paths,\n+ * continuation token and the executed REST operation.\n+ */\n+public class ListResponseData {\n+\n+  private List<FileStatus> fileStatusList;\n+  private Map<Path, Integer> renamePendingJsonPaths;\n\nReview Comment:\n   Keeping it as an Integer is also fine. Since the JSON file will be small, it's okay to keep it as an int.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n\nReview Comment:\n   I think we should either create a new package and keep this file there or move it to the service package since there are many similar files present there.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T09:14:33.775+0000", "updated": "2025-03-26T09:14:33.775+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938526", "id": "17938526", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013835275\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/VersionedFileStatus.java:\n##########\n@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.EtagSource;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * A File status with version info extracted from the etag value returned\n+ * in a LIST or HEAD request.\n+ * The etag is included in the java serialization.\n+ */\n+public class VersionedFileStatus extends FileStatus implements EtagSource {\n\nReview Comment:\n   javadocs missing for some functions\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T10:30:05.631+0000", "updated": "2025-03-26T10:30:05.631+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938539", "id": "17938539", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013904387\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1277,57 +1275,14 @@ public String listStatus(final Path path, final String startFrom,\n \n     do {\n       try (AbfsPerfInfo perfInfo = startTracking(\"listStatus\", \"listPath\")) {\n-        AbfsRestOperation op = listingClient.listPath(relativePath, false,\n-            abfsConfiguration.getListMaxResults(), continuation,\n-            tracingContext);\n+        ListResponseData listResponseData = listingClient.listPath(relativePath,\n+            false, abfsConfiguration.getListMaxResults(), continuation,\n+            tracingContext, this.uri);\n+        AbfsRestOperation op = listResponseData.getOp();\n         perfInfo.registerResult(op.getResult());\n-        continuation = listingClient.getContinuationFromResponse(op.getResult());\n-        ListResultSchema retrievedSchema = op.getResult().getListResultSchema();\n-        if (retrievedSchema == null) {\n-          throw new AbfsRestOperationException(\n-                  AzureServiceErrorCode.PATH_NOT_FOUND.getStatusCode(),\n-                  AzureServiceErrorCode.PATH_NOT_FOUND.getErrorCode(),\n-                  \"listStatusAsync path not found\",\n-                  null, op.getResult());\n-        }\n-\n-        long blockSize = abfsConfiguration.getAzureBlockSize();\n-\n-        for (ListResultEntrySchema entry : retrievedSchema.paths()) {\n-          final String owner = identityTransformer.transformIdentityForGetRequest(entry.owner(), true, userName);\n-          final String group = identityTransformer.transformIdentityForGetRequest(entry.group(), false, primaryUserGroup);\n-          final String encryptionContext = entry.getXMsEncryptionContext();\n-          final FsPermission fsPermission = entry.permissions() == null\n-                  ? new AbfsPermission(FsAction.ALL, FsAction.ALL, FsAction.ALL)\n-                  : AbfsPermission.valueOf(entry.permissions());\n-          final boolean hasAcl = AbfsPermission.isExtendedAcl(entry.permissions());\n-\n-          long lastModifiedMillis = 0;\n-          long contentLength = entry.contentLength() == null ? 0 : entry.contentLength();\n-          boolean isDirectory = entry.isDirectory() == null ? false : entry.isDirectory();\n-          if (entry.lastModified() != null && !entry.lastModified().isEmpty()) {\n-            lastModifiedMillis = DateTimeUtils.parseLastModifiedTime(\n-                entry.lastModified());\n-          }\n-\n-          Path entryPath = new Path(File.separator + entry.name());\n-          entryPath = entryPath.makeQualified(this.uri, entryPath);\n-\n-          fileStatuses.add(\n-                  new VersionedFileStatus(\n-                          owner,\n-                          group,\n-                          fsPermission,\n-                          hasAcl,\n-                          contentLength,\n-                          isDirectory,\n-                          1,\n-                          blockSize,\n-                          lastModifiedMillis,\n-                          entryPath,\n-                          entry.eTag(),\n-                          encryptionContext));\n-        }\n+        continuation = listResponseData.getContinuationToken();\n+        List<FileStatus> fileStatusListInCurrItr = listResponseData.getFileStatusList();\n+        fileStatuses.addAll(fileStatusListInCurrItr);\n\nReview Comment:\n   Good Suggestion taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:04:53.601+0000", "updated": "2025-03-26T11:04:53.601+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938540", "id": "17938540", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013907557\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java:\n##########\n@@ -1277,57 +1275,14 @@ public String listStatus(final Path path, final String startFrom,\n \n     do {\n       try (AbfsPerfInfo perfInfo = startTracking(\"listStatus\", \"listPath\")) {\n-        AbfsRestOperation op = listingClient.listPath(relativePath, false,\n-            abfsConfiguration.getListMaxResults(), continuation,\n-            tracingContext);\n+        ListResponseData listResponseData = listingClient.listPath(relativePath,\n\nReview Comment:\n   ListResponseData itself will never be null.\r\n   Its members can be null. Will add null check for its member where ever applicable\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:07:03.778+0000", "updated": "2025-03-26T11:07:03.778+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938543", "id": "17938543", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013911075\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation;\n+\n+/**\n+ * This class is used to hold the response data for list operations.\n+ * It contains a list of FileStatus objects, a map of rename pending JSON paths,\n+ * continuation token and the executed REST operation.\n+ */\n+public class ListResponseData {\n+\n+  private List<FileStatus> fileStatusList;\n+  private Map<Path, Integer> renamePendingJsonPaths;\n\nReview Comment:\n   I think its a good suggestion to keep it long only. Everywhere we parse content lenght as long only.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:09:30.780+0000", "updated": "2025-03-26T11:09:30.780+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938547", "id": "17938547", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013916622\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsAHCHttpOperation.java:\n##########\n@@ -194,26 +192,14 @@ String getConnResponseMessage() throws IOException {\n   public void processResponse(final byte[] buffer,\n       final int offset,\n       final int length) throws IOException {\n-    try {\n-      if (!isPayloadRequest) {\n-        prepareRequest();\n-        LOG.debug(\"Sending request: {}\", httpRequestBase);\n-        httpResponse = executeRequest();\n-        LOG.debug(\"Request sent: {}; response {}\", httpRequestBase,\n-            httpResponse);\n-      }\n-      parseResponseHeaderAndBody(buffer, offset, length);\n-    } finally {\n\nReview Comment:\n   Yes. It was forcing the input stream to close just after response parsing. But with new desing we oved the parsing logic to Clinets. So we need stream to live as long as the ABFSRestOperation object is alive.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:13:23.827+0000", "updated": "2025-03-26T11:13:23.827+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938551", "id": "17938551", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013931246\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -374,63 +380,68 @@ public AbfsRestOperation listPath(final String relativePath, final boolean recur\n         requestHeaders);\n \n     op.execute(tracingContext);\n-    // Filter the paths for which no rename redo operation is performed.\n-    fixAtomicEntriesInListResults(op, tracingContext);\n-    if (isEmptyListResults(op.getResult()) && is404CheckRequired) {\n+    ListResponseData listResponseData = parseListPathResults(op.getResult(), uri);\n+    listResponseData.setOp(op);\n+\n+    // Perform Pending Rename Redo Operation on Atomic Rename Paths.\n+    // Crashed HBase log rename recovery can be done by Filesystem.listStatus.\n+    if (tracingContext.getOpType() == FSOperationType.LISTSTATUS\n+        && op.getResult() != null\n+        && op.getResult().getStatusCode() == HTTP_OK) {\n+      retryRenameOnAtomicEntriesInListResults(tracingContext,\n+          listResponseData.getRenamePendingJsonPaths());\n\nReview Comment:\n   Yes, this will be removed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:23:27.884+0000", "updated": "2025-03-26T11:23:27.884+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938552", "id": "17938552", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013934055\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/VersionedFileStatus.java:\n##########\n@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.EtagSource;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * A File status with version info extracted from the etag value returned\n+ * in a LIST or HEAD request.\n+ * The etag is included in the java serialization.\n+ */\n+public class VersionedFileStatus extends FileStatus implements EtagSource {\n+\n+  /**\n+   * The superclass is declared serializable; this subclass can also\n+   * be serialized.\n+   */\n+  private static final long serialVersionUID = -2009013240419749458L;\n+\n+  /**\n+   * The etag of an object.\n+   * Not-final so that serialization via reflection will preserve the value.\n+   */\n+  private String version;\n+\n+  private String encryptionContext;\n+\n+  public VersionedFileStatus(\n+      final String owner, final String group, final FsPermission fsPermission, final boolean hasAcl,\n+      final long length, final boolean isdir, final int blockReplication,\n+      final long blocksize, final long modificationTime, final Path path,\n+      final String version, final String encryptionContext) {\n+    super(length, isdir, blockReplication, blocksize, modificationTime, 0,\n+        fsPermission,\n+        owner,\n+        group,\n+        null,\n+        path,\n+        hasAcl, false, false);\n+\n+    this.version = version;\n+    this.encryptionContext = encryptionContext;\n+  }\n+\n+  /** Compare if this object is equal to another object.\n+   * @param   obj the object to be compared.\n+   * @return  true if two file status has the same path name; false if not.\n+   */\n+  @Override\n+  public boolean equals(Object obj) {\n+    if (!(obj instanceof FileStatus)) {\n+      return false;\n+    }\n+\n+    FileStatus other = (FileStatus) obj;\n+\n+    if (!this.getPath().equals(other.getPath())) {// compare the path\n+      return false;\n+    }\n+\n+    if (other instanceof VersionedFileStatus) {\n+      return this.version.equals(((VersionedFileStatus) other).version);\n+    }\n+\n+    return true;\n+  }\n+\n+  /**\n+   * Returns a hash code value for the object, which is defined as\n+   * the hash code of the path name.\n+   *\n+   * @return  a hash code value for the path name and version\n+   */\n+  @Override\n+  public int hashCode() {\n+    int hash = getPath().hashCode();\n+    hash = 89 * hash + (this.version != null ? this.version.hashCode() : 0);\n\nReview Comment:\n   Not very sure, its a day 0 code just moved it out from Store.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:25:21.100+0000", "updated": "2025-03-26T11:25:21.100+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938553", "id": "17938553", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013935353\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/VersionedFileStatus.java:\n##########\n@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.EtagSource;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * A File status with version info extracted from the etag value returned\n+ * in a LIST or HEAD request.\n+ * The etag is included in the java serialization.\n+ */\n+public class VersionedFileStatus extends FileStatus implements EtagSource {\n\nReview Comment:\n   Added\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1780,19 +1782,19 @@ private Configuration createConfig(String producerQueueSize, String consumerMaxL\n   private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n       boolean isSrcExist, boolean isDstExist, boolean isJsonExist)\n       throws IOException {\n-    Assertions.assertThat(fs.exists(dst))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n-        .isEqualTo(isDstExist);\n     Assertions.assertThat(fs.exists(new Path(src.getParent(), src.getName() + SUFFIX)))\n         .describedAs(\"Renamed Pending Json file should exist.\")\n         .isEqualTo(isJsonExist);\n     Assertions.assertThat(fs.exists(src))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n+        .describedAs(\"Renamed Source directory should exist.\")\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:26:09.869+0000", "updated": "2025-03-26T11:26:09.869+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938554", "id": "17938554", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013935730\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/VersionedFileStatus.java:\n##########\n@@ -0,0 +1,127 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.EtagSource;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * A File status with version info extracted from the etag value returned\n+ * in a LIST or HEAD request.\n+ * The etag is included in the java serialization.\n+ */\n+public class VersionedFileStatus extends FileStatus implements EtagSource {\n+\n+  /**\n+   * The superclass is declared serializable; this subclass can also\n+   * be serialized.\n+   */\n+  private static final long serialVersionUID = -2009013240419749458L;\n+\n+  /**\n+   * The etag of an object.\n+   * Not-final so that serialization via reflection will preserve the value.\n+   */\n+  private String version;\n+\n+  private String encryptionContext;\n+\n+  public VersionedFileStatus(\n+      final String owner, final String group, final FsPermission fsPermission, final boolean hasAcl,\n+      final long length, final boolean isdir, final int blockReplication,\n+      final long blocksize, final long modificationTime, final Path path,\n+      final String version, final String encryptionContext) {\n+    super(length, isdir, blockReplication, blocksize, modificationTime, 0,\n+        fsPermission,\n+        owner,\n+        group,\n+        null,\n+        path,\n+        hasAcl, false, false);\n+\n+    this.version = version;\n+    this.encryptionContext = encryptionContext;\n+  }\n+\n+  /** Compare if this object is equal to another object.\n+   * @param   obj the object to be compared.\n+   * @return  true if two file status has the same path name; false if not.\n+   */\n+  @Override\n+  public boolean equals(Object obj) {\n+    if (!(obj instanceof FileStatus)) {\n+      return false;\n+    }\n+\n+    FileStatus other = (FileStatus) obj;\n+\n+    if (!this.getPath().equals(other.getPath())) {// compare the path\n+      return false;\n+    }\n+\n+    if (other instanceof VersionedFileStatus) {\n+      return this.version.equals(((VersionedFileStatus) other).version);\n+    }\n+\n+    return true;\n+  }\n+\n+  /**\n+   * Returns a hash code value for the object, which is defined as\n+   * the hash code of the path name.\n+   *\n+   * @return  a hash code value for the path name and version\n+   */\n+  @Override\n+  public int hashCode() {\n+    int hash = getPath().hashCode();\n+    hash = 89 * hash + (this.version != null ? this.version.hashCode() : 0);\n+    return hash;\n+  }\n+\n+  /**\n+   * Returns the version of this FileStatus\n+   *\n+   * @return  a string value for the FileStatus version\n+   */\n+  public String getVersion() {\n+    return this.version;\n+  }\n+\n+  @Override\n+  public String getEtag() {\n\nReview Comment:\n   Taken\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java:\n##########\n@@ -668,6 +660,10 @@ protected boolean isConnectionDisconnectedOnError() {\n     return connectionDisconnectedOnError;\n   }\n \n+  protected void setListResultSchema(final ListResultSchema listResultSchema) {\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:26:23.813+0000", "updated": "2025-03-26T11:26:23.813+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938555", "id": "17938555", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013937192\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -1464,20 +1472,41 @@ public Hashtable<String, String> getXMSProperties(AbfsHttpOperation result)\n \n   /**\n    * Parse the list file response from DFS ListPath API in Json format\n-   * @param stream InputStream contains the list results.\n-   * @throws IOException if parsing fails.\n+   * @param result InputStream contains the list results.\n+   * @param uri to be used for path conversion.\n+   * @return {@link ListResponseData}. containing listing response.\n+   * @throws AzureBlobFileSystemException if parsing fails.\n    */\n   @Override\n-  public ListResultSchema parseListPathResults(final InputStream stream) throws IOException {\n-    DfsListResultSchema listResultSchema;\n-    try {\n-      final ObjectMapper objectMapper = new ObjectMapper();\n-      listResultSchema = objectMapper.readValue(stream, DfsListResultSchema.class);\n+  public ListResponseData parseListPathResults(AbfsHttpOperation result, URI uri) throws AzureBlobFileSystemException {\n+    try (InputStream listResultInputStream = result.getListResultStream()) {\n+      DfsListResultSchema listResultSchema;\n+      try {\n+        final ObjectMapper objectMapper = new ObjectMapper();\n+        listResultSchema = objectMapper.readValue(listResultInputStream,\n+            DfsListResultSchema.class);\n+        result.setListResultSchema(listResultSchema);\n+        LOG.debug(\"ListPath listed {} paths with {} as continuation token\",\n+            listResultSchema.paths().size(),\n+            getContinuationFromResponse(result));\n+      } catch (IOException ex) {\n+        throw new AbfsDriverException(ex);\n\nReview Comment:\n   There is catch outside which will log error for this exception as well.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:27:27.228+0000", "updated": "2025-03-26T11:27:27.228+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938556", "id": "17938556", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013937894\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n+      try {\n+        primaryUserGroup = UserGroupInformation.getCurrentUser().getPrimaryGroupName();\n+      } catch (IOException ex) {\n+        LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\n+            getPrimaryUser());\n+        primaryUserGroup = getPrimaryUser();\n+      }\n+    } else {\n+      //Provide a default group name\n+      primaryUserGroup = getPrimaryUser();\n+    }\n+    return primaryUserGroup;\n+  }\n+\n+  private String getPrimaryUser() throws AzureBlobFileSystemException {\n+    try {\n+      return UserGroupInformation.getCurrentUser().getUserName();\n+    } catch (IOException ex) {\n+      throw new AbfsDriverException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Creates a VersionedFileStatus object from the ListResultEntrySchema.\n+   * @param entry ListResultEntrySchema object.\n+   * @param uri to be used for the path conversion.\n+   * @return VersionedFileStatus object.\n+   * @throws AzureBlobFileSystemException if transformation fails.\n+   */\n+  protected VersionedFileStatus getVersionedFileStatusFromEntry(\n+      ListResultEntrySchema entry, URI uri) throws AzureBlobFileSystemException {\n+    long blockSize = abfsConfiguration.getAzureBlockSize();\n+    final String owner, group;\n+    try{\n+      if (identityTransformer != null) {\n+        owner = identityTransformer.transformIdentityForGetRequest(\n+            entry.owner(), true, getPrimaryUser());\n+        group = identityTransformer.transformIdentityForGetRequest(\n+            entry.group(), false, getPrimaryUserGroup());\n+      } else {\n+        owner = null;\n+        group = null;\n+      }\n+    } catch (IOException ex) {\n+      LOG.error(\"Failed to get owner/group for path {}\", entry.name(), ex);\n+      throw new AbfsDriverException(ex);\n+    }\n+    final String encryptionContext = entry.getXMsEncryptionContext();\n\nReview Comment:\n   It will always be non-null value.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:27:58.860+0000", "updated": "2025-03-26T11:27:58.860+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938557", "id": "17938557", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013939076\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n+      try {\n+        primaryUserGroup = UserGroupInformation.getCurrentUser().getPrimaryGroupName();\n+      } catch (IOException ex) {\n+        LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\n+            getPrimaryUser());\n+        primaryUserGroup = getPrimaryUser();\n+      }\n+    } else {\n+      //Provide a default group name\n+      primaryUserGroup = getPrimaryUser();\n+    }\n+    return primaryUserGroup;\n+  }\n+\n+  private String getPrimaryUser() throws AzureBlobFileSystemException {\n+    try {\n+      return UserGroupInformation.getCurrentUser().getUserName();\n+    } catch (IOException ex) {\n+      throw new AbfsDriverException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Creates a VersionedFileStatus object from the ListResultEntrySchema.\n+   * @param entry ListResultEntrySchema object.\n+   * @param uri to be used for the path conversion.\n+   * @return VersionedFileStatus object.\n+   * @throws AzureBlobFileSystemException if transformation fails.\n+   */\n+  protected VersionedFileStatus getVersionedFileStatusFromEntry(\n+      ListResultEntrySchema entry, URI uri) throws AzureBlobFileSystemException {\n+    long blockSize = abfsConfiguration.getAzureBlockSize();\n+    final String owner, group;\n+    try{\n+      if (identityTransformer != null) {\n+        owner = identityTransformer.transformIdentityForGetRequest(\n+            entry.owner(), true, getPrimaryUser());\n+        group = identityTransformer.transformIdentityForGetRequest(\n+            entry.group(), false, getPrimaryUserGroup());\n+      } else {\n+        owner = null;\n\nReview Comment:\n   Makes sense.\r\n   Removed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:28:48.723+0000", "updated": "2025-03-26T11:28:48.723+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938560", "id": "17938560", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013943436\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n\nReview Comment:\n   Good Suggestion\r\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:31:53.342+0000", "updated": "2025-03-26T11:31:53.342+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938561", "id": "17938561", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013943423\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -285,6 +298,18 @@ private AbfsClient(final URL baseUrl,\n           metricIdlePeriod);\n     }\n     this.abfsMetricUrl = abfsConfiguration.getMetricUri();\n+\n+    final Class<? extends IdentityTransformerInterface> identityTransformerClass =\n\nReview Comment:\n   what is this change for identity transformer related to ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:31:54.208+0000", "updated": "2025-03-26T11:31:54.208+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938563", "id": "17938563", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013944402\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n\nReview Comment:\n   javadocs\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:32:33.975+0000", "updated": "2025-03-26T11:32:33.975+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938564", "id": "17938564", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013944995\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n\nReview Comment:\n   can name be shortened\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:33:03.253+0000", "updated": "2025-03-26T11:33:03.253+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938565", "id": "17938565", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013945474\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n+      try {\n+        primaryUserGroup = UserGroupInformation.getCurrentUser().getPrimaryGroupName();\n+      } catch (IOException ex) {\n+        LOG.error(\"Failed to get primary group for {}, using user name as primary group name\",\n+            getPrimaryUser());\n+        primaryUserGroup = getPrimaryUser();\n+      }\n+    } else {\n+      //Provide a default group name\n+      primaryUserGroup = getPrimaryUser();\n+    }\n+    return primaryUserGroup;\n+  }\n+\n+  private String getPrimaryUser() throws AzureBlobFileSystemException {\n\nReview Comment:\n   Added\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:33:24.001+0000", "updated": "2025-03-26T11:33:24.001+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938566", "id": "17938566", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013947755\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -285,6 +298,18 @@ private AbfsClient(final URL baseUrl,\n           metricIdlePeriod);\n     }\n     this.abfsMetricUrl = abfsConfiguration.getMetricUri();\n+\n+    final Class<? extends IdentityTransformerInterface> identityTransformerClass =\n+        abfsConfiguration.getRawConfiguration().getClass(FS_AZURE_IDENTITY_TRANSFORM_CLASS, IdentityTransformer.class,\n+            IdentityTransformerInterface.class);\n+    try {\n+      this.identityTransformer =\n+          identityTransformerClass.getConstructor(Configuration.class).newInstance(abfsConfiguration.getRawConfiguration());\n+    } catch (IllegalAccessException | InstantiationException | IllegalArgumentException\n+             | InvocationTargetException | NoSuchMethodException e) {\n+      throw new IOException(e);\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:35:00.322+0000", "updated": "2025-03-26T11:35:00.322+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938567", "id": "17938567", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013911075\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation;\n+\n+/**\n+ * This class is used to hold the response data for list operations.\n+ * It contains a list of FileStatus objects, a map of rename pending JSON paths,\n+ * continuation token and the executed REST operation.\n+ */\n+public class ListResponseData {\n+\n+  private List<FileStatus> fileStatusList;\n+  private Map<Path, Integer> renamePendingJsonPaths;\n\nReview Comment:\n   I think its a good suggestion to keep it long only. Everywhere we parse content lenght as long only.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:35:13.221+0000", "updated": "2025-03-26T11:35:13.221+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938569", "id": "17938569", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013951578\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -1464,20 +1472,41 @@ public Hashtable<String, String> getXMSProperties(AbfsHttpOperation result)\n \n   /**\n    * Parse the list file response from DFS ListPath API in Json format\n-   * @param stream InputStream contains the list results.\n-   * @throws IOException if parsing fails.\n+   * @param result InputStream contains the list results.\n+   * @param uri to be used for path conversion.\n+   * @return {@link ListResponseData}. containing listing response.\n+   * @throws AzureBlobFileSystemException if parsing fails.\n    */\n   @Override\n-  public ListResultSchema parseListPathResults(final InputStream stream) throws IOException {\n-    DfsListResultSchema listResultSchema;\n-    try {\n-      final ObjectMapper objectMapper = new ObjectMapper();\n-      listResultSchema = objectMapper.readValue(stream, DfsListResultSchema.class);\n+  public ListResponseData parseListPathResults(AbfsHttpOperation result, URI uri) throws AzureBlobFileSystemException {\n+    try (InputStream listResultInputStream = result.getListResultStream()) {\n+      DfsListResultSchema listResultSchema;\n+      try {\n+        final ObjectMapper objectMapper = new ObjectMapper();\n+        listResultSchema = objectMapper.readValue(listResultInputStream,\n+            DfsListResultSchema.class);\n+        result.setListResultSchema(listResultSchema);\n+        LOG.debug(\"ListPath listed {} paths with {} as continuation token\",\n+            listResultSchema.paths().size(),\n+            getContinuationFromResponse(result));\n+      } catch (IOException ex) {\n+        throw new AbfsDriverException(ex);\n+      }\n+\n+      List<FileStatus> fileStatuses = new ArrayList<>();\n+      for (DfsListResultEntrySchema entry : listResultSchema.paths()) {\n+        fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n+      }\n+      ListResponseData listResponseData = new ListResponseData();\n+      listResponseData.setFileStatusList(fileStatuses);\n+      listResponseData.setRenamePendingJsonPaths(null);\n+      listResponseData.setContinuationToken(\n+          getContinuationFromResponse(result));\n+      return listResponseData;\n     } catch (IOException ex) {\n       LOG.error(\"Unable to deserialize list results\", ex);\n\nReview Comment:\n   Add the uri as well in the exception message\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:37:44.110+0000", "updated": "2025-03-26T11:37:44.110+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938571", "id": "17938571", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013955480\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java:\n##########\n@@ -383,7 +388,8 @@ final void parseResponse(final byte[] buffer,\n       // consume the input stream to release resources\n       int totalBytesRead = 0;\n \n-      try (InputStream stream = getContentInputStream()) {\n+      try {\n\nReview Comment:\n   try with resources was ensuring stream is closed, is that not needed now ?\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:40:19.177+0000", "updated": "2025-03-26T11:40:19.177+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938573", "id": "17938573", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013968726\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatus.java:\n##########\n@@ -343,4 +319,174 @@ public void testRenameTrailingPeriodFile() throws IOException {\n     assertTrue(\"Attempt to create file that ended with a dot should\"\n         + \" throw IllegalArgumentException\", exceptionThrown);\n   }\n+\n+\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status all types\n+   * of paths viz. implicit, explicit, file.\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusWithImplicitExplicitChildren() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    Path root = new Path(ROOT_PATH);\n+\n+    // Create an implicit directory under root\n+    Path dir = new Path(\"a\");\n+    Path fileInsideDir = new Path(\"a/file\");\n+    createAzCopyFolder(dir);\n+\n+    // Assert that implicit directory is returned\n+    FileStatus[] fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertImplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a marker blob for the directory.\n+    fs.create(fileInsideDir);\n+\n+    // Assert that only one entry of explicit directory is returned\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a file under root\n+    Path file1 = new Path(\"b\");\n+    fs.create(file1);\n+\n+    // Assert that two entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(2);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+\n+    // Create another implicit directory under root.\n+    Path dir2 = new Path(\"c\");\n+    createAzCopyFolder(dir2);\n+\n+    // Assert that three entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(3);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+    assertImplicitDirectoryFileStatus(fileStatuses[2], fs.makeQualified(dir2));\n+  }\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status when called on an implicit path\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusOnImplicitDirectoryPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path implicitPath = new Path(\"/implicitDir\");\n+    createAzCopyFolder(implicitPath);\n+\n+    FileStatus[] statuses = fs.listStatus(implicitPath);\n+    Assertions.assertThat(statuses.length).isGreaterThanOrEqualTo(1);\n+    assertImplicitDirectoryFileStatus(statuses[0], fs.makeQualified(statuses[0].getPath()));\n+\n+    FileStatus[] statuses1 = fs.listStatus(new Path(statuses[0].getPath().toString()));\n+    Assertions.assertThat(statuses1.length).isGreaterThanOrEqualTo(1);\n+    assertFileFileStatus(statuses1[0], fs.makeQualified(statuses1[0].getPath()));\n+  }\n+\n+  @Test\n+  public void testListStatusOnEmptyDirectory() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path emptyDir = new Path(\"/emptyDir\");\n+    fs.mkdirs(emptyDir);\n+\n+    FileStatus[] statuses = fs.listStatus(emptyDir);\n+    Assertions.assertThat(statuses.length).isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testContinuationTokenAcrossListStatus() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    fs.listStatus(path);\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, null, getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+\n+    ListResponseData listResponseData1 =  fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, listResponseData.getContinuationToken(), getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData1.getContinuationToken()).isNull();\n+    Assertions.assertThat(listResponseData1.getFileStatusList()).hasSize(1);\n+  }\n+\n+  @Test\n+  public void testInvalidContinuationToken() throws Exception {\n+    assumeHnsDisabled();\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    intercept(AbfsRestOperationException.class,\n+        () -> fs.getAbfsStore().getClient().listPath(\n+            \"/testInvalidContinuationToken\", false, 1, \"invalidToken\",\n+            getTestTracingContext(fs, true), fs.getAbfsStore().getUri()));\n+  }\n+\n+  @Test\n+  public void testEmptyContinuationToken() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testInvalidContinuationToken\", false, 1, \"\",\n+        getTestTracingContext(fs, true), fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+  }\n+\n+  private void assertFileFileStatus(final FileStatus fileStatus,\n\nReview Comment:\n   typo in name\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:49:49.003+0000", "updated": "2025-03-26T11:49:49.003+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938574", "id": "17938574", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013970360\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatus.java:\n##########\n@@ -343,4 +319,174 @@ public void testRenameTrailingPeriodFile() throws IOException {\n     assertTrue(\"Attempt to create file that ended with a dot should\"\n         + \" throw IllegalArgumentException\", exceptionThrown);\n   }\n+\n+\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status all types\n+   * of paths viz. implicit, explicit, file.\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusWithImplicitExplicitChildren() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    Path root = new Path(ROOT_PATH);\n+\n+    // Create an implicit directory under root\n+    Path dir = new Path(\"a\");\n+    Path fileInsideDir = new Path(\"a/file\");\n+    createAzCopyFolder(dir);\n+\n+    // Assert that implicit directory is returned\n+    FileStatus[] fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertImplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a marker blob for the directory.\n+    fs.create(fileInsideDir);\n+\n+    // Assert that only one entry of explicit directory is returned\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a file under root\n+    Path file1 = new Path(\"b\");\n+    fs.create(file1);\n+\n+    // Assert that two entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(2);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+\n+    // Create another implicit directory under root.\n+    Path dir2 = new Path(\"c\");\n+    createAzCopyFolder(dir2);\n+\n+    // Assert that three entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(3);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+    assertImplicitDirectoryFileStatus(fileStatuses[2], fs.makeQualified(dir2));\n+  }\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status when called on an implicit path\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusOnImplicitDirectoryPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path implicitPath = new Path(\"/implicitDir\");\n+    createAzCopyFolder(implicitPath);\n+\n+    FileStatus[] statuses = fs.listStatus(implicitPath);\n+    Assertions.assertThat(statuses.length).isGreaterThanOrEqualTo(1);\n+    assertImplicitDirectoryFileStatus(statuses[0], fs.makeQualified(statuses[0].getPath()));\n+\n+    FileStatus[] statuses1 = fs.listStatus(new Path(statuses[0].getPath().toString()));\n+    Assertions.assertThat(statuses1.length).isGreaterThanOrEqualTo(1);\n+    assertFileFileStatus(statuses1[0], fs.makeQualified(statuses1[0].getPath()));\n+  }\n+\n+  @Test\n+  public void testListStatusOnEmptyDirectory() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path emptyDir = new Path(\"/emptyDir\");\n+    fs.mkdirs(emptyDir);\n+\n+    FileStatus[] statuses = fs.listStatus(emptyDir);\n+    Assertions.assertThat(statuses.length).isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testContinuationTokenAcrossListStatus() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    fs.listStatus(path);\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, null, getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+\n+    ListResponseData listResponseData1 =  fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, listResponseData.getContinuationToken(), getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData1.getContinuationToken()).isNull();\n+    Assertions.assertThat(listResponseData1.getFileStatusList()).hasSize(1);\n+  }\n+\n+  @Test\n+  public void testInvalidContinuationToken() throws Exception {\n+    assumeHnsDisabled();\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    intercept(AbfsRestOperationException.class,\n+        () -> fs.getAbfsStore().getClient().listPath(\n+            \"/testInvalidContinuationToken\", false, 1, \"invalidToken\",\n+            getTestTracingContext(fs, true), fs.getAbfsStore().getUri()));\n+  }\n+\n+  @Test\n+  public void testEmptyContinuationToken() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testInvalidContinuationToken\", false, 1, \"\",\n+        getTestTracingContext(fs, true), fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+  }\n+\n+  private void assertFileFileStatus(final FileStatus fileStatus,\n+      final Path qualifiedPath) {\n+    Assertions.assertThat(fileStatus.getPath()).isEqualTo(qualifiedPath);\n+    Assertions.assertThat(fileStatus.isFile()).isEqualTo(true);\n+    Assertions.assertThat(fileStatus.isDirectory()).isEqualTo(false);\n+    Assertions.assertThat(fileStatus.getModificationTime()).isNotEqualTo(0);\n+  }\n+\n+  private void assertImplicitDirectoryFileStatus(final FileStatus fileStatus,\n+      final Path qualifiedPath) throws Exception {\n+    assertDirectoryFileStatus(fileStatus, qualifiedPath);\n+    DirectoryStateHelper.isImplicitDirectory(qualifiedPath, getFileSystem(),\n+        getTestTracingContext(getFileSystem(), true));\n+    Assertions.assertThat(fileStatus.getModificationTime()).isEqualTo(0);\n\nReview Comment:\n   Assertion statements are missing for all tests\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:50:59.456+0000", "updated": "2025-03-26T11:50:59.456+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938575", "id": "17938575", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2013976701\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1780,19 +1782,19 @@ private Configuration createConfig(String producerQueueSize, String consumerMaxL\n   private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n       boolean isSrcExist, boolean isDstExist, boolean isJsonExist)\n       throws IOException {\n-    Assertions.assertThat(fs.exists(dst))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n-        .isEqualTo(isDstExist);\n     Assertions.assertThat(fs.exists(new Path(src.getParent(), src.getName() + SUFFIX)))\n         .describedAs(\"Renamed Pending Json file should exist.\")\n         .isEqualTo(isJsonExist);\n     Assertions.assertThat(fs.exists(src))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n+        .describedAs(\"Renamed Source directory should exist.\")\n         .isEqualTo(isSrcExist);\n+    Assertions.assertThat(fs.exists(dst))\n+        .describedAs(\"Renamed Destination directory should exist.\")\n+        .isEqualTo(isDstExist);\n   }\n \n   /**\n-   * Test the renaming of a directory with different parallelism configurations.\n+   * Test the renaming of a directory with different parallelism configurations.c\n\nReview Comment:\n   typo\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T11:54:34.556+0000", "updated": "2025-03-26T11:54:34.556+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938581", "id": "17938581", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014006565\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n\nReview Comment:\n   Moved to service\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:08:04.878+0000", "updated": "2025-03-26T12:08:04.878+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938582", "id": "17938582", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014009551\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/ListResponseData.java:\n##########\n@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.contracts.services;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsRestOperation;\n+\n+/**\n+ * This class is used to hold the response data for list operations.\n+ * It contains a list of FileStatus objects, a map of rename pending JSON paths,\n+ * continuation token and the executed REST operation.\n+ */\n+public class ListResponseData {\n+\n+  private List<FileStatus> fileStatusList;\n+  private Map<Path, Integer> renamePendingJsonPaths;\n\nReview Comment:\n   Rename Atomicity anyway accepts an integer only, that's why kept as integer\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:09:39.920+0000", "updated": "2025-03-26T12:09:39.920+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938583", "id": "17938583", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014012422\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -285,6 +298,18 @@ private AbfsClient(final URL baseUrl,\n           metricIdlePeriod);\n     }\n     this.abfsMetricUrl = abfsConfiguration.getMetricUri();\n+\n+    final Class<? extends IdentityTransformerInterface> identityTransformerClass =\n\nReview Comment:\n   Earlier identity transformation used to happen in Store. Just moved it to client.\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:11:09.944+0000", "updated": "2025-03-26T12:11:09.944+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938584", "id": "17938584", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014013003\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java:\n##########\n@@ -1753,4 +1772,87 @@ protected AbfsRestOperation getSuccessOp(final AbfsRestOperationType operationTy\n     successOp.hardSetResult(HttpURLConnection.HTTP_OK);\n     return successOp;\n   }\n+\n+  private String getPrimaryUserGroup() throws AzureBlobFileSystemException {\n+    String primaryUserGroup;\n+    if (!getAbfsConfiguration().getSkipUserGroupMetadataDuringInitialization()) {\n\nReview Comment:\n   Taken as per Manish's suggestions above\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:11:29.942+0000", "updated": "2025-03-26T12:11:29.942+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938585", "id": "17938585", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014014171\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsDfsClient.java:\n##########\n@@ -1464,20 +1472,41 @@ public Hashtable<String, String> getXMSProperties(AbfsHttpOperation result)\n \n   /**\n    * Parse the list file response from DFS ListPath API in Json format\n-   * @param stream InputStream contains the list results.\n-   * @throws IOException if parsing fails.\n+   * @param result InputStream contains the list results.\n+   * @param uri to be used for path conversion.\n+   * @return {@link ListResponseData}. containing listing response.\n+   * @throws AzureBlobFileSystemException if parsing fails.\n    */\n   @Override\n-  public ListResultSchema parseListPathResults(final InputStream stream) throws IOException {\n-    DfsListResultSchema listResultSchema;\n-    try {\n-      final ObjectMapper objectMapper = new ObjectMapper();\n-      listResultSchema = objectMapper.readValue(stream, DfsListResultSchema.class);\n+  public ListResponseData parseListPathResults(AbfsHttpOperation result, URI uri) throws AzureBlobFileSystemException {\n+    try (InputStream listResultInputStream = result.getListResultStream()) {\n+      DfsListResultSchema listResultSchema;\n+      try {\n+        final ObjectMapper objectMapper = new ObjectMapper();\n+        listResultSchema = objectMapper.readValue(listResultInputStream,\n+            DfsListResultSchema.class);\n+        result.setListResultSchema(listResultSchema);\n+        LOG.debug(\"ListPath listed {} paths with {} as continuation token\",\n+            listResultSchema.paths().size(),\n+            getContinuationFromResponse(result));\n+      } catch (IOException ex) {\n+        throw new AbfsDriverException(ex);\n+      }\n+\n+      List<FileStatus> fileStatuses = new ArrayList<>();\n+      for (DfsListResultEntrySchema entry : listResultSchema.paths()) {\n+        fileStatuses.add(getVersionedFileStatusFromEntry(entry, uri));\n+      }\n+      ListResponseData listResponseData = new ListResponseData();\n+      listResponseData.setFileStatusList(fileStatuses);\n+      listResponseData.setRenamePendingJsonPaths(null);\n+      listResponseData.setContinuationToken(\n+          getContinuationFromResponse(result));\n+      return listResponseData;\n     } catch (IOException ex) {\n       LOG.error(\"Unable to deserialize list results\", ex);\n\nReview Comment:\n   Taken\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:12:14.959+0000", "updated": "2025-03-26T12:12:14.959+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938586", "id": "17938586", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014014817\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java:\n##########\n@@ -383,7 +388,8 @@ final void parseResponse(final byte[] buffer,\n       // consume the input stream to release resources\n       int totalBytesRead = 0;\n \n-      try (InputStream stream = getContentInputStream()) {\n+      try {\n\nReview Comment:\n   Its still there but inside respective clients\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:12:39.982+0000", "updated": "2025-03-26T12:12:39.982+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938587", "id": "17938587", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014016042\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatus.java:\n##########\n@@ -343,4 +319,174 @@ public void testRenameTrailingPeriodFile() throws IOException {\n     assertTrue(\"Attempt to create file that ended with a dot should\"\n         + \" throw IllegalArgumentException\", exceptionThrown);\n   }\n+\n+\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status all types\n+   * of paths viz. implicit, explicit, file.\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusWithImplicitExplicitChildren() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    Path root = new Path(ROOT_PATH);\n+\n+    // Create an implicit directory under root\n+    Path dir = new Path(\"a\");\n+    Path fileInsideDir = new Path(\"a/file\");\n+    createAzCopyFolder(dir);\n+\n+    // Assert that implicit directory is returned\n+    FileStatus[] fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertImplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a marker blob for the directory.\n+    fs.create(fileInsideDir);\n+\n+    // Assert that only one entry of explicit directory is returned\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a file under root\n+    Path file1 = new Path(\"b\");\n+    fs.create(file1);\n+\n+    // Assert that two entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(2);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+\n+    // Create another implicit directory under root.\n+    Path dir2 = new Path(\"c\");\n+    createAzCopyFolder(dir2);\n+\n+    // Assert that three entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(3);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+    assertImplicitDirectoryFileStatus(fileStatuses[2], fs.makeQualified(dir2));\n+  }\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status when called on an implicit path\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusOnImplicitDirectoryPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path implicitPath = new Path(\"/implicitDir\");\n+    createAzCopyFolder(implicitPath);\n+\n+    FileStatus[] statuses = fs.listStatus(implicitPath);\n+    Assertions.assertThat(statuses.length).isGreaterThanOrEqualTo(1);\n+    assertImplicitDirectoryFileStatus(statuses[0], fs.makeQualified(statuses[0].getPath()));\n+\n+    FileStatus[] statuses1 = fs.listStatus(new Path(statuses[0].getPath().toString()));\n+    Assertions.assertThat(statuses1.length).isGreaterThanOrEqualTo(1);\n+    assertFileFileStatus(statuses1[0], fs.makeQualified(statuses1[0].getPath()));\n+  }\n+\n+  @Test\n+  public void testListStatusOnEmptyDirectory() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path emptyDir = new Path(\"/emptyDir\");\n+    fs.mkdirs(emptyDir);\n+\n+    FileStatus[] statuses = fs.listStatus(emptyDir);\n+    Assertions.assertThat(statuses.length).isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testContinuationTokenAcrossListStatus() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    fs.listStatus(path);\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, null, getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+\n+    ListResponseData listResponseData1 =  fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, listResponseData.getContinuationToken(), getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData1.getContinuationToken()).isNull();\n+    Assertions.assertThat(listResponseData1.getFileStatusList()).hasSize(1);\n+  }\n+\n+  @Test\n+  public void testInvalidContinuationToken() throws Exception {\n+    assumeHnsDisabled();\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    intercept(AbfsRestOperationException.class,\n+        () -> fs.getAbfsStore().getClient().listPath(\n+            \"/testInvalidContinuationToken\", false, 1, \"invalidToken\",\n+            getTestTracingContext(fs, true), fs.getAbfsStore().getUri()));\n+  }\n+\n+  @Test\n+  public void testEmptyContinuationToken() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testInvalidContinuationToken\", false, 1, \"\",\n+        getTestTracingContext(fs, true), fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+  }\n+\n+  private void assertFileFileStatus(final FileStatus fileStatus,\n\nReview Comment:\n   FileStatus is for object and I want to convey here that this File Status denoted a File\r\n   But I can see how it can be confusing though\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:13:29.993+0000", "updated": "2025-03-26T12:13:29.993+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938588", "id": "17938588", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014021214\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsCustomEncryption.java:\n##########\n@@ -301,10 +302,10 @@ private AbfsRestOperation callOperation(AzureBlobFileSystem fs,\n            */\n           FileStatus status = fs.listStatus(testPath)[0];\n           Assertions.assertThat(status)\n\nReview Comment:\n   we can add assertion statement here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:16:50.072+0000", "updated": "2025-03-26T12:16:50.072+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938589", "id": "17938589", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014022080\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsCustomEncryption.java:\n##########\n@@ -301,10 +302,10 @@ private AbfsRestOperation callOperation(AzureBlobFileSystem fs,\n            */\n           FileStatus status = fs.listStatus(testPath)[0];\n           Assertions.assertThat(status)\n-              .isInstanceOf(AzureBlobFileSystemStore.VersionedFileStatus.class);\n+              .isInstanceOf(VersionedFileStatus.class);\n \n           Assertions.assertThat(\n\nReview Comment:\n   we can add assertion statement here\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:17:16.668+0000", "updated": "2025-03-26T12:17:16.668+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938590", "id": "17938590", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014023099\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemRename.java:\n##########\n@@ -1780,19 +1782,19 @@ private Configuration createConfig(String producerQueueSize, String consumerMaxL\n   private void validateRename(AzureBlobFileSystem fs, Path src, Path dst,\n       boolean isSrcExist, boolean isDstExist, boolean isJsonExist)\n       throws IOException {\n-    Assertions.assertThat(fs.exists(dst))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n-        .isEqualTo(isDstExist);\n     Assertions.assertThat(fs.exists(new Path(src.getParent(), src.getName() + SUFFIX)))\n         .describedAs(\"Renamed Pending Json file should exist.\")\n         .isEqualTo(isJsonExist);\n     Assertions.assertThat(fs.exists(src))\n-        .describedAs(\"Renamed Destination directory should exist.\")\n+        .describedAs(\"Renamed Source directory should exist.\")\n         .isEqualTo(isSrcExist);\n+    Assertions.assertThat(fs.exists(dst))\n+        .describedAs(\"Renamed Destination directory should exist.\")\n+        .isEqualTo(isDstExist);\n   }\n \n   /**\n-   * Test the renaming of a directory with different parallelism configurations.\n+   * Test the renaming of a directory with different parallelism configurations.c\n\nReview Comment:\n   Fixed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:17:55.085+0000", "updated": "2025-03-26T12:17:55.085+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938593", "id": "17938593", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "manika137 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014026084\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestListActionTaker.java:\n##########\n@@ -132,10 +136,10 @@ protected void addPaths(final List<Path> paths,\n           occurrences[0]++;\n           Assertions.assertThat((int) answer.getArgument(2))\n\nReview Comment:\n   assertion statement\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:19:40.117+0000", "updated": "2025-03-26T12:19:40.117+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938594", "id": "17938594", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014035695\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsCustomEncryption.java:\n##########\n@@ -301,10 +302,10 @@ private AbfsRestOperation callOperation(AzureBlobFileSystem fs,\n            */\n           FileStatus status = fs.listStatus(testPath)[0];\n           Assertions.assertThat(status)\n\nReview Comment:\n   Added\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsCustomEncryption.java:\n##########\n@@ -301,10 +302,10 @@ private AbfsRestOperation callOperation(AzureBlobFileSystem fs,\n            */\n           FileStatus status = fs.listStatus(testPath)[0];\n           Assertions.assertThat(status)\n-              .isInstanceOf(AzureBlobFileSystemStore.VersionedFileStatus.class);\n+              .isInstanceOf(VersionedFileStatus.class);\n \n           Assertions.assertThat(\n\nReview Comment:\n   Added\n\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestListActionTaker.java:\n##########\n@@ -132,10 +136,10 @@ protected void addPaths(final List<Path> paths,\n           occurrences[0]++;\n           Assertions.assertThat((int) answer.getArgument(2))\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:25:25.386+0000", "updated": "2025-03-26T12:25:25.386+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938595", "id": "17938595", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014036287\n\n\n##########\nhadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatus.java:\n##########\n@@ -343,4 +319,174 @@ public void testRenameTrailingPeriodFile() throws IOException {\n     assertTrue(\"Attempt to create file that ended with a dot should\"\n         + \" throw IllegalArgumentException\", exceptionThrown);\n   }\n+\n+\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status all types\n+   * of paths viz. implicit, explicit, file.\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusWithImplicitExplicitChildren() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.setWorkingDirectory(new Path(ROOT_PATH));\n+    Path root = new Path(ROOT_PATH);\n+\n+    // Create an implicit directory under root\n+    Path dir = new Path(\"a\");\n+    Path fileInsideDir = new Path(\"a/file\");\n+    createAzCopyFolder(dir);\n+\n+    // Assert that implicit directory is returned\n+    FileStatus[] fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertImplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a marker blob for the directory.\n+    fs.create(fileInsideDir);\n+\n+    // Assert that only one entry of explicit directory is returned\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(1);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+\n+    // Create a file under root\n+    Path file1 = new Path(\"b\");\n+    fs.create(file1);\n+\n+    // Assert that two entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(2);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+\n+    // Create another implicit directory under root.\n+    Path dir2 = new Path(\"c\");\n+    createAzCopyFolder(dir2);\n+\n+    // Assert that three entries are returned in alphabetic order.\n+    fileStatuses = fs.listStatus(root);\n+    Assertions.assertThat(fileStatuses.length).isEqualTo(3);\n+    assertExplicitDirectoryFileStatus(fileStatuses[0], fs.makeQualified(dir));\n+    assertFileFileStatus(fileStatuses[1], fs.makeQualified(file1));\n+    assertImplicitDirectoryFileStatus(fileStatuses[2], fs.makeQualified(dir2));\n+  }\n+\n+  /**\n+   * Test to verify that listStatus returns the correct file status when called on an implicit path\n+   * @throws Exception if there is an error or test assertions fails.\n+   */\n+  @Test\n+  public void testListStatusOnImplicitDirectoryPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path implicitPath = new Path(\"/implicitDir\");\n+    createAzCopyFolder(implicitPath);\n+\n+    FileStatus[] statuses = fs.listStatus(implicitPath);\n+    Assertions.assertThat(statuses.length).isGreaterThanOrEqualTo(1);\n+    assertImplicitDirectoryFileStatus(statuses[0], fs.makeQualified(statuses[0].getPath()));\n+\n+    FileStatus[] statuses1 = fs.listStatus(new Path(statuses[0].getPath().toString()));\n+    Assertions.assertThat(statuses1.length).isGreaterThanOrEqualTo(1);\n+    assertFileFileStatus(statuses1[0], fs.makeQualified(statuses1[0].getPath()));\n+  }\n+\n+  @Test\n+  public void testListStatusOnEmptyDirectory() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path emptyDir = new Path(\"/emptyDir\");\n+    fs.mkdirs(emptyDir);\n+\n+    FileStatus[] statuses = fs.listStatus(emptyDir);\n+    Assertions.assertThat(statuses.length).isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testContinuationTokenAcrossListStatus() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    fs.listStatus(path);\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, null, getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+\n+    ListResponseData listResponseData1 =  fs.getAbfsStore().getClient().listPath(\n+        \"/testContinuationToken\", false, 1, listResponseData.getContinuationToken(), getTestTracingContext(fs, true),\n+        fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData1.getContinuationToken()).isNull();\n+    Assertions.assertThat(listResponseData1.getFileStatusList()).hasSize(1);\n+  }\n+\n+  @Test\n+  public void testInvalidContinuationToken() throws Exception {\n+    assumeHnsDisabled();\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    intercept(AbfsRestOperationException.class,\n+        () -> fs.getAbfsStore().getClient().listPath(\n+            \"/testInvalidContinuationToken\", false, 1, \"invalidToken\",\n+            getTestTracingContext(fs, true), fs.getAbfsStore().getUri()));\n+  }\n+\n+  @Test\n+  public void testEmptyContinuationToken() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path path = new Path(\"/testInvalidContinuationToken\");\n+    fs.mkdirs(path);\n+    fs.create(new Path(path + \"/file1\"));\n+    fs.create(new Path(path + \"/file2\"));\n+\n+    ListResponseData listResponseData = fs.getAbfsStore().getClient().listPath(\n+        \"/testInvalidContinuationToken\", false, 1, \"\",\n+        getTestTracingContext(fs, true), fs.getAbfsStore().getUri());\n+\n+    Assertions.assertThat(listResponseData.getContinuationToken()).isNotNull();\n+    Assertions.assertThat(listResponseData.getFileStatusList()).hasSize(1);\n+  }\n+\n+  private void assertFileFileStatus(final FileStatus fileStatus,\n+      final Path qualifiedPath) {\n+    Assertions.assertThat(fileStatus.getPath()).isEqualTo(qualifiedPath);\n+    Assertions.assertThat(fileStatus.isFile()).isEqualTo(true);\n+    Assertions.assertThat(fileStatus.isDirectory()).isEqualTo(false);\n+    Assertions.assertThat(fileStatus.getModificationTime()).isNotEqualTo(0);\n+  }\n+\n+  private void assertImplicitDirectoryFileStatus(final FileStatus fileStatus,\n+      final Path qualifiedPath) throws Exception {\n+    assertDirectoryFileStatus(fileStatus, qualifiedPath);\n+    DirectoryStateHelper.isImplicitDirectory(qualifiedPath, getFileSystem(),\n+        getTestTracingContext(getFileSystem(), true));\n+    Assertions.assertThat(fileStatus.getModificationTime()).isEqualTo(0);\n\nReview Comment:\n   Added\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:25:45.440+0000", "updated": "2025-03-26T12:25:45.440+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938602", "id": "17938602", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014066457\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -404,13 +403,8 @@ public ListResponseData listPath(final String relativePath, final boolean recurs\n       BlobListResultSchema listResultSchema = getListResultSchemaFromPathStatus(relativePath, pathStatus);\n       LOG.debug(\"ListBlob attempted on a file path. Returning file status.\");\n       List<FileStatus> fileStatusList = new ArrayList<>();\n-      Map<Path, Integer> renamePendingJsonPaths = new HashMap<>();\n       for (BlobListResultEntrySchema entry : listResultSchema.paths()) {\n-        if (isRenamePendingJsonPathEntry(entry)) {\n-          renamePendingJsonPaths.put(entry.path(), entry.contentLength().intValue());\n-        } else {\n-          fileStatusList.add(getVersionedFileStatusFromEntry(entry, uri));\n-        }\n+        fileStatusList.add(getVersionedFileStatusFromEntry(entry, uri));\n\nReview Comment:\n   didn't understand why this change to remove renamePending paths was removed\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:45:21.384+0000", "updated": "2025-03-26T12:45:21.384+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938603", "id": "17938603", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anmolanmol1234 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014066457\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -404,13 +403,8 @@ public ListResponseData listPath(final String relativePath, final boolean recurs\n       BlobListResultSchema listResultSchema = getListResultSchemaFromPathStatus(relativePath, pathStatus);\n       LOG.debug(\"ListBlob attempted on a file path. Returning file status.\");\n       List<FileStatus> fileStatusList = new ArrayList<>();\n-      Map<Path, Integer> renamePendingJsonPaths = new HashMap<>();\n       for (BlobListResultEntrySchema entry : listResultSchema.paths()) {\n-        if (isRenamePendingJsonPathEntry(entry)) {\n-          renamePendingJsonPaths.put(entry.path(), entry.contentLength().intValue());\n-        } else {\n-          fileStatusList.add(getVersionedFileStatusFromEntry(entry, uri));\n-        }\n+        fileStatusList.add(getVersionedFileStatusFromEntry(entry, uri));\n\nReview Comment:\n   didn't understand why this change to remove renamePending paths was made\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T12:45:34.722+0000", "updated": "2025-03-26T12:45:34.722+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938616", "id": "17938616", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on code in PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#discussion_r2014192835\n\n\n##########\nhadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsBlobClient.java:\n##########\n@@ -404,13 +403,8 @@ public ListResponseData listPath(final String relativePath, final boolean recurs\n       BlobListResultSchema listResultSchema = getListResultSchemaFromPathStatus(relativePath, pathStatus);\n       LOG.debug(\"ListBlob attempted on a file path. Returning file status.\");\n       List<FileStatus> fileStatusList = new ArrayList<>();\n-      Map<Path, Integer> renamePendingJsonPaths = new HashMap<>();\n       for (BlobListResultEntrySchema entry : listResultSchema.paths()) {\n-        if (isRenamePendingJsonPathEntry(entry)) {\n-          renamePendingJsonPaths.put(entry.path(), entry.contentLength().intValue());\n-        } else {\n-          fileStatusList.add(getVersionedFileStatusFromEntry(entry, uri));\n-        }\n+        fileStatusList.add(getVersionedFileStatusFromEntry(entry, uri));\n\nReview Comment:\n   This is the code path where handling for listStatus on a file path is done. I checked on wasb if the listing is done on a filepath atomicity related checks are not performed and rename redo is not triggered. Keeping same behavior here as well.\n\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T13:49:07.120+0000", "updated": "2025-03-26T13:49:07.120+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938627", "id": "17938627", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2754672693\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |   0m 53s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  1s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ trunk Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  39m 45s |  |  trunk passed  |\r\n   | +1 :green_heart: |  compile  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 36s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 33s |  |  trunk passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 40s |  |  trunk passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 41s |  |  trunk passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 34s |  |  trunk passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  9s |  |  trunk passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 46s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   | -0 :warning: |  patch  |  39m  8s |  |  Used diff version of patch file. Binary files and potentially other changes not applied. Please rebase and squash commits if necessary.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 30s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 33s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 33s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 28s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 28s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 21s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 32s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 29s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 25s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   1m  7s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  38m 54s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   3m  0s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 36s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   | 132m 28s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/12/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7421 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux f5d50c8ccc68 5.15.0-131-generic #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | trunk / 972889915dbb4f9c53162838f56f6bbaeda2431e |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/12/testReport/ |\r\n   | Max. process+thread count | 529 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7421/12/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-26T14:40:25.608+0000", "updated": "2025-03-26T14:40:25.608+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938872", "id": "17938872", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421#issuecomment-2757494851\n\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 796, Failures: 0, Errors: 0, Skipped: 162\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 799, Failures: 0, Errors: 0, Skipped: 131\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 10\r\n    \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 638, Failures: 0, Errors: 0, Skipped: 214\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n    \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 796, Failures: 0, Errors: 0, Skipped: 169\r\n   [WARNING] Tests run: 131, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 641, Failures: 0, Errors: 0, Skipped: 144\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n    \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 635, Failures: 0, Errors: 0, Skipped: 215\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 638, Failures: 0, Errors: 0, Skipped: 145\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n    \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 636, Failures: 0, Errors: 0, Skipped: 163\r\n   [WARNING] Tests run: 131, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n    \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 670, Failures: 0, Errors: 0, Skipped: 165\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n    \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n    \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 11\r\n   [WARNING] Tests run: 635, Failures: 0, Errors: 0, Skipped: 213\r\n   [WARNING] Tests run: 154, Failures: 0, Errors: 0, Skipped: 5\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   Branch: HADOOP-19234_followup, Commit: 972889915dbb4f9c53162838f56f6bbaeda2431e\r\n    \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-27T10:16:04.394+0000", "updated": "2025-03-27T10:16:04.394+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17938874", "id": "17938874", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7421:\nURL: https://github.com/apache/hadoop/pull/7421\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-03-27T10:17:36.521+0000", "updated": "2025-03-27T10:17:36.521+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17940871", "id": "17940871", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 opened a new pull request, #7581:\nURL: https://github.com/apache/hadoop/pull/7581\n\n   ### Description of PR\r\n   On blob endpoint, there are a couple of handling that is needed to be done on client side.\r\n   This involves:\r\n   1. Parsing of xml response and converting them to VersionedFileStatus list\r\n   2. Removing duplicate entries for non-empty explicit directories coming due to presence of the marker files\r\n   3. Trigerring Rename recovery on the previously failed rename indicated by the presence of pending json file.\r\n   \r\n   Currently all three are done in a separate iteration over whole list. This is to pbring all those things to a common place so that single iteration over list reposne can handle all three.\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-04T05:24:27.495+0000", "updated": "2025-04-04T05:24:27.495+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17940882", "id": "17940882", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "hadoop-yetus commented on PR #7581:\nURL: https://github.com/apache/hadoop/pull/7581#issuecomment-2777698196\n\n   :confetti_ball: **+1 overall**\r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   | Vote | Subsystem | Runtime |  Logfile | Comment |\r\n   |:----:|----------:|--------:|:--------:|:-------:|\r\n   | +0 :ok: |  reexec  |  11m 38s |  |  Docker mode activated.  |\r\n   |||| _ Prechecks _ |\r\n   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |\r\n   | +0 :ok: |  codespell  |   0m  0s |  |  codespell was not available.  |\r\n   | +0 :ok: |  detsecrets  |   0m  0s |  |  detect-secrets was not available.  |\r\n   | +0 :ok: |  xmllint  |   0m  0s |  |  xmllint was not available.  |\r\n   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |\r\n   | +1 :green_heart: |  test4tests  |   0m  0s |  |  The patch appears to include 11 new or modified test files.  |\r\n   |||| _ branch-3.4 Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |  22m 28s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  compile  |   0m 25s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  compile  |   0m 22s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 22s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 28s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 27s |  |  branch-3.4 passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 22s |  |  branch-3.4 passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 48s |  |  branch-3.4 passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 13s |  |  branch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Patch Compile Tests _ |\r\n   | +1 :green_heart: |  mvninstall  |   0m 16s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |\r\n   | +1 :green_heart: |  compile  |   0m 15s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  javac  |   0m 15s |  |  the patch passed  |\r\n   | +1 :green_heart: |  blanks  |   0m  0s |  |  The patch has no blanks issues.  |\r\n   | +1 :green_heart: |  checkstyle  |   0m 11s |  |  the patch passed  |\r\n   | +1 :green_heart: |  mvnsite  |   0m 20s |  |  the patch passed  |\r\n   | +1 :green_heart: |  javadoc  |   0m 17s |  |  the patch passed with JDK Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04  |\r\n   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06  |\r\n   | +1 :green_heart: |  spotbugs  |   0m 42s |  |  the patch passed  |\r\n   | +1 :green_heart: |  shadedclient  |  19m 17s |  |  patch has no errors when building and testing our client artifacts.  |\r\n   |||| _ Other Tests _ |\r\n   | +1 :green_heart: |  unit  |   2m 11s |  |  hadoop-azure in the patch passed.  |\r\n   | +1 :green_heart: |  asflicense  |   0m 22s |  |  The patch does not generate ASF License warnings.  |\r\n   |  |   |  81m 56s |  |  |\r\n   \r\n   \r\n   | Subsystem | Report/Notes |\r\n   |----------:|:-------------|\r\n   | Docker | ClientAPI=1.48 ServerAPI=1.48 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7581/1/artifact/out/Dockerfile |\r\n   | GITHUB PR | https://github.com/apache/hadoop/pull/7581 |\r\n   | JIRA Issue | HADOOP-19474 |\r\n   | Optional Tests | dupname asflicense codespell detsecrets xmllint compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle |\r\n   | uname | Linux 9baecf1e5a5d 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux |\r\n   | Build tool | maven |\r\n   | Personality | dev-support/bin/hadoop.sh |\r\n   | git revision | branch-3.4 / 1c97abbeb4007eced8eef6aa0cbb373663e1b13e |\r\n   | Default Java | Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.26+4-post-Ubuntu-1ubuntu120.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_442-8u442-b06~us1-0ubuntu1~20.04-b06 |\r\n   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7581/1/testReport/ |\r\n   | Max. process+thread count | 561 (vs. ulimit of 5500) |\r\n   | modules | C: hadoop-tools/hadoop-azure U: hadoop-tools/hadoop-azure |\r\n   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-7581/1/console |\r\n   | versions | git=2.25.1 maven=3.6.3 spotbugs=4.2.2 |\r\n   | Powered by | Apache Yetus 0.14.0 https://yetus.apache.org |\r\n   \r\n   \r\n   This message was automatically generated.\r\n   \r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-04T06:47:25.316+0000", "updated": "2025-04-04T06:47:25.316+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17941444", "id": "17941444", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 commented on PR #7581:\nURL: https://github.com/apache/hadoop/pull/7581#issuecomment-2781977128\n\n   \r\n   ============================================================\r\n   HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 808, Failures: 0, Errors: 0, Skipped: 171\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 28\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   HNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 4\r\n   [WARNING] Tests run: 808, Failures: 0, Errors: 0, Skipped: 122\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 28\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 10\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 792, Failures: 0, Errors: 0, Skipped: 365\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 29\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   AppendBlob-HNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 808, Failures: 0, Errors: 0, Skipped: 178\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 52\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-SharedKey-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 792, Failures: 0, Errors: 0, Skipped: 292\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 11\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 792, Failures: 0, Errors: 0, Skipped: 369\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 29\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 792, Failures: 0, Errors: 0, Skipped: 296\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 27\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   AppendBlob-NonHNS-OAuth-Blob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 792, Failures: 0, Errors: 0, Skipped: 316\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 51\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \r\n   ============================================================\r\n   HNS-Oauth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 3\r\n   [WARNING] Tests run: 808, Failures: 0, Errors: 0, Skipped: 300\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 28\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 23\r\n   \r\n   ============================================================\r\n   NonHNS-OAuth-DFS-IngressBlob\r\n   ============================================================\r\n   \r\n   [WARNING] Tests run: 174, Failures: 0, Errors: 0, Skipped: 10\r\n   [WARNING] Tests run: 792, Failures: 0, Errors: 0, Skipped: 367\r\n   [WARNING] Tests run: 178, Failures: 0, Errors: 0, Skipped: 29\r\n   [WARNING] Tests run: 272, Failures: 0, Errors: 0, Skipped: 24\r\n   \n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-07T04:18:02.860+0000", "updated": "2025-04-07T04:18:02.860+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13610099/comment/17941445", "id": "17941445", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "body": "anujmodi2021 merged PR #7581:\nURL: https://github.com/apache/hadoop/pull/7581\n\n\n", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot", "name": "githubbot", "key": "githubbot", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "ASF GitHub Bot", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-04-07T04:18:15.949+0000", "updated": "2025-04-07T04:18:15.949+0000"}], "maxResults": 64, "total": 64, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}