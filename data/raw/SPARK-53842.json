{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13631019", "self": "https://issues.apache.org/jira/rest/api/2/issue/13631019", "key": "SPARK-53842", "fields": {"summary": " Enable Filter Push-Down for Pandas UDFs with an Immutable Column Hint", "description": "h3. Problem Description\r\n\r\nPandas UDFs ({{{}mapInPandas{}}}, {{{}applyInPandas{}}}, etc.) are powerful for custom data processing in PySpark. However, they currently act as a black box to the Catalyst Optimizer. This prevents the optimizer from pushing down filters on columns that pass through the UDF unmodified. As a result, filtering operations occur _after_ the expensive UDF execution and associated data shuffling, leading to significant performance degradation.\r\n\r\nThis is especially common in pipelines where transformations are applied to grouped data, and the grouping key itself is not modified within the UDF.\r\n\r\n*Example:*\r\n\r\nConsider the following DataFrame and Pandas UDFs:\r\n{code:java}\r\nimport pandas as pd\r\nfrom typing import Iterator\r\n\r\ndf = spark.createDataFrame(\r\n    [[\"A\", 1], [\"A\", 1], [\"B\", 2]], \r\n    schema=[\"id string\", \"value int\"]\r\n)\r\n\r\n# UDF to modify the 'value' column\r\ndef map_udf(pdfs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\r\n    for pdf in pdfs:\r\n        pdf[\"value\"] = pdf[\"value\"] + 1\r\n        yield pdf\r\n\r\n# UDF to aggregate data by 'id'\r\ndef agg_udf(pdf: pd.DataFrame) -> pd.DataFrame:\r\n    return pdf.groupby(\"id\").agg(count=(\"value\", \"count\"))\r\n\r\n# Apply the UDFs\r\nmodified_df = (\r\n    df\r\n    .mapInPandas(map_udf, schema=\"id string,value int\")\r\n    .groupby(\"id\")\r\n    .applyInPandas(agg_udf, schema=\"id string,count int\")\r\n)\r\n\r\n# Filter the result\r\nmodified_df.where(\"id == 'A'\").explain() {code}\r\nIn this example, the {{id}} column is never modified by either UDF. However, the filter on {{id}} is applied only after all transformations are complete.\r\n\r\n*Current Physical Plan:*\r\n\r\nThe physical plan shows the {{Filter}} operation at the very top, processing data that has already been scanned, shuffled, and processed by both Pandas UDFs.\r\n\r\n\u00a0\r\n\r\n{{}}\r\n{code:java}\r\n== Physical Plan ==\r\nAdaptiveSparkPlan isFinalPlan=false\r\n+- Filter (isnotnull(id#20) AND (id#20 = A))\r\n   +- FlatMapGroupsInPandas [id#13], agg_udf(id#13, value#14)#19, [id#20, count#21]\r\n      +- Sort [id#13 ASC NULLS FIRST], false, 0\r\n         +- Exchange hashpartitioning(id#13, 200), ENSURE_REQUIREMENTS, [plan_id=20]\r\n            +- Project [id#13, id#13, value#14]\r\n               +- MapInPandas map_udf(id string#8, value int#9L)#12, [id#13, value#14], false\r\n                  +- Scan ExistingRDD[id string#8,value int#9L]{code}\r\n{{\u00a0}}\r\n\r\nThis plan processes all data for both {{id = 'A'}} and {{id = 'B'}} through the entire pipeline, even though the data for {{'B'}} is discarded at the end.\r\nh3. Proposed Solution\r\n\r\nWe propose introducing a mechanism to *hint* to the Catalyst Optimizer that specific columns within a Pandas UDF are immutable or pass through without modification. This would allow the optimizer to safely push down filters on these columns.\r\n\r\nThis could be implemented as a new parameter in the UDF registration, for example, {{{}passthrough_cols{}}}:\r\n\r\n\u00a0\r\n\r\n{{}}\r\n{code:java}\r\n# Proposed API modification\r\nmodified_df = (\r\n    df\r\n    .mapInPandas(\r\n        map_udf, \r\n        schema=\"id string,value int\",\r\n        passthrough_cols=[\"id\"]  # New hint parameter\r\n    )\r\n    .groupby(\"id\")\r\n    .applyInPandas(\r\n        agg_udf, \r\n        schema=\"id string,count int\",\r\n        passthrough_cols=[\"id\"]  # New hint parameter\r\n    )\r\n)\r\n{code}\r\n{{\u00a0}}\r\n\r\nWith this hint, the optimizer could transform the physical plan to apply the filter at the data source, _before_ any expensive operations.\r\n\r\n*Desired Physical Plan:*\r\n\r\n\u00a0\r\n\r\n{{}}\r\n{code:java}\r\n== Desired Physical Plan ==\r\nAdaptiveSparkPlan isFinalPlan=false\r\n+- FlatMapGroupsInPandas [id#13], agg_udf(id#13, value#14)#19, [id#20, count#21]\r\n   +- Sort [id#13 ASC NULLS FIRST], false, 0\r\n      +- Exchange hashpartitioning(id#13, 200), ENSURE_REQUIREMENTS, [plan_id=20]\r\n         +- Project [id#13, id#13, value#14]\r\n            +- MapInPandas map_udf(id string#8, value int#9L)#12, [id#13, value#14], false\r\n               +- Filter (isnotnull(id#8) AND (id#8 = A))  // <-- FILTER PUSHED DOWN\r\n                  +- Scan ExistingRDD[id string#8,value int#9L]]{code}\r\n{{\u00a0}}\r\n\r\nThis optimized plan would significantly reduce the amount of data sent to the UDFs and shuffled across the network, resulting in major performance improvements.\r\nh3. Motivation & Justification\r\n # *Performance:* In large-scale data processing pipelines, filtering data early is one of the most effective optimization strategies. Enabling filter push-down for Pandas UDFs would unlock substantial performance gains, reducing I/O, network traffic, and computational load.\r\n\r\n # *Common Use Case:* Developers often know with certainty that grouping keys or other identifier columns are not modified within their UDFs. The proposed hint provides a direct means of communicating this domain knowledge to the optimizer.\r\n\r\n # *Usability:* This feature would empower developers to optimize their pipelines in scenarios where they cannot change an incoming plan and can only apply transformations to a given DataFrame.\r\n\r\nh3. Optional: Runtime Validation\r\n\r\nTo safeguard against incorrect usage of the hint, Spark could optionally perform a runtime validation. This check would verify that the values in the columns marked as {{passthrough_cols}} are indeed unchanged between the input and output of the UDF. If a discrepancy is found (e.g., a value in the output {{id}} column did not exist in the input {{id}} column for that batch), Spark could raise an exception. While not entirely foolproof, this would cover most grouping and mapping use cases and prevent subtle bugs.", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=lioritzhak", "name": "lioritzhak", "key": "JIRAUSER311106", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"}, "displayName": "Lior Itzhak", "active": true, "timeZone": "Etc/UTC"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13631019/comment/18029184", "id": "18029184", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=juklein", "name": "juklein", "key": "JIRAUSER311102", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=JIRAUSER311102&avatarId=54523", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=JIRAUSER311102&avatarId=54523", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=JIRAUSER311102&avatarId=54523", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=JIRAUSER311102&avatarId=54523"}, "displayName": "Julian Klein", "active": true, "timeZone": "Europe/Berlin"}, "body": "Hi [~lioritzhak] ,\r\n\r\nI would _love_ to work on this, because I am super excited about query optimization and want to get my feet wet working on Spark. Since this would be my first issue for Spark, I might have questions during the process, though.\r\nI do have another thing to work on first, AND I'll have to setup my dev eivironment for Spark first (which might take some time). All in all, I might take 2 to 3 weeks for setting this up and getting ready, I'd guess (subject to change!).\r\nIf that does not sound too off-putting, feel free to assign this to me. I'd be super excited to do this!\r\n\r\nBest,\r\nJulian", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=juklein", "name": "juklein", "key": "JIRAUSER311102", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=JIRAUSER311102&avatarId=54523", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=JIRAUSER311102&avatarId=54523", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=JIRAUSER311102&avatarId=54523", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=JIRAUSER311102&avatarId=54523"}, "displayName": "Julian Klein", "active": true, "timeZone": "Europe/Berlin"}, "created": "2025-10-11T09:26:56.768+0000", "updated": "2025-10-11T10:34:28.975+0000"}], "maxResults": 1, "total": 1, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}