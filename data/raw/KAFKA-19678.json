{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13628249", "self": "https://issues.apache.org/jira/rest/api/2/issue/13628249", "key": "KAFKA-19678", "fields": {"summary": "Streams open iterator tracking has high contention on metrics lock", "description": "We run Kafka Streams 4.1.0 with custom processors that heavily use state store range iterators.\r\n\r\nWhile investigating disappointing performance, we found a surprising source of lock contention.\r\n\r\nOver the course of about a 1 minute profiler sample, the {{org.apache.kafka.common.metrics.Metrics}} lock is taken approximately 40,000 times and blocks threads for about 1 minute.\r\n\r\nThis appears to be because our state stores generally have no iterators open, except when their processor is processing a record, in which case it opens an iterator (taking the lock through {{OpenIterators.add}} into {{{}Metrics.registerMetric{}}}), does a tiny bit of work, and then closes the iterator (again taking the lock through {{OpenIterators.remove}} into {{{}Metrics.removeMetric{}}}).\r\n\r\nSo, stream processing threads takes a globally shared lock twice per record, for this subset of our data. I've attached a profiler thread state visualization with our findings - the red bar indicates the thread was blocked during the sample on this lock. As you can see, this lock seems to be severely hampering our performance.\r\n\r\n\u00a0\r\n\r\n!image-2025-09-05-12-13-24-910.png!", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18028890", "id": "18028890", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Thanks for reporting this issue. \u2013 I am wondering what your application is doing exactly, and if it might be possible to avoid creating an iterator per record?\r\n\r\nOne hacky work-around I could think of, would be to create a \"dummy iterator\", so you always have at least one-open iterators, and the metric won't be removed/added over and over again?", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-09T23:54:34.472+0000", "updated": "2025-10-09T23:54:34.472+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18029580", "id": "18029580", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Thanks [~mjsax] for taking a look.\r\n\r\nWe have a product requirement to compute a streaming-min and streaming-max operation over a grouped aggregate. For example, \"earliest record due date for each user\" or \"latest record created date for each user\".\r\n\r\nTo do this, we take the input stream,\r\n{code:java}\r\nK1 = U1 V1\r\nK2 = U1 V2\r\nK3 = U2 V3\r\nK4 = U2 V4 {code}\r\nand reorganize the records so the group-key and value are the key prefix, like\r\n{code:java}\r\nU1 V1 K1 = K1\r\nU1 V2 K2 = K2\r\nU2 V3 K3 = K3\r\nU2 V4 K4 = K4{code}\r\nand put it in a state store. Then, to determine the minimum or maximum, we do a prefix range scan to take the first or last record for the group U1 or U2.\r\n\r\nIt might be possible to reduce the number of range scans by caching the minimum and maximum values by key, to know if the max or min possibly changed and skip the iterator if not, but then we need a second state store duplicating the winning record per user. We assumed the cost of opening an iterator is roughly equal to the cost of a key lookup, but maybe this is not a good assumption.\r\n\r\nRegardless, to me, the current semantics for this metric seems wrong. If the store is open, with no iterators currently, the correct value for the metric is explicitly \"0\" not \"null / unregister\". The current setup makes it difficult to graph, since our dashboards will interpret \"null\" as \"missing data\" which is distinct from a present 0.\r\n\r\nI would expect the metric to be unregistered only when the state store is closed or otherwise we are sure no new iterators will ever be created.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-13T18:02:07.784+0000", "updated": "2025-10-13T18:02:07.784+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18029604", "id": "18029604", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "body": "This metric is a little bit tricky... (for context [KIP-989|https://cwiki.apache.org/confluence/display/KAFKA/KIP-989%3A+Improved+StateStore+Iterator+metrics+for+detecting+leaks]) \u2013 if we would report `0` (or `-1`), the issue is, that if you setup an alert that computes \"currentTime minus metricValue\" you get false-positives, as the iterator open time computation would report a high value (many years). Your alert would need to be conditional, what is a struggle as far as I know. While a dashboard can render `0` it would blow out your \"y-axis\" on the dashboard to a very high value, too, and it seems it would make it very hard to actually read the dashboard?\r\n\r\nWe actually reported `null` originally, but this also caused issues: https://issues.apache.org/jira/browse/KAFKA-17954 \u2013 so we decided to de-register the metric when it becomes empty.\r\n{quote}\u00a0otherwise we are sure no new iterators will ever be created.\r\n{quote}\r\nNot sure what you mean by this?\r\n\r\nFor your use case: how many values per group do you get? Would it be possible to do an `aggregation` per group, and compute a `List` over all values per group? This would allow you to maintain this list with a key-lookup per update, avoiding a range scan (of course, this only works if the list is small enough, to avoid too large records...)", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-13T20:14:38.434+0000", "updated": "2025-10-13T20:14:38.434+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18029605", "id": "18029605", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Thanks for the context, this does sound tricky :(\r\n\r\nUnfortunately, some degenerate groups can have upwards of 0.5M entries (of at least 16 bytes each), so I'm concerned the list approach would quickly run into maximum-record-size problems, as well as expensive serialization and deserialization costs.\r\n\r\nFor now, we run a patched kafka client which intentionally leaks these metrics, which is far from a long term solution but at least keeps us running at the moment.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-13T20:23:00.873+0000", "updated": "2025-10-13T20:23:00.873+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18029608", "id": "18029608", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "body": "0.5M entries... yeah, that won't work with the list approach...\r\n\r\nDid you consider the \"dummy iterator\" idea? Something like, create an `all()` iterator at startup, and every X second, you first create a new all() iterator, and close the old one? This way, you have at least one open iterator all the time \u2013 you still want to close and replace it periodically, to not get an very old open iterator. Could this work?\r\n\r\nLeaking the metrics sounds like a bad idea, as it will consume a lot a resources inside RocksDB...", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-13T20:32:28.656+0000", "updated": "2025-10-13T20:32:28.656+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18029609", "id": "18029609", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Yes, we can explore the dummy iterator approach. That said, is this not a problem also for built in processors, like the ForeignTableJoinProcessor? It also seems to use a range scan per record.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-13T20:39:55.781+0000", "updated": "2025-10-13T20:39:55.781+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18029618", "id": "18029618", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "body": "We did not observe any regression in our test/benchmark setup with regard to throughput (but maybe our setup is just not catching it), and nobody reported anything about it yet (well, beside you :))... But yes, might be worth to look into. It's not just FK join, but also session-windows, sliding-windows, and stream-stream join that use range scans... (maybe also others \u2013 would need to double check the code).", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-13T22:36:54.353+0000", "updated": "2025-10-13T22:37:41.006+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18031253", "id": "18031253", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "I believe I can observe a similar performance bottleneck where the `ForeinTableJoinProcessorSupplier$KTableKTableJoinProcessor` is less performant than it could be due to repeated registering and unregistering metrics with this lock, so while I am happy to test workaround on our custom processor, I have increased confidence that ideally there would be a fix outside of each individual processor having workarounds:\r\n\r\n\r\n\r\n!image-2025-10-20-13-36-54-857.png!", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-20T20:37:14.412+0000", "updated": "2025-10-20T20:37:14.412+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18031472", "id": "18031472", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Ok, I think part of the reason why the monitor contention is so high, is because we have a lot of metrics registered, and the storage is a LinkedList inside a CHM. I'm not sure yet if 9.1M(!!) metrics is a leak or something we're doing wrong...\r\n\r\n!image-2025-10-21-09-24-02-505.png!", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-21T16:23:30.217+0000", "updated": "2025-10-21T16:24:28.951+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18031487", "id": "18031487", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Ok, this might be an error on our end. I (too eagerly?) picked the fix to KAFKA-19748 before it was finished, looks like the version I have is incomplete, and thought the metrics leak was fixed. I will re-apply the final version and hope it fixes the leak properly this time.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-21T17:03:41.539+0000", "updated": "2025-10-21T17:03:41.539+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18031505", "id": "18031505", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "Re-picking the fix to KAFKA-19748 made the situation much, much better. But, I am still seeing elevated levels of contention, with the leak fixed.", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-21T18:18:41.302+0000", "updated": "2025-10-21T18:18:41.302+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18031529", "id": "18031529", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "body": "[~mjsax] , would it make sense to move the state store oldest open iterator metric from current INFO to only register when metrics is set to DEBUG level? That would resolve the issue as far as we are concerned, we are happy to accept this kind of overhead when debugging (now that the leak is fixed).", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=stevenschlansker", "name": "stevenschlansker", "key": "stevenschlansker", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Steven Schlansker", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-21T19:26:12.939+0000", "updated": "2025-10-21T19:27:25.806+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13628249/comment/18031538", "id": "18031538", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "body": "{quote}ideally there would be a fix outside of each individual processor having workarounds\r\n{quote}\r\nI never disagreed about this \u2013 just wanted to get you out of the ditch, until we find a fix :)\u00a0\r\n\r\nGlad you figures out the memory/metric leak thing, and happy to hear that the fix improves the situation... AK 4.1.1 should do out soon....\r\n\r\nInteresting idea about making it a DEBUG level metric \u2013 could be a good solution in case we cannot figure out anything better. But would require a KIP I assume? [~bbejeck] wanted to work on this ticket. Let's hear from him. \u2013 Personally I would hope that we just find a good fix, even if I am not 100% sure what it could be \u2013 maybe something a lazy/delayed removal of the metric, that we would cancel if a new iterator comes in again?", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=mjsax", "name": "mjsax", "key": "mjsax", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=mjsax&avatarId=29314", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mjsax&avatarId=29314", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mjsax&avatarId=29314", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mjsax&avatarId=29314"}, "displayName": "Matthias J. Sax", "active": true, "timeZone": "America/Los_Angeles"}, "created": "2025-10-21T20:23:10.667+0000", "updated": "2025-10-21T20:23:10.667+0000"}], "maxResults": 13, "total": 13, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}