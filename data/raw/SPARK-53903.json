{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13631526", "self": "https://issues.apache.org/jira/rest/api/2/issue/13631526", "key": "SPARK-53903", "fields": {"summary": "Performance degradation for PySpark apis at scale as compared to Scala apis", "description": "Customers love PySpark and the flexibility of using several python libraries as part of our workflows. I've a unique scenario where this specific usecase has multiple tables with around 10k columns and some of those columns have array datatype that when exploded, contain ~1k columns each.\r\n\r\n*Issues that we are facing:*\r\n * Frequent driver OOM depending on the use case and how many columns are involved in the logic and how many array type columns are exploded. There is frequent GC, slowing down the workflows.\r\n * We tried equivalent scala apis and the performance as well latency seemed a lot better (no OOM and significantly less GC overheads).\r\n\r\n*Here is what we understand so far from thread and memory dumps:*\r\n * driver ends up having open references for every pyspark object created in the python vm because of py4j bridge-based communication implementation for pyspark apis. and the garbage keeps accumulating on driver ultimately leading to OOM\r\n * even if we delete python references in pyspark code (for example: \u00a0del df_dummy1) and run \"gc.collect()\" specifically, we are not able to ease the memory pressure. Python gc or python triggered gc via py4j bridge in the driver doesn't seem to be that good.\r\n\r\nThis is not a typical workload but we have multiple such usecases and we are debating if it's worth changing existing workflows to scala just like that (existing DEs are more comfortable with PySpark, there is cost of migration as well that we will have to convince our management to approve)\r\n\r\n*ASK:*\r\n\r\nThis Jira includes a sample notebook that reproduces what our usecases see. We are seeking community feedback on such a usecase and if there are ideas to improve this situation further other than migrating to Scala apis. Any PySpark improvement ideas that could help?\u00a0", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ksumit", "name": "ksumit", "key": "ksumit", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10438", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10438", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10438", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10438"}, "displayName": "Sumit Kumar", "active": true, "timeZone": "America/Vancouver"}, "comment": {"comments": [], "maxResults": 0, "total": 0, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/3", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg", "name": "Major", "id": "3"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/1", "description": "The issue is open and ready for the assignee to start work on it.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png", "name": "Open", "id": "1", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2", "id": 2, "key": "new", "colorName": "blue-gray", "name": "To Do"}}}}