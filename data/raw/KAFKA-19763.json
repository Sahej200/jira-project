{"expand": "renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations", "id": "13630886", "self": "https://issues.apache.org/jira/rest/api/2/issue/13630886", "key": "KAFKA-19763", "fields": {"summary": "Parallel remote reads causes memory leak in broker", "description": "This issue is caused with changes from https://issues.apache.org/jira/browse/KAFKA-14915\r\n\r\nBroker heap memory gets filled up and throws OOM error when remote reads are triggered for multiple partitions within a FETCH request. \r\n\r\nSteps to reproduce: \r\n\r\n1. Start a one node broker and configure LocalTieredStorage as remote storage. \r\n2. Create a topic with 5 partitions. \r\n3. Produce message and ensure that few segments are uploaded to remote.\r\n4. Start a consumer to read from those 5 partitions. Seek the offset to beginning for 4 partitions and to end for 1 partition. This is to simulate that the FETCH request read from both remote-log and local-log.\r\n5. The broker crashes with the OOM error.\r\n6. The DelayedRemoteFetch / RemoteLogReadResult references are being held by the purgatory, so the broker crashes.\r\n\r\ncc [~showuon] [~satish.duggana]\r\n", "reporter": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ckamal", "name": "ckamal", "key": "ckamal", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Kamal Chandraprakash", "active": true, "timeZone": "Asia/Kolkata"}, "comment": {"comments": [{"self": "https://issues.apache.org/jira/rest/api/2/issue/13630886/comment/18028277", "id": "18028277", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=showuon", "name": "showuon", "key": "showuon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=showuon&avatarId=42594", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=showuon&avatarId=42594", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=showuon&avatarId=42594", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=showuon&avatarId=42594"}, "displayName": "Luke Chen", "active": true, "timeZone": "Etc/UTC"}, "body": "[~ckamal] , I tired to reproduce it using your steps, but the heap only increase ~ 100 MB, not a big issue IMO. Have you figured it out where do we leak the memory?\u00a0\u00a0", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=showuon", "name": "showuon", "key": "showuon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=showuon&avatarId=42594", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=showuon&avatarId=42594", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=showuon&avatarId=42594", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=showuon&avatarId=42594"}, "displayName": "Luke Chen", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T06:33:23.072+0000", "updated": "2025-10-08T06:33:23.072+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630886/comment/18028315", "id": "18028315", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ckamal", "name": "ckamal", "key": "ckamal", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Kamal Chandraprakash", "active": true, "timeZone": "Asia/Kolkata"}, "body": "[~showuon]\r\nAble to reproduce the issue consistently. Uploaded the RemoteReadMemoryLeakReproducer. The leak was due to that the DelayedRemoteFetchPurgatory holding the references of previously completed DelayedRemoteFetch objects. DelayedRemoteFetch contains the RemoteReadResult internally.\r\n\r\n> Have you figured it out where do we leak the memory? \r\nIn a given FETCH request, if 1 out of 5 partition, read the data from local log, then the watcherKey for that partition holds the reference of the DelayedRemoteFetch in the purgatory; if there are no other remote-read happens for that partition, then it won't get removed until the reaper thread cleans it up after the purgeInterval (entries) of 1000.\u00a0\r\n{code:java}\r\n% sh kafka-topics.sh --create --topic apple --partitions 5 --replication-factor 1 --bootstrap-server localhost:9092 --config remote.storage.enable=true --config local.retention.ms=60000 --config retention.ms=7200000 --config segment.bytes=104857600 --config file.delete.delay.ms=1000\r\n\r\n% for i in `seq 1 100`; do echo $i; sleep 1; sh kafka-producer-perf-test.sh --topic apple --num-records 1200000000 --record-size 1024 --throughput 1000 --producer-props bootstrap.servers=localhost:9092; done {code}", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=ckamal", "name": "ckamal", "key": "ckamal", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Kamal Chandraprakash", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-10-08T09:12:17.837+0000", "updated": "2025-10-08T09:25:06.973+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630886/comment/18028323", "id": "18028323", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=showuon", "name": "showuon", "key": "showuon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=showuon&avatarId=42594", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=showuon&avatarId=42594", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=showuon&avatarId=42594", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=showuon&avatarId=42594"}, "displayName": "Luke Chen", "active": true, "timeZone": "Etc/UTC"}, "body": "This patch fixes the problem. But it slows down the read throughput because it takes time to clone the buffer. There should be other better solutions.\r\n\r\n\u00a0\r\n{code:java}\r\n--- a/core/src/main/scala/kafka/server/DelayedRemoteFetch.scala\r\n+++ b/core/src/main/scala/kafka/server/DelayedRemoteFetch.scala\r\n@@ -22,6 +22,7 @@ import kafka.utils.Logging\r\n\u00a0import org.apache.kafka.common.TopicIdPartition\r\n\u00a0import org.apache.kafka.common.errors._\r\n\u00a0import org.apache.kafka.common.protocol.Errors\r\n+import org.apache.kafka.common.record.MemoryRecords\r\n\u00a0import org.apache.kafka.server.LogReadResult\r\n\u00a0import org.apache.kafka.server.metrics.KafkaMetricsGroup\r\n\u00a0import org.apache.kafka.server.purgatory.DelayedOperation\r\n@@ -121,7 +122,8 @@ class DelayedRemoteFetch(remoteFetchTasks: util.Map[TopicIdPartition, Future[Voi\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0result.error,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0result.highWatermark,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0result.leaderLogStartOffset,\r\n- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0info.records,\r\n+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0// clone the record buffer to release the memory\r\n+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0MemoryRecords.readableRecords(info.records.asInstanceOf[MemoryRecords].buffer()),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Optional.empty(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0if (result.lastStableOffset.isPresent) OptionalLong.of(result.lastStableOffset.getAsLong) else OptionalLong.empty(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0info.abortedTransactions,\r\n@@ -132,7 +134,8 @@ class DelayedRemoteFetch(remoteFetchTasks: util.Map[TopicIdPartition, Future[Voi\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0tp -> result.toFetchPartitionData(false)\r\n\u00a0 \u00a0 \u00a0 \u00a0}\r\n\u00a0 \u00a0 \u00a0}\r\n-\r\n+ \u00a0 \u00a0// clear the map to avoid memory leak\r\n+ \u00a0 \u00a0remoteFetchResults.clear()\r\n\u00a0 \u00a0 \u00a0responseCallback(fetchPartitionData)\r\n\u00a0 \u00a0}\r\n\u00a0}\r\n{code}", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=showuon", "name": "showuon", "key": "showuon", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=showuon&avatarId=42594", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=showuon&avatarId=42594", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=showuon&avatarId=42594", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=showuon&avatarId=42594"}, "displayName": "Luke Chen", "active": true, "timeZone": "Etc/UTC"}, "created": "2025-10-08T10:16:34.982+0000", "updated": "2025-10-08T10:17:12.198+0000"}, {"self": "https://issues.apache.org/jira/rest/api/2/issue/13630886/comment/18030998", "id": "18030998", "author": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=satish.duggana", "name": "satish.duggana", "key": "satish.duggana", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Satish Duggana", "active": true, "timeZone": "Asia/Kolkata"}, "body": "This issue is fixed with https://github.com/apache/kafka/pull/20654 and https://github.com/apache/kafka/pull/20706", "updateAuthor": {"self": "https://issues.apache.org/jira/rest/api/2/user?username=satish.duggana", "name": "satish.duggana", "key": "satish.duggana", "avatarUrls": {"48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452", "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452", "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452", "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"}, "displayName": "Satish Duggana", "active": true, "timeZone": "Asia/Kolkata"}, "created": "2025-10-20T00:13:21.724+0000", "updated": "2025-10-20T00:13:21.724+0000"}], "maxResults": 4, "total": 4, "startAt": 0}, "priority": {"self": "https://issues.apache.org/jira/rest/api/2/priority/1", "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg", "name": "Blocker", "id": "1"}, "status": {"self": "https://issues.apache.org/jira/rest/api/2/status/5", "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.", "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png", "name": "Resolved", "id": "5", "statusCategory": {"self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3", "id": 3, "key": "done", "colorName": "green", "name": "Done"}}}}